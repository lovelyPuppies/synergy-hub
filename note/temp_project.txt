https://pmnxis.github.io/posts/my_first_commerical_rust_embedded_product_1/

XP-Pen Driver ... Gimp ì—ì„œ ì¸ì‹ì‹œí‚¤ê¸°
  * Deco LW:
    https://www.xp-pen.com/download/deco-lw.html
    ... download .deb file
    %shell> sudo dpkg -i XPPENLinux3.4.9-240607.deb


ê°œì¸ì •ë³´ë³´í˜¸ë²•.. ì–´í”Œë¦¬ì¼€ì´ì…˜.. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì°¸ê³ ..
  you will need to provide:
    An official link to your app's Privacy Policy
    A YouTube video showing how you plan to use the Google user data you get from scopes
    A written explanation telling Google why you need access to sensitive and/or restricted user data
    All your domains verified in Google Search Console 

DSP Digital signal Processing? ì´ë¯¸ì§€ì™€ ê´€ë ¨..?

ì œê°€ ì–¸ê¸‰í•œ ~/.local/share/applications/kakaotalk.desktop íŒŒì¼ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ë‰´ì— KakaoTalkì„ ì¶”ê°€í•˜ê±°ë‚˜, ë°”íƒ•í™”ë©´ì— ì•„ì´ì½˜ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” íŒŒì¼ì…ë‹ˆë‹¤. ì´ íŒŒì¼ì„ ìƒì„±í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
  ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ë‰´:
      Ubuntuì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ë‰´ì—ì„œ KakaoTalkì„ ê²€ìƒ‰í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Ubuntuì˜ ì¢Œì¸¡ ìƒë‹¨ì— ìˆëŠ” "í™œë™" ë©”ë‰´ì—ì„œ KakaoTalkì„ ê²€ìƒ‰í•˜ë©´ ì´ ì•„ì´ì½˜ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.
  ë°”íƒ•í™”ë©´ ì•„ì´ì½˜:
      ì´ íŒŒì¼ì„ ë°”íƒ•í™”ë©´ì— ë³µì‚¬í•˜ë©´ ë°”íƒ•í™”ë©´ì—ì„œ ë°”ë¡œ KakaoTalkì„ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì•„ì´ì½˜ì´ ìƒì„±ë©ë‹ˆë‹¤.

  ì¢Œì¸¡ ë°”(Launcher)ì— ê³ ì •ëœ ì•„ì´ì½˜
    ì¢Œì¸¡ ë°”(Launcher)ì— ê³ ì •ëœ ì•„ì´ì½˜ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•˜ê±°ë‚˜ ê³ ì •í•  ë•Œ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.
    ì•±ì„ ì‹¤í–‰í•œ í›„, ì¢Œì¸¡ ë°”ì— ì•„ì´ì½˜ ê³ ì •:
        KakaoTalkì„ í•œ ë²ˆ ì‹¤í–‰í•˜ë©´, í•´ë‹¹ ì•„ì´ì½˜ì´ ì¢Œì¸¡ ë°”ì— ë‚˜íƒ€ë‚©ë‹ˆë‹¤. ì•„ì´ì½˜ì„ ìš°í´ë¦­í•œ í›„ "ì¦ê²¨ì°¾ê¸°ì— ì¶”ê°€" ë˜ëŠ” "ë°”ì— ê³ ì •"ì„ ì„ íƒí•˜ë©´ ì•„ì´ì½˜ì´ ì¢Œì¸¡ ë°”ì— ê³ ì •ë©ë‹ˆë‹¤.
    .desktop íŒŒì¼ì„ í†µí•œ ê³ ì •:
        .desktop íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê³ ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ íŒŒì¼ì„ ìƒì„±í•˜ê³  ì•±ì„ ì‹¤í–‰í•˜ë©´, í•´ë‹¹ ì•„ì´ì½˜ì´ ì¢Œì¸¡ ë°”ì— ìë™ìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.
  ë”°ë¼ì„œ, ì œê°€ ì„¤ëª…í•œ .desktop íŒŒì¼ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ë‰´ì— ì•„ì´ì½˜ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë°”íƒ•í™”ë©´ì— ì•„ì´ì½˜ì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì´ë©°, ì´ë¥¼ í†µí•´ KakaoTalkì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¢Œì¸¡ ë°”ì— ì•„ì´ì½˜ì„ ê³ ì •í•˜ë ¤ë©´ KakaoTalkì„ í•œ ë²ˆ ì‹¤í–‰í•œ í›„ ê³ ì •í•˜ë©´ ë©ë‹ˆë‹¤.

    
ì—ì´ë‹¤ ë¶€ìŠ¤íŠ¸ í•™ìŠµ; ê°€ëŠ¥í•œ ëª¨ë“  ì»¤ë„ì„ ê°€ì§€ê³  ì´ë¯¸ì§€ ì „ì²´ë¥¼ ìŠ¤ìº”í•˜ì—¬ í•˜ë¥´ íŠ¹ì§•ì„ ê³„ì‚°í•œë‹¤?
https://docs.ultralytics.com/models/yolo-nas/

0 0?? 
  0: Dump backup. 0 is not dump
  0: fcsk (File System check). 0s is not check

  /etc/fstab ë¬¸ì œë¡œ ë¶€íŒ…ì´ ì‹¤íŒ¨í•  ê²½ìš°:
  /etc/fstabì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•´ ë¶€íŒ…ì´ ì‹¤íŒ¨í•˜ê±°ë‚˜ ì¤‘ë‹¨ëœ ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

  ë³µêµ¬ ëª¨ë“œì—ì„œ ìˆ˜ì •: ë¶€íŒ… ì‹œ Grub ë©”ë‰´ì—ì„œ ë³µêµ¬ ëª¨ë“œë¡œ ë¶€íŒ…í•œ í›„, /etc/fstab íŒŒì¼ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  ë¼ì´ë¸Œ USBë¡œ ë¶€íŒ… í›„ ìˆ˜ì •: ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ë¶€íŒ…ë˜ì§€ ì•ŠëŠ” ê²½ìš°, ë¼ì´ë¸Œ USBë¥¼ ì‚¬ìš©í•´ ì‹œìŠ¤í…œì„ ë¶€íŒ…í•œ í›„, /etc/fstab íŒŒì¼ì„ ë§ˆìš´íŠ¸í•˜ê³  ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
â” Hard link, Soft link
  https://en.wikipedia.org/wiki/Hard_link
  https://en.wikipedia.org/wiki/Symbolic_link



MediaPipe
  https://github.com/google-ai-edge/mediapipe
    # Contents
      ğŸ” License: Apahce License 2.0

      These libraries and resources provide the core functionality for each MediaPipe Solution:
        ğŸª± MediaPipe Tasks: Cross-platform APIs and libraries for deploying solutions. Learn more.
        ğŸª± MediaPipe models: Pre-trained, ready-to-run models for use with each solution.
      These tools let you customize and evaluate solutions:
        ğŸª± MediaPipe Model Maker: Customize models for solutions with your data. Learn more.
        ğŸª± MediaPipe Studio: Visualize, evaluate, and benchmark solutions in your browser. Learn more.

    Fash Mesh ; https://github.com/google-ai-edge/mediapipe/blob/master/docs/solutions/face_mesh.md
  

  https://ai.google.dev/edge/mediapipe/solutions/guide
    https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker
      # Models
        Face detection model, Face mesh model, Blendshape prediction model

  https://mediapipe-studio.webapps.google.com/demo/face_landmarker
 ğŸŒŸ íƒˆëª¨ì•½>>>>>>>>>>>>>>>>>>>> í”„ë¡œí˜ì‹œì•„, ì•„ë³´ë‹¤íŠ¸, ë¯¸ë…¹ì‹œë”œ?
  
https://en.wikipedia.org/wiki/Facial_Action_Coding_System
  ... blendshape scores (coefficients representing facial expression) from https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker
  https://mediapipe-studio.webapps.google.com/home

MediaPipe API
  # Python
    # mp
      âš“ Overview ; https://ai.google.dev/edge/api/mediapipe/python/mp

https://stackoverflow.com/questions/59051631/what-is-the-use-of-stub-files-pyi-in-python

â“ íŒŒì´ì¬ì—ì„œ ì£¼ë¡œ C++ë¡œ êµ¬í˜„ëœ ë¶€ë¶„ì„ í˜¸ì¶œí•˜ê¸° ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµ...
  pyi stub pile
https://pypi.org/project/type-enforced/

â“ íœ´ëŒ€ìš© ì±… ì§€ì§€ëŒ€

Software Design Specification
  Software Design Design Method: -
  Hardware Constraints: -
  UI: - : pyqt6 ë¡œ í† ê¸€í˜• ìŠ¤í‹°ì»¤ IO ì„¤ê³„
ì•Œê³ ë¦¬ì¦˜
  ..í•¨ìˆ˜ ê°„ì˜ ë™ì‘?


ğŸ‘ğŸ“° GPT APP: Writing Assitant
  "ì–´ìƒ‰í•˜ê²Œ ì´ì–´ì§€ëŠ” ë¶€ë¶„ì„ ìˆ˜ì •í•˜ê³  ë°°ë ¤ìˆëŠ” í‘œí˜„ê³¼ ê²©ì‹ì²´ë¥¼ ì‚¬ìš©í•´ì„œ, ì „ë¬¸ì ìœ¼ë¡œ êµ¬ì²´ì ì¸ ê·¼ê±°ì™€ í•¨ê»˜, ì „ì²´ì ìœ¼ë¡œ ì˜ ë‹¤ë“¬ì–´ì¤˜."
  // ìˆ˜ìš” ì¦ê°€ì— ëŒ€í•œ ì£¼ì¥ì„ í”¼í•˜ì.
  // ê³ ë ¹ìì˜ ì¼ìƒê³¼ ê¸°ì–µì„ ê¸°ë¡í•˜ëŠ” ë¬¸ì œê°€ ì‚¬íšŒì  ê³¼ì œë¡œ ë– ì˜¤ë¥´ê³  ìˆë‹¤ ë¼ëŠ” êµ¬ì²´ì ì¸ ì‚¬ë¡€ë‚˜ ë‰´ìŠ¤ê°€ ë¶€ì¡±.

ğŸŒªï¸ TODO: MonkeyType
  íƒ€ì… íŒíŠ¸ ìë™ ìƒì„± ë„êµ¬:
    MonkeyType:
        MonkeyTypeì€ ì½”ë“œ ì‹¤í–‰ ì‹œ ë™ì  ì¶”ì ì„ í†µí•´ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” íƒ€ì…ì„ ê¸°ë°˜ìœ¼ë¡œ íƒ€ì… íŒíŠ¸ë¥¼ ì¶”ë¡ í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íƒ€ì… íŒíŠ¸ë¥¼ ìƒì„±í•´ ì¤ë‹ˆë‹¤.
    ... protobuf ì—ì„œ ì¶”ì  ì•ˆë˜ëŠ” ê²ƒë„ ìƒì„±í•´ì£¼ëŠ”ì§€ ì²´í¬.
  https://pypi.org/project/types-protobuf/

ì‚¬ìš©ìë“¤ì€ ìƒì„±ëœ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê¸°ë¡ì„ ì›¹ ë˜ëŠ” ëª¨ë°”ì¼ ì•±ì„ í†µí•´ ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì´ ê¸°ë¡ì„ ë””ì§€í„¸ ì•¨ë²”ìœ¼ë¡œ ê´€ë¦¬í•˜ê±°ë‚˜ SNSì— ê³µìœ í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤â€‹.

**** Usecase, Class Diagram, Activity diagram
  ìœ ìŠ¤ì¼€ì´ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨: ì‹œìŠ¤í…œê³¼ ì‚¬ìš©ì ê°„ ìƒí˜¸ì‘ìš©ì„ ì„¤ëª…í•˜ëŠ” ê³ ìˆ˜ì¤€ ê°œìš”.
  í™œë™ ë‹¤ì´ì–´ê·¸ë¨: ìœ ìŠ¤ì¼€ì´ìŠ¤ë‚˜ í”„ë¡œì„¸ìŠ¤ì˜ ì„¸ë¶€ íë¦„.
  ìƒíƒœ ë‹¤ì´ì–´ê·¸ë¨: ê°ì²´ì˜ ìƒíƒœ ì „ì´.
  ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨: ê°ì²´ ê°„ì˜ ë©”ì‹œì§€ íë¦„.
  í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨: ì‹œìŠ¤í…œì˜ êµ¬ì¡°ì™€ ê´€ê³„.

  ì¶”ì²œ ìˆœì„œ:
    ìœ ìŠ¤ì¼€ì´ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨: ì „ì²´ ì‹œìŠ¤í…œì˜ ê°œìš”ë¥¼ ë¨¼ì € ì„¤ëª….
    í™œë™ ë‹¤ì´ì–´ê·¸ë¨: ì£¼ìš” í”„ë¡œì„¸ìŠ¤ì˜ ì„¸ë¶€ íë¦„ì„ ë³´ì—¬ì¤Œ.
    ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨: ìƒí˜¸ì‘ìš© íë¦„ì„ ì‹œê°í™”.
    í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨: ì‹œìŠ¤í…œì˜ êµ¬ì¡°ë¥¼ ì„¤ëª…. ì •ì  êµ¬ì¡°.
    ìƒíƒœ ë‹¤ì´ì–´ê·¸ë¨: ê°ì²´ì˜ ë™ì  ìƒíƒœ ë³€í™”ë¥¼ ì„¤ëª….

ê¸°ìˆ ë¬¸ì„œëŠ” ì„œìˆ í˜• X. ìˆ˜í•™ì ìœ¼ë¡œ.


ì• í”Œ ì„¼í„°ìŠ¤í…Œì´ì§€ ê¸°ëŠ¥ êµ¬í˜„í•´ë³´ê¸°?? 
  ì¹´ë©”ë¼ê°€ ì‚¬ìš©ìë¥¼ ë”°ë¼ë‹¤ë‹ˆë©´ì„œ í¬ì°©í•˜ëŠ”ë“¯
  smooth í•˜ê²Œ ì²œì²œíˆ ì´ë™í•´ì•¼ í•¨.

BlazeFace (short-range)
  ìŠ¤ë§ˆíŠ¸í° ì¹´ë©”ë¼ë‚˜ ì›¹ìº ì—ì„œ ì…€ì¹´ ê°™ì€ ì´ë¯¸ì§€ì—ì„œ í•˜ë‚˜ ë˜ëŠ” ì—¬ëŸ¬ ê°œì˜ ì–¼êµ´ì„ ê°ì§€í•˜ê¸° ìœ„í•œ ê°€ë²¼ìš´ ëª¨ë¸ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë‹¨ê±°ë¦¬ì—ì„œ ì „ë©´ ì¹´ë©”ë¼ ì´ë¯¸ì§€ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ ì•„í‚¤í…ì²˜ëŠ” ì‚¬ìš©ì ì§€ì • ì¸ì½”ë”ê°€ ìˆëŠ” Single Shot Detector(SSD) í•©ì„±ê³± ë„¤íŠ¸ì›Œí¬ ê¸°ìˆ ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ Single Shot MultiBox Detectorì— ëŒ€í•œ ì—°êµ¬ ë…¼ë¬¸ì„ ì°¸ì¡°í•˜ì„¸ìš”.

PPT...
  ì´ëŸ° ê²½ìš°, í”„ë¡œì íŠ¸ì˜ ê¸°íš ë°°ê²½, ê¸°ìˆ ì ì¸ ì„¤ëª…, ê°œì¸ì ì¸ ë™ê¸° ìˆœì„œë¡œ ë‚˜ì—´í•˜ë©´ ë” ìì—°ìŠ¤ëŸ½ê²Œ íë¦„ì„ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìˆ˜ì •ëœ ë²„ì „ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

GaussianBlur, Sobel filter, ì´ì§„í™”, ConvexHull, Edge Area, Mask, HSV ìƒ‰ ì²˜ë¦¬.. ì—£ì§€ ê²€ì¶œ.. sobel maskvs canny edge, ìº˜ë¦¬ë¸Œë ˆì´ì…˜
  ...


  
ğŸ“° ì¹´ì¹´ì˜¤í†¡ API.. authorization code..
ğŸ“° zoom-in, zoom-out ê¸°ëŠ¥. ìë™ ì¶”ì  ê¸°ëŠ¥ ë§Œë“¤ê¸°.. smooth í•˜ê²Œ ì›€ì§ì´ë„ë¡?
https://en.wikipedia.org/wiki/Docent
ì²­ë…„ ì•ˆì‹¬ì£¼íƒ ì„ëŒ€ë³´ì¦ê¸ˆì§€ì› ; https://soco.seoul.go.kr/youth/main/contents.do?menuNo=400022
ë³µì§€ì•±
ìƒì¡°ë³´í—˜




ğŸ“°ğŸ“°ğŸ“°ğŸ“°ğŸ“° >>>>>>>>>>
  >>>>>>>>> ìŒì„±ìœ¼ë¡œë¶€í„° ê°ì • ë¶„ì„í•˜ëŠ” ê¸°ìˆ  í•„ìš”...: ì˜ˆ: Cogito, Beyond Verbval, Affectiva, Nexmo (Vonage API)

  ë‹ˆë‹¤ -> X. ëª…ì‚¬í˜•ìœ¼ë¡œ ëë‚´ëŠ” ê²ƒì´ ë‚˜ì€ ë“¯?
  ê°œì¸í™”ëœ>> ì œê±°
  ìì—°ì–´ ì²˜ë¦¬(NLP) ..  í•´ì•¼ í• ë“¯. ìƒì„±í˜• AI ê°€ ë‹¤ í•´ ì£¼ëŠ”ê±°ì•„ë‹Œê°€? ë¬¸ì¥ìœ¼ë¡œë¶€í„° í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì„œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë™ì ì¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ì•¼ í•´ì„œ.
  >> ê°€ë…ì„±ìˆê²Œ ì¶”ë ¤ë‹¬ë¼...
  í”„ë¼ì´ë¹— í´ë¼ìš°ë“œ..

  ë””ì§€í„¸ ì•¨ë²”ì€ ì „í†µì ì¸ ì‚¬ì§„ì²©ì„ ë””ì§€í„¸í™”í•œ ê²ƒìœ¼ë¡œ, ì‚¬ìš©ìë“¤ì´ ì €ì¥í•œ ì‚¬ì§„, ì˜ìƒ, í…ìŠ¤íŠ¸ ê¸°ë¡ ë“±ì„ í•œ ê³³ì— ëª¨ì•„ ì‰½ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ ì•¨ë²”ì€ ì‚¬ìš©ìë“¤ì´ ìì‹ ë§Œì˜ ì†Œì¤‘í•œ ìˆœê°„ì„ ì •ë¦¬í•˜ê³  ì–¸ì œë“ ì§€ ë‹¤ì‹œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê³µê°„ì„ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ ì´ ì„œë¹„ìŠ¤ì—ì„œëŠ” ìŒì„± ê¸°ë¡ê³¼ ì´ë¯¸ì§€, ìœ„ì¹˜ ì •ë³´ ë“±ì´ í†µí•©ë˜ì–´ ê¸°ë¡ë˜ê¸° ë•Œë¬¸ì—, ì´ëŸ¬í•œ ë°ì´í„°ë¥¼ ì‹œê°ì ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ëŠ” ê°œì¸ ë§ì¶¤í˜• ê¸°ë¡ ë³´ê´€ì†Œ ì—­í• ì„ í•©ë‹ˆë‹¤.


====================================
AL/DL Momentu
  ì¸í…” ê°€ìš°ë”” ì‚¬í”¼ì˜¨??

ìë™ì°¨ê°€.. ë§¤ìš° ë³´ìˆ˜ì ì¸ ì§‘ë‹¨ì´ì—ˆë‹¤..
  ì¤‘êµ­- BYD ì²´ë¦¬, ê·¸ë ˆì´íŠ¸ë³¼?.. ìë™ã…ˆì°¨ ë‚˜ì˜¤ëŠ”ì£¼ê¸°ê°€ 2ë…„ã„·ã„·?
ì „ê¸°ì°¨ëŠ”.. ë°”í€´ë¥¼ ëŒë¦¬ëŠ” ë™ë ¥ì´ í™”ì„ê¸°ê´€ì—ì„œ ì˜¤ëƒ ë™ë ¥ê¸°ê´€ì—ì„œ ì˜¤ëƒ..
  ì˜¤íˆë ¤ í•˜ì´ë¸Œë¦¬ë“œê°€ ë” ë‚˜ì„  ìˆ˜ ìˆë‹¤?>
  iCQA? GQ ì„¼ì„œ?..ë¡œìš°ë ˆë²¨ ë“œë¼ì´ë²„ ê²½í—˜í•´ë³´ëŠ” ê²ƒì´ ì¢‹ë‹¤.
  ì»¤ë„ìª½ì„ ì¢€ íŒŒë´ë¼..
ì¸í…”ì´ ì„œë²„ìª½ì€ê°•í–ˆëŠ”ë° ì—£ì§€ê°€ ì•½í•´ì„œ.. ì—£ì§€ ë¶„ì•¼ë¥¼ ê°œë°œì¤‘ì´ë‹¤?
  Hands-on ì„ ê°™ì´í•˜ë©´ì„œ ì¨ë³´ëŠ” ê²ƒì´ ëª©í‘œ.



í‰ì„œí˜• ì¢…ê²°ì–´ë¯¸
í•´ë¼ì²´ (ê²©ì‹ ë°˜ë§, í‰ì„œí˜• ë‹¤ì²´)

Imagent Large scale Visual Recognition challenge. ILSVRC
  ì‚¬ëŒê¸°ì¤€ 5%.. 2015ë…„ ResNet, GoogleNet-v4, SENet.. ì˜¤ì°¨ìœ¨ ê³„ì™ ì¤„ì–´ë“¬..



ë”¥ëŸ¬ë‹ê³¼ ì—°ì—­ì ì¸ ë°©ë²•ì´ ë‹¤ë¥´ë‹¤.
  ë”¥ëŸ¬ë‹ì€.. ë°ì´í„°ì…‹ í•™ìŠµì´ í•„ìš”.
openvino.. pytorch ì—ì„œë„ extension ì“¸ ìˆ˜ ìˆë‹«ê³  í•œë‹¤. 
  ëŒ€ì‹  ì„±ëŠ¥ 90/100%

AI Growth.
AI Products
  í•­ë§Œ.. ë¶ˆë²•ã…‡ìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ì™¸ë…¸ì ê´€ë¦¬?
  LG energy solution, Hyundai, Hanwha, ë¡¯ë°, í˜„ëŒ€ì¤‘ê³µì—…, ë„¤ì´ë²„, View the Invisible, Know the Unknown (VUNO?)
  ğŸš£ SAMSUNG Medison, DELL, Lottel, EMARt, Beart Lobotics, ì‹ í•œì€í–‰, LG Energy Solution
    SAMSUNG Medison ê°€ ê°€ì¥ ë§ì´ ì¼í–ˆë‹¤ê³  í•œë‹¤.
    NVIDIA ê°€ 2ë…„ ë³´ì¦ì´ë¼ì„œ... intel ì´ë‘ ë§ì´ ì¼í–‡ë‚˜?..
    ì• ê¸°..ì—ê²Œ ë­”ê°€ íŒë‹¨í•  ë–„ ì‚¬ìš©?? ë³‘ì›ì—ì„œ ì“°ëŠ”ê±°ë¼ Watt ë¥¼ ë§ì´ ëª»ì“´ë‹¤ê³  í•œë‹¤. 
    ë³‘ì›ì—ì„œ ê¸°ê¸°ë“¤ì´ ì „ë ¥ì„ ë§ì´ì“°ë©´ ë¬¸ì œê°€ ìƒê¸´ë‹¤. ì €ì „ë ¥ì—ì„œ êµ¬ë™ê°€ëŠ¥í•œ ê²ƒì´ í•„ìš”í•´ì„œ.. ì¸í…”ì—ì„œ êµ‰ì¥íˆ ì„±ê³µì ì¸ ì¼€ì´ìŠ¤ë¡œ ë¶„ë¥˜í•œë‹¤ê³  í•¨.
    OpenVino - Intel
  ì™„ì „ ê³ ì„±ëŠ¥ì€ NVIDIA, ì¤‘ê°„ ì„±ëŠ¥ ê¸°ëŠ¥ìœ¼ë¡œ OpenVINO ê°€ ì í•˜ë‹¤ê³  í•œë‹¤.
  >>>>> ë©´ì ‘ë³¼ë•Œë§ˆë‹¤ ì—¬ê¸°ì—ì„œëŠ” ë‹¤ë¥¸ ê²ƒì„ í•  ìˆ˜ ìˆë‹¤ ì–´í•„í•  ì •ë„ë¡œ. ê³µë¶€í•´ì•¼ í• ë“¯.
AI ëŠ” ìì—°ìœ¼ë¡œë¶€í„° ì˜ê°ì„ ë§ì´ ë°›ì•˜ë‹¤ê³  í•œë‹¤.
ì‚ì‚ì‚-ì°¨ëŸ‰ ì†Œë¦¬.. ë°•ì¥ì˜ ì´ˆìŒíŒŒ..ë¡œ..ë¶€í„° ì˜ê°ì„ ë°›ì•˜ë‹¤.
ì‚¬ì´ë“œ?..ì–´ì©Œêµ¬ ì €ì©Œêµ¬ëŠ” ì‚¬ë§‰ë±€ì˜ ì—´ì¶”ì ? ìœ¼ë¡œë¶€í„° ì˜ê°ì„ ë°”ì•˜ë‹¤.
â“ ì„¸ì„íœ? ì‚¬ì§„?ì„ ì§‘ìœ¼ë©´ ì–´ë–¤ ë™ë¬¼ì¸ì§€ ë§í•´ì£¼ëŠ” ì œí’ˆ?
  í«ë‚˜ìš°"ì™€ ê°™ì€ AI ê¸°ë°˜ ë™ë¬¼ ì¸ì‹ ê¸°ìˆ ì„ ê°€ë¦¬í‚¤ëŠ” ê²ƒ
ì£¼ì°¨ê´€ë¦¬ì‹œìŠ¤í…œ ...
ğŸ†š í…ì„œí”Œë¡œìš°, pytorch ì–¸ì œì‚¬ìš©í•˜ë‚˜ ë¬¼ì–´ë³¼ê°€

â“ ë©´ì ‘.. ê·¸ê±° ì§€ê¸ˆ ìˆëŠ”ë° --> ì§€ê¸ˆ ê·¸ëŸ¼ íšŒì‚¬ëŠ” ì–´ë–¤ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ê³  ì–´ë–¤ ë„¤íŠ¸ì›¤ì„ ì“°ê³  ê³„ì‹œë‚˜ìš”?
  ê·¸ ëª¨ë¸ ê°™ì€ ê²½ìš°ëŠ” ì´ëŸ° ëª¨ë¸ì€ ë‚®ì¶˜ë‹¤ë©´ .. time-critical í•˜ì§€ ì•Šì•„ì„œ FPS ëŠ” ì¡°ê¸ˆ ë–¨ì–´ì§€ê²Ÿì§€ë§Œ, .. ì–´ì©Œêµ¬.. 

Image segementation
  ì„¤ëª…: positioning íŒë‹¨í•˜ì£ ? ì‚¬ëŒ ì˜ì—­ ì´ë ‡ê²Œ íŒë‹¨í•˜ì£ ?
OCR


ì¸í…” ì½”ë¦¬ì•„ ê³½ìš°ì˜
  CPG :Communication Product Group? 
  ì¸í…” ëª¨ë°”ì¼, íƒ€ë¸”ë¦¿.. í•˜ëŠ” ì¡°ì§

ë°˜ë„ì²´: conductor, insulator ì˜ ì¤‘ê°„ ë¬¼ì§ˆ..
  ëª¨ë“  ê°€ì „ì œí’ˆì— ë“¤ì–´ê°€ëŠ”..
  ì›ìì¬: ê°ˆë¥¨, ì‹¤ë¦¬ì½˜.. ..

Indstur

World=changing Technology. 
  -- 
  Diriving Product Leadership


>>>>>> [Intel] Lunar Lake - AI PC
  On-Device.. NPU ìì²´ê°€ ì—†ì—ˆë‹¤.
ì˜¬í•´ë¶€í„° ë‚˜ì˜¤ëŠ” PCëŠ” On-Device ë¼ê³  ëª…ì¹­í•œë‹¤ê³  í•œë‹¤. NPU íƒ‘ì¬.
  ê·¸ ì¤‘ Lunar Lake
  CPU, GPU, NPU ê°€ í•¨ê»˜ ë‚´ì¥ëœë‹¤ëŠ”ë“¯.
    HP GPU? LNC?

  45 TOPS ê°€ ë„˜ì–´ì•¼ On-Device ë¼ê³  í•œë‹¤ê³  í•œë‹¤.

  ğŸª± Intel - í¬ë² ë¡œìŠ¤ëŠ” ì¹©ë › êµ¬ì¡°ì˜ 3D ë°˜ë„ì²´ ì ì¸µ ê¸°ìˆ ì´ë‹¤

  Lunar Lake - ğŸª± MOP package (Memory on Package)
    Foveros
  
  * Ultimate Thin& Light Systems
    - Detachables
    - Premium Fanless Latops
    - Premium Modern T&L Latops
  ?? LNL Archiecture
  >>>> â” Lunar Lake Architecture

âš“ Board Support Package (BSP) https://en.wikipedia.org/wiki/Board_support_package
BSP? LPDRR5x x64, LPDRR6x x64
SoC ë„ì‹í™”ëœ ê·¸ë¦¼?
AEP
  ì£¼ë¡œ ì¸í…”ì˜ Optane DC Persistent Memory ê¸°ìˆ ê³¼ ê´€ë ¨ëœ ìš©ì–´ë¡œ, Apache Passë¼ëŠ” ì½”ë“œëª…ì„ ê°€ì§€ê³  ìˆëŠ” Intel's Optane DC Persistent Memory (AEP: Apache Pass)
System on a chip (SoC) ; System on a chip

* Motherboard. ì•/ë’·ë©´
  Heat sync.. IO Module.., 
  ë…¸íŠ¸ë¶ì—ì„œ ì£¼ë¡œ ì—´ë‚˜ëŠ” ë¶„, Soc, ë©”ëª¨ë¦¬, íŒŒì›Œ
* Die = Tile?
ğŸ†š Chips vs Dies, Chiplets vs Dielets
  The terms Chiplets and Dielets, are frequently used interchangeably but strictly speaking the suffix â€œletâ€ indicates a diminutive size typically below 100mm2. Chips refer either to the design IP or to the packaged dies. Dies typically mean bare singulated instantiations of the chip design that are not packaged

  https://www.reddit.com/r/chipdesign/comments/1e9izse/chips_vs_dies_vs_chiplets_vs_dielets/?rdt=41376
  ë©”ëª¨ë¦¬ê°„ CPU ê°„ì˜ ì„¤ê³„ë¥¼ ì˜í•´ì•¼í•œë‹¤. ì•ˆê·¸ëŸ¬ë©´ ë©”ëª¨ë¦¬ ì„±ëŠ¥ì´ ê¹ì¸ë‹¤. ë‘˜ì´ ëª¨ë‘ ê°€ê¹Œìš°ë©´ ì¢‹ê² ì§€ë§Œ..
    í•­ìƒ ì´ ë¶€ë¶„ì´ ë¬¸ì œë¼ê³  í•œë‹¤.
  ì‚¼ì„±ë„ íŒ¨í‚¤ì§•ì„ ì˜í•œë‹¤ê³  í•œë‹¤. ê·¼ë° CPU ë¥¼ ì˜ëª»ë§Œë“¦. intel, Tsmc ëŠ” ì˜ ë§Œë“¦.
  Tsmc: 5nano, 10nano ë¥¼ ì˜í•œë‹¤ê³ í•œë‹¤. 7anano,  >> tsmc 3 nano.. ? ë°˜ë„ì²´ ìˆ˜ìœ¨ (Yield) ì´ ì•ˆì¢‹ì•„ì„œ ê³ ë¯¼í•˜ê³  ìˆë‹¤ê³  í•œë‹¤. ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ì¹©ì˜ ë¹„ìœ¨.
  intel: 14nano (5ë…„ ì „).. ì„ ì˜í•œë‹¤ê³  í•œë‹¤.

AI ì—°ì‚°ì„ í•˜ê²Œ ë˜ë©´
  Relo, Convolution --> framework ì—ì„œë¶ˆëŸ¬ì£¼ëŠ” API ì¼ ë¿ì´ê³ .
    ì‹¤ì œë¡œ ì»´í“¨í„° ë‚´ë¶€ì—ì„œëŠ” 3*3 -> ...
    CPU ëŠ”.. ê³±í•˜ê³  ë”í•˜ê³ .. ì´ 4ë²ˆ? ì´ í•„ìš”í•˜ë‹¤ê³  í•œë‹¤.
    GPU ê°™ì€ ê²½ìš°ëŠ”: ...
      GPU ì•ˆì—ëŠ” ì‹¤ì œë¡œëŠ” GPGPU ë¥¼ ì“´ë‹¤ê³  í•œë‹¤. SIMD single instruction, muli data ë¥¼ ì§€ì›?
    NLP: 
  GPGPU (General-Purpose computing on Graphics Processing Units)
  ì‚¬í”¼ì˜¨ì´ ë¦¬ë²¨ë¦¬ì˜¨í•œí…Œ í†µí•©ì´ ë¬ê³  í“¨ë¦¬ì˜¤ëŠ” ì•„ì§ ì¢‹ì€ ì„±ëŠ¥ì„ ëª»ë‚´ê³  ìˆë‹¤ê³  í•¨.
  â“ ë©´ì ‘: CPU GPGPU, NPU ì—°ì‚°.. ë‚´ë¶€ ì¥ì¹˜, TPU
  ã„±ê¸°ì¡´ì˜ pytorch ë¡œ í•˜ë©´ one-stinrctuon - one-instruction ì´ì—‡ì§€ë§Œ
    ã…ã…ë‚˜ í•˜ë‚˜ë”ã…ê³  ê³±í•˜ê³  ê³±í•˜ê³ .. 
    ëª‡ê°€ì§€ ì—°ì‚°ì„ í•˜ë‚˜ì˜ instruction..
    Compute Tile 2D
    OpenVino ë¥¼ ì“°ë©´ ì´ê±°ë¥¼ í•œë²ˆì˜ ëª…ë ¹ì— ì—¬ëŸ¬ ê°œì˜ ì—°ì‚°ì„ ì ìš©í•  ìˆ˜ ìˆë‹¤ê³  í•œë‹¤.
    oficcialy, OpenVino ëŠ” ì¸í…”ì—ì„œë§Œ ëŒì•„ê°„ë‹¤ê³  í•œë‹¤.
  
    Lunar LakeëŠ” **ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬(Microcontroller)**
      https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units
    
GPG key 
  âš“ https://en.wikipedia.org/wiki/GNU_Privacy_Guard
WARNING:absl:You are saving your model as an HDF5 file via model.save() or keras.saving.save_model(model). This file format is considered legacy. We recommend using instead the native Keras format, e.g. model.save('my_model.keras') or keras.saving.save_model(model, 'my_model.keras')
  abslì€ Abseilì´ë¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì•½ìì…ë‹ˆë‹¤. ì´ëŠ” Googleì—ì„œ ì œê³µí•˜ëŠ” Python ë¡œê¹… ë° ìœ í‹¸ë¦¬í‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, Kerasì—ì„œ ëª¨ë¸ ì €ì¥ ì‹œ ê²½ê³  ë©”ì‹œì§€ë¥¼ ë¡œê¹…í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. Abseilì€ ë¡œê·¸ ì²˜ë¦¬ì™€ ê°™ì´ í‘œì¤€ ë¡œê¹…ì„ ë³´ë‹¤ í™•ì¥ëœ ê¸°ëŠ¥ìœ¼ë¡œ ì œê³µí•˜ê¸° ìœ„í•´ ì¢…ì¢… ì‚¬ìš©ë©ë‹ˆë‹¤.
  
  
â“ ë©´ì ‘: ë„¤íŠ¸ì›Œí¬ ip ì£¼ì†Œ, ì„œë¸Œë„· ë§ˆìŠ¤í¬, ê²Œì´íŠ¸ì›¨ì´
https://rufus.ie/ko/

precetron? CNN, RNN ~ LLM ~ OpenVINO


SEO / íŒ¨ì‹¯?

Install List
  from class room..
      sudo apt install -y vim git-all htop net-tools tree mplayer mesa-utils  

  OpenVIno
    # https://docs.openvino.ai/2024/get-started/install-openvino.html
    ğŸª %shell> 
      wget https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB
      sudo cp GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB /etc/apt/trusted.gpg.d/intel-sw-products.gpg
      echo "deb https://apt.repos.intel.com/openvino/2023 ubuntu22 main" | sudo tee /etc/apt/sources.list.d/intel-openvino-2023.list
      sudo apt update -y
      apt-cache search openvino
      sudo apt install -y openvino


  Whale
    ğŸª %shell> 
      wget https://installer-whale.pstatic.net/downloads/installers/naver-whale-stable_amd64.deb -O /tmp/naver-whale-stable_amd64.deb && \
      sudo dpkg -i /tmp/naver-whale-stable_amd64.deb
    ğŸš¨ (issue): bug; ğŸ“… 
    Unintsall; %shell> sudo apt remove -y naver-whale-stable

  Telegram
    ğŸª %shell> sudo snap install telegram-desktop
  zoom
    ğŸª %shell> sudo snap install zoom-client
    https://snapcraft.io/zoom-client
wget -O - https://raw.githubusercontent.com/p1ratrulezzz/telegram-linux-installer/master/telegram-installer.sh | bash

\\INTEL-TEACHER\shared

\\10.110.16.180
\\10.10.16.180

sudo apt update
sudo apt install ibus ibus-hangul
ibus-setup
ibus restart
ì„¤ì • ë©”ë‰´ì—ì„œ Settingsë¥¼ ì—½ë‹ˆë‹¤.
Region & Language ë©”ë‰´ë¡œ ì´ë™í•©ë‹ˆë‹¤.
Input Sourcesì—ì„œ + ë²„íŠ¼ì„ í´ë¦­í•˜ê³ , **Korean (Hangul)*
/// ì´ë ¥ì„œ  /ì„±ì ì¦ëª…ì„œ


Commands
  ls -al         # == ll    â“ 

ğŸ“°ğŸ‘ Snapì€ ë¦¬ëˆ…ìŠ¤ì—ì„œ ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ íŒ¨í‚¤ì§•í•˜ê³  ë°°í¬í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì…ë‹ˆë‹¤. Canonical (ìš°ë¶„íˆ¬ë¥¼ ê°œë°œí•˜ëŠ” íšŒì‚¬)ì—ì„œ ê°œë°œí•œ ì´ ê¸°ìˆ ì€ ì—¬ëŸ¬ ë¦¬ëˆ…ìŠ¤ ë°°í¬íŒì—ì„œ ë™ì¼í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì¼ê´€ë˜ê²Œ ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤. Snapì˜ ì£¼ìš” íŠ¹ì§•ê³¼ ì¥ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
snap install telegram-desktop   # https://en.wikipedia.org/wiki/Snap_(software)
  https://github.com/canonical/snapcraft
  https://snapcraft.io/store
  e.g.
    snap find editor
    snap install telegram-desktop



https://telegram.org/dl/desktop/linux
pip install jupyter

(how); firefox, open the new tab with same url
  Alt + D ë˜ëŠ” F6ì„ ëˆŒëŸ¬ ì£¼ì†Œ í‘œì‹œì¤„ë¡œ ì»¤ì„œë¥¼ ì´ë™í•©ë‹ˆë‹¤.
  Alt + Enterë¥¼ ëˆ„ë¥´ë©´ í˜„ì¬ íƒ­ì˜ ë§í¬ê°€ ìƒˆ íƒ­ì—ì„œ ì—´ë¦½ë‹ˆë‹¤.

  ì´ê±°ëŠ” ëª¨ë“  ë¸Œë¼ìš°ì € ê³µí†µì´ì•¼?
  Popup View for Googleâ„¢ Translate ; https://addons.mozilla.org/ko/firefox/addon/dictionary-anywhere/


========= ì™•ì„±ì‹ êµìˆ˜ë‹˜
=========-- ë°±ì¬ìš° êµìˆ˜ë‹˜   // ìˆ˜ì¹˜í•´ì„/ìˆ˜í•™
=========-- ê¹€ì„±ê·¼ êµìˆ˜ë‹˜   // ì»´í“¨í„° ë¹„ì „

AI
  Perceron ; https://en.wikipedia.org/wiki/Perceptron
  CNN ; https://en.wikipedia.org/wiki/Perceptron
    ë¥´ë„¤ë¶€í„°?
  RNN ; https://en.wikipedia.org/wiki/Recurrent_neural_network
  LSTM ; https://en.wikipedia.org/wiki/Long_short-term_memory
  LLM ; https://en.wikipedia.org/wiki/Large_language_model
    Transofmrer, GPT, Attension..?

  YOLO(You Only Look Once) ; https://arxiv.org/abs/1506.02640
  
  OpenVINO notebook
    iGPU
  Openmodel zoo

  Smart Factory
    Arduino/ Mult-threading_OTX/Smart Factory
    Simulation/Handson
  Team Project
    CVAT&OTX
    MSA ì„¤ê³„
    Computer visionAI ê¸°ìˆ  ë™í–¥
    BSPã„µ ë‘í–ã…œã„·ã„·ã„± wjsakd
    LLM design guide
    ê°œë°œ procses
    ì·¨ì—… ë©˜í† ë§
    ë°œí‘œ ì˜í•˜ëŠ” ë°©ë²•
    ìµœì¢… ì ê²€
    careeer ë©´ë‹´.
Ubuntu GNONE terminal (Default)
Ubuntu File explorer Nautilus (default)
  Ubuntu Shortcuts
    í´ë”ë¥¼ ë¶ë§ˆí¬ë¡œ ë“±ë¡. Ctrl + D  (íŒŒì¼ ìµìŠ¤í´ëŸ¬ëŸ¬ ì•ˆì—ì„œë§Œ ê°€ëŠ¥)
Ubuntu Shortcuts (ë“±ë¡ í•„ìš”)
  Keyboard Shortcuts - View and Customize Shortcuts
  Keyboard Shortcuts - Launchers
    Home folders - Super+E
Ubuntu Settings - Printer install. type;     .ppd; PostScript Printer Description
  í”„ë¦°í„° ê¸°ëŠ¥ ì„¤ëª…, í”„ë¦°í„° ì˜µì…˜ ì œê³µ, í”„ë¦°í„°ì™€ì˜ í˜¸í™˜ì„±

spike neural network?
ë‰´ë¡œëª¨í”½ 
VCS
  %shell>
    cat ~/.gitconfig
  Software Development Lifecycle
    Requirement;  Speicifcation
    Design; Architecture
    Development
    Test; Quality
    Deployent; Release
    Maintenance;   Hotfix
  Centralized VCS vs. Distributed
  What is Git ğŸ“°.. ëª¨ë‘ ì„¤ëª…..
    git add... stage, un-stage, working-dir
    git status     vs git log
      git log --oneline
    git reset hard, soft, mixd and revert
      ğŸ’¡ ê´€ì ì´: HEAD Poitner, commit history, staging area, working directrory .. 4ê°œë¡œ ë‚˜ë‰¨.
    git log --graph --decorate --abbrev-commit --all --pretty=oneline

  ğŸ“° Non-bare repository vs. Bare repository
    client-side vs server side?.. ã…‡ã…‡.. bare repo ëŠ” í´ë¡ ë„ ê°€ëŠ¥.
  ğŸ’¡ GitHub CLI ; https://cli.github.com/
    Install ; https://github.com/cli/cli/blob/trunk/docs/install_linux.md
    gh auth login
    https://cli.github.com/manual/gh_repo_create
    gh repo create <repository-name> --public --source=. --remote=origin
    gh repo view <repository-name>
      gh repo view intel-05
    github milestone.. issue.. // Milestoneì€ íŠ¹ì • ê¸°í•œ ë˜ëŠ” ëª©í‘œë¥¼ ì„¤ì •í•´ ì—¬ëŸ¬ Issueë¥¼ ë¬¶ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.
      // ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ì§€?
    git pull --rebase     vs .. git upll == get fetch + git merge
      A --- B --- C   (main)          # ë¡œì»¬ ë¸Œëœì¹˜ ìƒíƒœ
             \
              D --- E   (origin/main)  # ì›ê²© ë¸Œëœì¹˜ ìƒíƒœ

      A --- B --- D --- E --- C'   (main, origin/main)

  https://www.gnu.org/software/bash/manual/bash.html#index-HISTSIZE

  >>> https://tally.so/r/w7D05A
    git stash       # == git stash push
    git stash push -m ""    # stash ì´ë¦„ ì§€ì •

    git stash list
    git stash apply
    git stash pop
    git stash drop

    ê°€ì¥ ìµœê·¼ stashëŠ” stash@{0}
    git stash clear


vim
  i       ì‚½ì… ëª¨ë“œ
  :       ëª…ë ¹ì–´ ëª¨ë“œ
    :wq   ì €ì¥í•˜ê³  ì¢…ë£Œ
    :q!   ì €ì¥í•˜ì§€ ì•Šê³  ê°•ì œ ì¢…ë£Œ
  ESC     ëª¨ë“œ ì¢…ë£Œ
gnone terminal
redirction ; https://www.gnu.org/software/bash/manual/html_node/Redirections.html
  >   write       // Redirecting Output
  >>  append      // Appending Redirected Output
ë§ˆì¼ìŠ¤í†¤
PR:
  Development
  Successfully merging this pull request may close these issues.

ğŸª± OAuth ë™ì‘ ë°©ì‹:
  ì‚¬ìš©ì ê¶Œí•œ ìš”ì²­: rclone ê°™ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì‚¬ìš©ìì˜ Google Drive íŒŒì¼ì— ì ‘ê·¼í•˜ë ¤ê³  í•  ë•Œ, Googleì€ ì‚¬ìš©ìì—ê²Œ í•´ë‹¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ê¶Œí•œì„ ë¶€ì—¬í• ì§€ ë¬»ìŠµë‹ˆë‹¤.
  ì‚¬ìš©ì ë™ì˜: ì‚¬ìš©ìê°€ ê¶Œí•œì„ ë¶€ì—¬í•˜ë©´, Googleì€ í•´ë‹¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì— Access Tokenì„ ë°œê¸‰í•©ë‹ˆë‹¤. ì´ í† í°ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì‚¬ìš©ìì˜ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•´ì¤ë‹ˆë‹¤.
  Access Token ì‚¬ìš©: ë°œê¸‰ë°›ì€ í† í°ì„ í†µí•´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ Google APIì— ì ‘ê·¼í•´ ë°ì´í„°ë¥¼ ìš”ì²­í•˜ê³  í•„ìš”í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  ë¦¬í”„ë ˆì‹œ í† í°: Access Tokenì€ ë§Œë£Œë˜ê¸° ë•Œë¬¸ì—, ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ë¦¬í”„ë ˆì‹œ í† í°ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ Access Tokenì„ ì–»ì–´ ì§€ì†ì ì¸ ì ‘ê·¼ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  * Oauth Client
    Role of the OAuth Client: Why is it called "Client" and not "Server"?
    OAuth Client typically refers to an application that requests data from a resource server (e.g., Google Drive). The term "client" is used because the application plays the role of the client in the OAuth process.

    Concept Explanation:
      OAuth Client: The entity requesting data (the application, e.g., rclone).
      OAuth Server (Authorization Server): The server responsible for authentication and authorization (e.g., Google OAuth server).
      Resource Server: The server that provides the actual data the client is trying to access (e.g., Google Drive).

    The OAuth Client accesses the resource server on behalf of the user and obtains an Access Token from the OAuth Server, which is then passed to the resource server. Therefore, the OAuth Client is the one requesting authentication and authorization, while the OAuth Server grants the authorization.
      The client is the user's application (e.g., rclone, Gimp) that requests permission via OAuth to access data on behalf of the user.
      The server is a service like Google or GitHub that grants this permission.

    Thus, the OAuth Client requests authorization from the server and retrieves data, making it appropriate to call it a "client."

ğŸ“– Book: íŒŒì´ì¬ìœ¼ë¡œ ë°°ìš°ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ êµê³¼ì„œ // ì´í†  ë§ˆì½”í†  ì§€ìŒ. ë°•ê´‘ìˆ˜(ì•„í¬ëª¬ë“œ) ì˜®ê¹€. í•œë¹›ë¯¸ë””ì–´, SE SHOEISHA
  
  http://www.hanbit.co.kr/src/10124


Bash Shellì—ì„œ Gimpë¥¼ ì‹¤í–‰í•˜ê³ , Shellì„ ì¢…ë£Œí•´ë„ Gimpê°€ ì¢…ë£Œë˜ì§€ ì•Šë„ë¡ í•˜ëŠ” ë°©ë²•
  gimp  &
    dis own # ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ìŠ¤ë¥¼ í˜„ì¬ ì‰˜ ì„¸ì…˜ì—ì„œ ë¶„ë¦¬í•˜ì—¬, Shellì„ ì¢…ë£Œí•´ë„ Gimpê°€ ì¢…ë£Œë˜ì§€ ì•Šë„ë¡ ë§Œë“¦

  nohup  gimp &    # í”„ë¡œê·¸ë¨ì„ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰í•˜ë©´ì„œ ê·¸ í”„ë¡œì„¸ìŠ¤ë¥¼ no hang-up (ì‰˜ ì¢…ë£Œ) ë¡œë¶€í„° ë³´í˜¸.
  setsi d gimp &   # setsid ëª…ë ¹ì€ í”„ë¡œê·¸ë¨ì„ ìƒˆë¡œìš´ ì„¸ì…˜ì—ì„œ ì‹¤í–‰í•˜ê¸° ë•Œë¬¸ì—, ë¶€ëª¨ Shellê³¼ ê´€ê³„ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.

Math
  ğŸª± Coprime integers; https://en.wikipedia.org/wiki/Coprime_integers
    In number theory, two integers a and b are coprime, relatively prime or mutually prime
  ì´ˆì›”í•¨ìˆ˜ ; https://en.wikipedia.org/wiki/Transcendental_function
    **ë‹¤í•­ì‹(Polynomial)**ì€ í•˜ë‚˜ ì´ìƒì˜ ë³€ìˆ˜ì™€ ê·¸ ë³€ìˆ˜ì— ëŒ€í•œ **ê³„ìˆ˜(coefficient)**ë¡œ êµ¬ì„±ëœ ì‹ìœ¼ë¡œ, ë³€ìˆ˜ì˜ ì§€ìˆ˜ê°€ ìŒìˆ˜ë‚˜ ë¶„ìˆ˜ê°€ ì•„ë‹Œ ìì—°ìˆ˜ë¡œ ì œí•œë©ë‹ˆë‹¤..
  
  ë‹¤í•­ì‹ì´ ì•„ë‹Œ í•¨ìˆ˜ë“¤
    ì§€ìˆ˜í•¨ìˆ˜ exex: ë³€ìˆ˜ê°€ ì§€ìˆ˜ì— ìˆëŠ” í•¨ìˆ˜ëŠ” ë‹¤í•­ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.
      ì§€ìˆ˜í•¨ìˆ˜ëŠ” ë°‘ì´ ì¼ì •í•œ ìƒìˆ˜ì´ê³ , **ì§€ìˆ˜(ì œê³±í•˜ëŠ” ê°’)**ê°€ ë³€ìˆ˜ë¡œ ì£¼ì–´ì§€ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤
    ë¡œê·¸í•¨ìˆ˜ lnâ¡(x)ln(x): ë³€ìˆ˜ê°€ ë¡œê·¸ ì•ˆì— ìˆìœ¼ë©´ ë‹¤í•­ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.
    ì‚¼ê°í•¨ìˆ˜ sinâ¡(x),cosâ¡(x)sin(x),cos(x): ì£¼ê¸°ì ì¸ í•¨ìˆ˜ëŠ” ë‹¤í•­ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.
    ë¶„ìˆ˜ í•¨ìˆ˜ 1xx1â€‹: ì§€ìˆ˜ê°€ ìŒìˆ˜ì¸ ê²½ìš° ë‹¤í•­ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.
  ì˜¤ì¼ëŸ¬ ìƒìˆ˜ e
  ğŸª± Euler's totient function
    Ï• ê¸°í˜¸: Ï•(íŒŒì´ ë˜ëŠ” í”¼)ëŠ” ê·¸ë¦¬ìŠ¤ ë¬¸
    ì˜¤ì¼ëŸ¬ì˜ í”¼ í•¨ìˆ˜(Euler's Totient Function, Ï•(n))ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” íŠ¹ì • ì •ìˆ˜ në³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì€ ì–‘ì˜ ì •ìˆ˜ ì¤‘ì—ì„œ nê³¼ ì„œë¡œ ì†Œ(ì¦‰, ìµœëŒ€ê³µì•½ìˆ˜ê°€ 1ì¸)ì¸ ìˆ˜ì˜ ê°œìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    ë§Œì•½ n=9n=9ì¸ ê²½ìš°, 9ì™€ ì„œë¡œ ì†Œì¸ ìˆ˜ëŠ” 1, 2, 4, 5, 7, 8ì´ë¯€ë¡œ Ï•(9)=6Ï•(9)=6ì…ë‹ˆë‹¤.
      >>> ì•”í˜¸í•™ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ë©°, RSA ì•Œê³ ë¦¬ì¦˜ê³¼ ê°™ì€ ì•”í˜¸ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.
  totient ; https://en.wiktionary.org/wiki/totient
    (mathematics) The number of positive integers not greater than a specified integer that are relatively prime to it.
  ğŸª± relatively prime ; https://en.wiktionary.org/wiki/relatively_prime#English
    (mathematics, of a number) having no factors (except the number 1) in common with a specified other number or numbers.
      e.g. 24 is relatively prime to 35.


Gaussian function ; https://en.wikipedia.org/wiki/Gaussian_function
ìŠ¤ì¹¼ë¼, ë²¡í„°
  https://en.wikipedia.org/wiki/Dot_product
    In mathematics, the dot product or scalar product[note 1] is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors), and returns a single number. 


  scalar: ì–‘
    ì£¼ë¡œ ê¸°ìš¸ì´ì§€ ì•Šì€ ì¼ë°˜ í…ìŠ¤íŠ¸ë‚˜ ì´íƒ¤ë¦­ì²´ë¡œ í‘œê¸°ë¨.
  vector: í¬ê¸°ì™€ ë°©í–¥
    ì£¼ë¡œ êµµì€ í…ìŠ¤íŠ¸ë‚˜ í™”ì‚´í‘œ í‘œì‹œë¡œ ë‚˜íƒ€ëƒ„
    ë‹¨ìœ„ ë²¡í„°? ë²¡í„°ë¥¼ ê·¸ í¬ê¸°ë¡œ ë‚˜ëˆˆ ê°’.
    
    inner product (ë‚´ì )
      ë‚´ì ì˜ ê²°ê³¼ê°’ì€ ìŠ¤ì¹¼ë¼.
    outer product
      ì™¸ì ì˜ ê²°ê³¼ê°’ì€ ë²¡í„°
    
    íˆ¬ì˜?
    ë²¡í„°ì˜ ì—°ì‚°
  
  Derivatives
  í¸ë¯¸ë¶„? ì°¨ì›ì„ ëŠ˜ë¦°ë‹¤? multivariable of partial derivatives... partial? round?

  dell =.. round x Gradient : Derviative of vector.. 
  gradient f.. n ì°¨ì›..
  íˆ¬ëª…ì ???


  https://marketplace.visualstudio.com/items?itemName=shd101wyy.markdown-preview-enhanced
  
  í€´ë²„?.. ì´ graidant ì˜ ë°©í–¥?
  https://shd101wyy.github.io/markdown-preview-enhanced/#/



4. í–‰ë ¬ê³± (Matrix Multiplication)
  í–‰ë ¬ê³±ì€ ì—¬ëŸ¬ ë³€ìˆ˜ë¥¼ ë™ì‹œì— ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì—°ì‚°ì…ë‹ˆë‹¤. ê·¸ë¦¼ì—ì„œ, ì‘ì€ 2x2 í–‰ë ¬ê³¼ ë²¡í„°ì˜ ê³±ì…ˆì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ì—°ì‚°ì€ ê³µê°„ ë³€í™˜ì´ë‚˜ ì‹œìŠ¤í…œì˜ ë³µì¡í•œ ê³„ì‚°ì„ ì²˜ë¦¬í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
  ì˜ˆì‹œ:
  ì»´í“¨í„° ê·¸ë˜í”½ìŠ¤ì—ì„œ 3D ëª¨ë¸ì„ íšŒì „í•˜ê±°ë‚˜ í¬ê¸°ë¥¼ ì¡°ì •í•  ë•Œ í–‰ë ¬ê³±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 3D ëª¨ë¸ì˜ ì¢Œí‘œë¥¼ ì €ì¥í•œ í–‰ë ¬ê³¼ íšŒì „ ë³€í™˜ì„ ë‚˜íƒ€ë‚´ëŠ” í–‰ë ¬ì„ ê³±í•˜ë©´, íšŒì „ëœ ê°ì²´ì˜ ìƒˆë¡œìš´ ìœ„ì¹˜ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Sigmoid function = ?? 
  1/(1 + e^(-z))



https://en.wikipedia.org/wiki/Gaussian_function

"ì–‘ì ì»´í“¨íŒ…ì— ëŒ€í•´ ì„œë¡ , ì •ì˜, ìˆ˜í•™ì  ì˜ë¯¸, ì‘ìš©, í•´ì„, ê²°ë¡ ì˜ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±í•´ì¤˜."


Testing.. Pylance Vscode
  "markdown-preview-enhanced.previewTheme": "github-dark.css",
  "python.analysis.inlayHints.callArgumentNames": "all",

â“>>>>>>>>>..........? ë¹„ì „ê³¼ì œí•œê±° resource/ í´ë” ì‚¬ë¼ì§;;;...




https://tramamte.github.io/2018/07/ /rsa/
ì¤‘êµ­ì¸ì˜ ë‚˜ë¨¸ì§€ ì •ë¦¬

ğŸ‘ https://marketplace.visualstudio.com/items?itemName=James-Yu.latex-workshop
  1. install Late xWorkshop
  2. The only requirement is a compatible LaTeX distribution in the system PATH. For example, TeX Live. We strongly recommend TeX Live. Other possible choices are:
    https://www.tug.org/texlive/
    sudo apt install -y texlive-full fonts-noto-color-emoji

  3. restart VSCode
    Notice that you have to restart VS Code and the operating system after changing the variable.
https://www.overleaf.com/learn/latex/Questions/Inserting_emojis_in_LaTeX_documents_on_Overleaf
  Why Itâ€™s Hard to Render Emojis Without \emoji{}:
    LaTeX's Text Rendering: Unlike modern word processors, LaTeX is very strict about font handling. Each character must be assigned a specific font that contains the glyph (in this case, the emoji). Without specific commands, LaTeX wonâ€™t switch between fonts automatically.
    Font Overriding: Even though fonts like Noto Sans CJK KR support a wide range of characters, they don't include emoji glyphs, which is why LaTeX needs explicit instructions to switch to Noto Color Emoji or a similar font when rendering emoji characters.



Cannot view file PDF file. File not found: file:///home/wbfw109v2/repo/intel-edge-academy-6/note/sorted_note/test.pdf
ğŸš¨ error: Recipe terminated with fatal error: spawn latexmk ENOENT.
  latexmk ë„ ì„¤ì¹˜ ã…£ã„¹ìš”í•œë“¯



ğŸš¨ error
  VSCode + LaTeX Workshopì˜ ê¸°ë³¸ LaTeX ì—”ì§„ì€ **pdflatex**ì…ë‹ˆë‹¤. ì´ ì—”ì§„ì€ ëŒ€ë¶€ë¶„ì˜ ê²½ìš°ì—ì„œ ì‘ë™í•˜ì§€ë§Œ, Unicode ì§€ì›ì´ í•„ìš”í•˜ê±°ë‚˜ fontspec ê°™ì€ íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” XeLaTeX ë˜ëŠ” LuaLaTeXë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.

  XeLaTeX ë˜ëŠ” LuaLaTeX
  
  Compiling
    Building the document
      LaTeX recipes
        https://github.com/James-Yu/LaTeX-Workshop/wiki/Compile#latex-recipes
  í•œê¸€, ì˜ì–´ ì§€ì›í•˜ëŠ” ë¬´ë£Œ í°íŠ¸.. êµ¬ê¸€ 
    2. NotoNoto Sans CJK KR
    // how to usage
    \usepackage{fontspec} % XeLaTeX ë˜ëŠ” LuaLaTeXì—ì„œ í°íŠ¸ ì‚¬ìš©ì„ ìœ„í•´ í•„ìš”
    % Noto Sans CJK KR í°íŠ¸ ì„¤ì •
    \setmainfont{Noto Sans CJK KR}

    \usepackage{fontspec} % í°íŠ¸ ì„¤ì •ì„ ìœ„í•´ í•„ìš”
    \setmainfont{Noto Sans CJK KR} % Noto Sans CJK KR í°íŠ¸ ì‚¬ìš©
    \usepackage{xcolor}   % ìƒ‰ìƒ ì„¤ì •ì„ ìœ„í•´ í•„ìš”
    % ë°°ê²½ìƒ‰ê³¼ ê¸€ììƒ‰ ì„¤ì •
    \pagecolor{black}  % í˜ì´ì§€ ë°°ê²½ì„ ê²€ì •ìƒ‰ìœ¼ë¡œ ì„¤ì •
    \color{white}      % ê¸€ììƒ‰ì„ í°ìƒ‰ìœ¼ë¡œ ì„¤ì •

ì•„ì´ë‹¤ìŠ¤ ì‹œìŠ¤í…œ.. ë ˆì´ë” ì‹œìŠ¤í…œ..


í¼í”Œë ‰ì„œ í‹°?

Gemini vs Omni..

AL/DL Momentum : chatGPT app for iOS
Zeta ; https://zeta-ai.io/ko    AI chatting bot service
  HER AI
AI ìœ ëª…í•œ ë…¼ë¬¸ë“¤ì´ ì»¨í¼ëŸ°ìŠ¤ statista. aiindex.org AI; (Source: Scopus.com, Crunchbase, VentureSource, Sand Hill Econometrics, Monster.com)

ImagNet large scale visual recognition
  2010 - NEC-UIUC Lin et al.
  2011 - XRCE Florent Perronnin, Jorge Sanchez
  2012 - AlexNet
  2013 - ZFNet
  2014 - GoogLeNet
  VGGNet (Second Winner)
  2015 - ResNet     // Alphago??
  2016 - GoogLeNet-v4
  2017 - SENet
AI is changing every market
  EMERGENCY RESPONSE
    Real-time emergency and crime response
  ENERGY
    Maximize production and uptime
  EDUCATION
    Transform the learning experience
  SMART CITIES
    Enhance safety, research, and more
  FINANCE
    Turn data into valuable intelligence
  HEALTH
    Revolutionize patient outcomes
  INDUSTRIAL
    Empower truly intelligent Industry 4.0
  MEDIA
    Create thrilling experiences
  RETAIL
    Transform stores and inventory
  SMART HOMES
    Enable homes that see, hear, and respond
  TELECOM
    Drive network and operational efficiency
  TRANSPORT
    Efficient and robust traffic systems

.. í”„ë¡¬í”„íŠ¸? í˜ë¥´ì†Œë‚˜ë¥¼ ë¶€ì—¬? AI??
ë¦´ë¦¬ìŠ¤ì—ì´ì•„ì´(Lilys AI) ; ìœ íŠœë¸Œ ìš”ì•½ AI
??? ë‰´ë¡œëª¨í”½ ì¹©, ë¡œì´íˆ, ë¼ë°” ..
LG ì—ë„ˆì§€ ì†”ë£¨ì…˜ - ë¶ˆëŸ‰í’ˆ ê²€ì‚¬ì—ì„œë„ AI ê°€ ì‚¬ìš©í•œë‹¤ê³  í•œë‹¤.

Sidewinder... ë¯¸ì‚¬ì¼.. ìë™ì¶”ì ? , Ultrasound.. ììœ¨ì£¼í–‰ ì„¼ì„œ.


Deep Learning Workflow (ìƒê°í•˜ê²Œ ë§Œë“¤ê¸°)
  1. Problem Definition
    - DL Type
      âœ” Classification
      âœ” Detection
      âœ” Segmentation
      âœ” ...

  2. Data Preparation
    - Datasets
      âœ” Obtain data (ex, images, video, audio)
      âœ” Annotation

  3. Training
    - In-house model
    - Open model
    - Model training

  4. Optimization (Training)
    - Training optimization
      âœ” Accuracy

  5. Deployment (Inference)
    - Inference optimization
      âœ” Deploy model on edge

  ë‹¨ê³„ êµ¬ë¶„:
  - Use Case
  - Date-prep
  - Training
  - Optimization
  - Deployment

Neural style transfer ??? Colorization



Training ì—ì„œ Foreward, Backward
YOLO: Real-Time Object Detection
  í”¼ì³ë§µ?..ì„ ë§Œë“ ë‹¤?

ì–¸ì œ optimization ì„ í•´ì•¼í•˜ëŠ”ê°€?
  - ë„ë©”ì¸ì´ ë°”ë€ŒëŠ” ê²½ìš°
  - FP16 vs FP32
Transfer learning
  Low-level Feature --> Mid-level featuer --> High-level Feature..
    



genetic algoirthm..


1950: Alan Turning - Turing test
1958: Frank Rosenblatt - perception
1969: Marvin Minsky - a book of 'Perceptrons'
  MLP ë¥¼ í•  ìˆ˜ ìˆëŠ”ê±´ ì•Œì•˜ì§€ë§Œ ë„ˆë¬´ ê³„ì‚°ëŸ‰ì´ ë§ì•„ì„œ.. Perceptron ëª¨ë¸ì— ëŒ€í•œ í•œê³„
    ANd, NANd, OR, XOr.. perceptronì´ ë¼ì¸í•˜ë‚˜ë¡œ 
1986: david rumelhart -> Multi Layer Perceptron (MLP)
  ê³„ì‚°ëŸ‰ì„ Back propagation ìœ¼ë¡œ ì¤„ì„.. ê·¼ë° ì•„ë¬´ë¦¬ ìŒ“ì•„ë„ ì„±ëŠ¥ì˜ í•œê³„ì ì´ ë³´ì„..
1998: Yann Lecun - LeNet-5
  Hidden layer ê°€ ê¹Šì–´ì§€ë©´ back propagation ì´ ì œëŒ€ë¡œ ì•ˆë¨.
  ë‹¤ ë•Œë ¤ë„£ì§€ ë§ê³ , ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•´ì„œ ë„£ì–´ë³´ì. ã…‡ã…‡ CNN ì„ ì œì•ˆí•¨
2012: Alex Krizhevsky - AlexNet
  GPU ë„ ì²˜ìŒ ì”€..

1986 (RNN.. recurrent í•œ êµ¬ì¡°ê°€ í¬í•¨ë¨..)
  -> LSTM -> Seq2Seq -> ATtention -> Transformer -> GPT-1 -> BERT -> GPT-3
  transformer .. ì›ë˜ëŠ” ë³‘ë ¬ ì²˜ë¦¬ê°€ ì•ˆë¬ë‹¤. ìœ„ì¹˜ì— ë”°ë¥¸ ì²˜ë¦¬..


Neuron in our rains..
  ì „ë‹¬ë˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì´ ë‰´ëŸ°..
  Unistab function, Sigmoid, Relu,
  Spiking neurl network ì—ì„œëŠ” ì´ë¥¼ ê·¸ëŒ€ë¡œ ë¬˜ì‚¬í•œë‹¤? integrate fire?
...
ë¶„í¬ì¬ì¡°ì •.
normalize.. ì—ì„œ ì…ì‹¤ë¡  ê°’?..
ê°ë§ˆ, ë² íƒ€.. scale, and shift..

class activation map CAM. Segmentation, object detection.. ë‹¤ìŒì£¼..


activation functino íŠ¹ì§•ì€: non-linear?í•´ì•¼í•œë‹¤
input -> Hypothesis
  relu ë„ "1" ì€ ì˜ë¯¸ê°€ ìˆë‹¤.
  ì¸¡ë©´ ì–µì œ íš¨ê³¼?
  ì…ì¶œë ¥ë‹¨ì„

ìµœëŒ€ gradiant ê°€ 0.25ë¼ì„œ sigmoid ëŠ” chaine rule ì„ ì ìš©í•˜ê¸° ì–´ë µë‹¤. ; gradiant vanishing
Hyperbolic Tangent (Tanh) ë„ ë§ˆì°¬ê°€ì§€.    // RNN ê³„ì—´ì€ ì´ë¥¼ ì“°ê³ , ?? ë‹¤ë¥¸ ê²ƒì€ RELU ë¥¼ ë§ì´ ì“´ë‹¤?ê³ í•œë‹¤?
  --> Batch normalization ?? ..
    >>>?? nobatch+ 
      nobatch+sig --> 
      batch ë¥¼ ì“°ë©´ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ëŠ˜ì–´ì„œ ì•ˆ ì“°ëŠ” ê²ƒì´ ë‚«ë‚˜?
    backpropagation ì—ì„œ weighting ì„ í•  ë•Œ ë¬¸ì œê°€ìƒê¸°ê¸° ëŒ€ë¬¸ì— í•´ ì¤Œ.
  ReLu ëŠ” graidant vanishing ë¬¸ì œê°€ ê±°ì˜ ë‚˜ì˜¤ì§€ ì•Šì§€ë§Œ 0 ì´í•˜ì—ì„œ ë„ˆë¬´ ë°˜ì‘ì´ ì—†ì–´ì„œ leakyReLU ë¥¼ ë§Œë“¤ì—‡ë‹¤.
  ë ˆì´ì–´ê°€ ê¹Šì„ ìˆ˜ë¡ ì—…ë°ì´íŠ¸ê°€ ì‚¬ë¼ì ¸ê°.
graidant vanishing... ??????
??? ë¯¸ë¶„ì˜ ë²¡í„°í˜•ì´ gradiant? 
Epoch& Iteration.. If batch size big (BGD?)
If Batch size is small(ã„¶ã…‡?)
batch ì‚¬ì´ì¦ˆë¥¼ í¬ê²Œ í•˜ëŠ”ê²ƒì´ ì¢‹ì§€ë§Œ, ë©”ëª¨ë¦¬ í•œê³„ìƒ...

ì•Œê³ ë¦¬ì¦˜ì˜ ë°©í–¥ì´ graidant ê°€ ì¤„ì–´ë“œëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì„ íƒí–ˆë‹¤. ë¼ì„œ gradiant decesnt ë¼ê³  ì´ë¦„ìœ¼ ì •í•¨.

    
underfitting, overfitting.. noise..
  eary_stopping
  ğŸ–ï¸ Dataset
    Train, Validation, Test
    4ì°¨ì› ë°ì´í„°.. Batch * Height * Wdight * Channel
    ?? CNNì€ 4ì°¨ì›ì´ê³  ANN ì€ 3ì°¨ì›??..
    ê·¸ë¦¼ í•´ì„.. "Epoch & Iteration & Batch"
dropout..


ì „ì¥ ì‹œìŠ¤í…œ ..?? ìë™ì²´. í˜„ëŒ€ìë™ì°¨.
  CAN signal
  í¬ëŸ¬ìŠ¤í„° ì‹œìŠ¤í…œ?
    My-come..? ë§ˆì´ì»´? 
    ì—¬ëŸ¬ê°€ì§€ í•˜ë“œì›¨ì–´ì ì¸ ì»¨íŠ¸ë¡¤ë„ í•˜ê³ , ì—¬ëŸ¬ê°€ì§€ can signal ë„ ì •ì˜í•˜ê³ ..
  ìë™ì°¨ì—ì„œ ì œì¼ ì¤‘ìš”í•œ ì´ìŠˆ.. battery drain..
    ì „ì¥ ì‹œìŠ¤í…œì— ìˆëŠ” mycom ë„ ë‹¤ êº¼ì§€ëŠ” ê²ƒì´ ë¬¸ì œ..

âŒ¨ï¸ Navigate Brackets
  Ctrl + Shift + \ 

  remove Brackets 
  Ctrl + Alt + BackSpace

ì „ììª½ì€ (Cì–¸ì–´) í†µì¼ë˜ì–´ìˆì§€ë§Œ
PLC ëŠ” ë‹¤ ë‹¤ë¥´ë‹¤ê³  í•¨.. (base ê°€ ê¸°ê³„ìª½ì´ë¼ ê·¸ëŸ¼..)
  Hypervisor ..

ì¤‘ê°„ íŒŒì¼ ë§Œë“¤ê³  pdf íŒŒì¼ë§Œ ë‹¤ë¥¸ ê³³ì— ë§Œë“¤ê²Œ í•˜ëŠ” ë°©ë²•
ìš°ë¤¼ë„ adam.. ì •ë„ 


âš“ Society of Automotive Engineers (SAE) International ; https://en.wikipedia.org/wiki/SAE_International
âš“ Self-driving car ; https://en.wikipedia.org/wiki/Self-driving_car
  #ï¸âƒ£ Definitions ; https://en.wikipedia.org/wiki/Self-driving_car#Definitions
    #ï¸âƒ£ SAE classification ; https://en.wikipedia.org/wiki/Self-driving_car#SAE_classification
Latex
  âš“ Wikibooks - Latex ; https://en.wikibooks.org/wiki/LaTeX/
    âš“ğŸ’¡ Mathematics ; https://en.wikibooks.org/wiki/LaTeX/Mathematics
      mathbf
  âš“ Official Latex ; https://www.latex-project.org/help/documentation/
    # Typesetting complex mathematics
      # Specifically targeting the typesetting of mathematics is:
        âš“ Userâ€™s Guide for the amsmath Package (Version 2.1) ; https://www.latex-project.org/help/documentation/amsldoc.pdf
  
  âš“ Emoji Docs ; https://ctan.math.washington.edu/tex-archive/macros/luatex/latex/emoji/emoji-doc.pdf

  VSCOde extension
  @ suggestions
    Inserting Greek letters



Sigmoid
  https://en.wikipedia.org/wiki/Sigmoid_function












Here's the revised LaTeX code with improved structure, avoiding redundancy and keeping a smooth flow between the points:

âš“ Parallelogram ; https://en.wikipedia.org/wiki/Parallelogram
  Area formula
ğŸ“° ë‹¨ì¼ ì§„ì‹¤ ê³µê¸‰ì›ìœ¼ë¡œ ë§Œë“¤ê³ ì‹¶ì€ë° .. ëª…ã…‡..


âš“ find ; https://www.gnu.org/software/findutils/manual/html_mono/find.html
  2.1 find Expressions ; https://www.gnu.org/software/findutils/manual/html_mono/find.html#find-Expressions
    The expression that find uses to select files consists of one or more ğŸª± primaries, each of which is a separate command line argument to find.
    An expression can contain any of the following types of primaries: 
      ... ğŸª± actions
        have side effects and return a true or false value; and  ...
  3.3.2 Multiple Files
    Action: -execdir command {} +; https://www.gnu.org/software/findutils/manual/html_mono/find.html#index-_002dexec-1
      This insecure variant of the â€˜-execdirâ€™ action is specified by POSIX.
      The main difference is that the command is executed in the directory from which find was invoked, meaning that â€˜{}â€™ is expanded to a relative path starting with the name of one of the starting directories
      , rather than just the basename of the matched file. The result is always true. 
âš“ Function ; https://en.wikipedia.org/wiki/Function_(mathematics)
  unspecified function ...

Latex Engine
  https://en.wikipedia.org/wiki/LuaTeX
    https://www.luatex.org/
Latex auomation build tool; latexmk ; https://github.com/debian-tex/latexmk
  LATEX MaKe


ğŸ“°ğŸ“°ğŸ“°ğŸ“° TODO: Documentation
  ì¶”ê°€ë‚´ìš©ì„ í†µí•©í•˜ê¸°: ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•Šë„ë¡ ê¸°ì¡´ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ê³ , ìƒˆë¡œìš´ ì„¹ì…˜ë§Œ ì¶”ê°€
  ë‹¤ìŒ latex í…ìŠ¤íŠ¸ì— ì¶”ê°€ë‚´ìš©ì„ í†µí•©í•´ì¤˜.  ì ˆëŒ€ ì˜¤ë¥˜ë‚˜ì§€ ì•Šê²Œ í¬ë§·ì€ ìµœëŒ€í•œ ê±´ë“œë¦¬ì§€ë§ê³ 
  ê´„í˜¸ìˆ˜ë¥¼ ì˜ ì„¸ê³  ì˜ ë‹«ì„ ê²ƒ.
ê°ê°..ì˜ matrix ì•ˆì˜ ì„¸ë¶€..ë‹¨ì–´, veector- ê°€ ì»´í“¨í„°ë¹„ì „/ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ì–´ë–»ê²Œ ì“°ì´ëŠ”ì§€ ì‹¤ì œ ì¡°ì‚¬í•˜ê¸°.
ğŸ“°ğŸ“°ğŸ“°ğŸ“° TODO
  about_matrix.tex
    ê¸°íƒ€:
      ê³ ìœ ê°’ (Eigenvalue), ê³ ìœ ë²¡í„° (Eigenvector): w, v = np.linalg.eig(x)
			ê³ ìœ ê³µê°„,.. ì—­í–‰ë ¬ê³¼ì˜ ê´€ê³„..í–‰ë ¬ì˜ ëŒ€ê°í™”ì™€ì˜ ê´€ê³„.. (ê¸°ì¡´ì— ì»ë˜ê²ƒê³¼ í•©ì¹˜ê¸°?ë¶„ë¦¬í•˜ê¸°?)
				ë¬¼ì²´ê°€ ê°€ì§€ëŠ” ê³ ìœ í•œ ì„±ì§ˆì„ ì°¾ê¸° ìœ„í•´ ì‚¬ìš©í•¨. ã…‡ã…‡ ê³µëª…
      np.linalg....
      https://rfriend.tistory.com/163

  Perceptron & ANN
    AL/DL areas and applications: past, current, upcoming
    Multi-layer perceptron --> ìŒ“ì•„ì„œ ë§Œë“  ê²ƒì´ ANN?
    ë‰´ëŸ°ì„ ìˆ˜í•™ì ìœ¼ë¡œ ëª¨ë¸ë§í•œ ê²ƒ..
    ì•ŒíŒŒê³  í”„ë¡œê·¸ë¨.. êµ¬ê¸€ì˜ ë”¥ë§ˆì¸ë“œ?.. 2001ë…„ë¶€í„° í•œ í”„ë¡œê·¸ë¨
  GRadiant
    Gradient(âˆ‡) : Derivatives of vector..
  ë‡Œ ì† ì‹ ê²½ë§.. ë¯¸ì„¸í•˜ê²Œ ë–¨ì–´ì ¸ìˆë‹¤.. 
    inputs.. x_n --> weights.. wij -> transfer function (Sigma)... -> net input net_j ---> activation function(threshold seta_j) -----> activation (o_j(?))
    Activation Function..
      "ë¹„ì„ í˜„ì„±ì„ ë¶€ì—¬í•œë‹¤ëŠ” ê²ƒ" ì´ ë¬´ìŠ¨ ëœ»
  back propagation.. ì—ì„œ Chain rule ì“´ë‹¤ëŠ”ë°.. ë­”ì†Œë¦¬..
    weighting? ì´ ê³±í•´ì§„ë‹¤?...
    input -> .. caclulate the sigma?W from sigmaF ???
  ë”¥ëŸ¬ë‹.. matrix ì—ì„œ ì™œ ì°¨ì›ì„ ë†’ì—¬ì•¼ í•˜ëŠ”ê°€?.. ..
    ?? ìˆ«ì OCR í•™ìŠµì— ëŒ€í•œ ì˜ˆì‹œë¡œ...
    ?? ì°¨ì›ì„ ë†’ì¼ìˆ˜ë¡ ì¢‹ë‹¤? cube-root?
    Local Minima.. ?
      - loss contour of a VGG-56 DNN's loss function
    cost function.. ìš°ë¦¬ê°€ ë§Œë“¤ë ¤ê³  í•œ ëª¨ë¸ê³¼ ë°ì´í„° ì‚¬ì´ì˜ ì˜¤ì°¨ë¥¼ ë‚˜íƒ€ë‚¸ ê²ƒ?
    saddle points?.. maxima in antoher direcion, a minia in .. direction
    ì§êµì„±?
    ì§€ìˆ˜ ê¸°ì €í•¨ìˆ˜?
    ë‹¤ì°¨ì› ë²¡í„°ì˜ ë‚´ì 
      ë²¡í„° ê°„ì˜ ì—°ì‚°ì´ë¯€ë¡œ ì°¨ì›ì´ ê°™ì•„ì•¼ í•¨.
    matrix.. ë¡œ í™•ì¥í•˜ë©´ ì—¬ëŸ¬ ë²¡í„°ì˜ ë‚´ì ì„ í•œë²ˆì— ì§„í–‰ ê°€ëŠ¥?
      ?? N ê°œ batch
  ì„œë¡œì†Œ; relatively prime ..
    ì»¤ë„í–‰ë ¬ì„ ì¸ê³µì‹ ê²½ë§ í˜•íƒœë¡œ í‘œí˜„í•˜ë©´, í”¼ì³ë§µì„ ê° ê°€ì¤‘ì¹˜ê°€ ê³±í•´ì§„ ì±„ë„ì˜ í•©ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŒ

  ì‹ ê²½ë§: Tensor? ì „ë°©íŒ¨ìŠ¤? ë‚´ì ?
  íŒŒë¼ë¯¸í„° ë¼ëŠ” ì •ì˜ê°€..?
    ì´ë¯¸ì§€ë¡œ ì¹˜ë©´ ê°ê° i, j ì˜ ì¸ë±ìŠ¤ì˜ í•©??ì¸ê°€? ì¦‰ ê°œìˆ˜?
  Loss Function
    ì¢…ë¥˜
      í‰ê·  ì œê³± ì˜¤ì°¨(Mean Squared Error): íšŒê·€ ë¬¸ì œì—ì„œ ìì£¼ ì‚¬ìš©ë˜ë©°, ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ì˜ ì œê³±ì„ í‰ê· í•œ ê°’
      êµì°¨ ì—”íŠ¸ë¡œí”¼(Cross-Entropy): ë¶„ë¥˜ ë¬¸ì œì—ì„œ ìì£¼ ì‚¬ìš©ë˜ë©°, ì˜ˆì¸¡í•œ í™•ë¥  ë¶„í¬ì™€ ì‹¤ì œ ë¶„í¬ì˜ ì°¨ì´ë¥¼ ê³„ì‚°
    ìµœì í™”(Optimization)
      ìµœì í™”ëŠ” ì†ì‹¤ í•¨ìˆ˜ì˜ ê°’ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ëª¨ë¸ì˜ **ê°€ì¤‘ì¹˜(Weight)**ë¥¼ ì¡°ì •í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ ëª¨ë¸ì´ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ì˜ í•™ìŠµí•˜ê³ , ì˜ˆì¸¡ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      "ê°€ì¤‘ì¹˜".. ê°€ ì •í•™íˆ ë­ì§€? COEFFICIENTs ? ë²¡í„°?
      ì˜ˆ: ê²½ì‚¬ í•˜ê°•ë²•(Gradient Descent): ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ ì†ì‹¤ í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•˜ì—¬ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
  Liniear regression
    DOI (Data of interest)  ... e.g. squared error
    Value of interest (VOI) ... e.g. least ?

    find DOI data with VOI

    ?? What is cost function?
  Gradient Descent..
    cost function is convex function
    Goal
    A_k = Learning Rate / Step Size
    Delta?ì…ì‹¤ë¡ ? x(k): Search direction
    Adaptive Learning rate scheme
    ì…ì‹¤ë¡ ..

    Momentum descent algoirhtm
    Adagrad: 2011
      Division and square root applied element-wise .. means
    RMSprop: 2012
      ...deacy.. ì•„ì£¼ ì˜¤ë˜ì „ ê¶¤ì ì˜ ì˜í–¥ì„ ì¤„ì´ê³ , ê°€ê¹Œìš´ ì‹œê°„ì˜ ê¶¤ì ì˜ ì˜í–¥ì„ ë†’ì´ê¸° ìœ„í•´.. deacy ì¶”ê°€
    Adam 2014
      Hyper-parameter ì„¤ì •ì—ì„œ ê°€ì¥ roust í•˜ë‹¤ê³  ì•Œë ¤ì§.

  Min Sqaure error ë¥¼ Mean aboulste error ë¥¼ ì“°ëŠ” ì´ìœ ..

Validation set

RNN ì´ë‚˜ ì‹œê³„ì—´ ìª½ì€ batch ì „ì²´ë¥¼ í•œ ë²ˆì— ì§‘ì–´ë„£ì„ ìˆ˜ ì—†ë‹¤? ëŒ€í˜• ì–¸ì–´ ëª¨ë¸? serial
  ë°°ì¹˜ ì •ê·œí™”ê°€ ì•ˆëœë‹¤ëŠ”ê±´ê°€? layer normalization

  position encoading. ìœ„ì¹˜ê°€ ì–´ë””ìˆëŠ”ì§€ í‘œì‹œí•˜ëŠ”
  sigmoid ëŠ” ìµœëŒ€ gradiant ê°€ 0.25ë¼ì„œ ë°°ì¹˜ì •ê·œí™”ë¥¼ ì•ˆí–ˆì„ ë•Œ sigmoid ë¥¼ ì“°ê¸° vs ReLu
  
  A2 A1 Ax .. activation functino ì´ ì—†ìœ¼ë©´ layer ë¥¼ ì•„ë¬´ë¦¬ ì¨ë„ í•˜ë‚˜ë¥¼ ì“´ê±°ë¡œ ì¹˜í™˜í•  ìˆ˜ ìˆëŠ” ìƒí™©ìœ¼ë¡œ ë‚˜ì˜¨ë‹¤..
  ì„ í˜•ì ì¸ ê²ƒì„ ë¹„ì„ í˜•ì ìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ”..
  CNN Sequential model (keras) ì™œ conv2d ì´í›„ batchnomralization ì„ ê³„ì† ê°™ì´ í•´ì£¼ëŠ” ì´ìœ . 
    ì´ê±° í•  ë•Œë§ˆë‹¤ output shapeì™€ param size ëŠ” ì–´ë–¤ ê´€ê³„ê°€ ìˆëŠ”ê²ƒ?
  ë¯¸ë‹ˆ ë°°ì¹˜? ë°°ì¹˜, ë°°ì¹˜ ì •ê·œí™”, iteratio, epoch, learning rate, step size ì˜ ì°¨ì´ëŠ” ë˜ ë­ì•¼
    batch normzliation ì—ì„œ ë³€ìˆ˜ëŠ” 4ê°œ: í‰ê· , í‘œì¤€í¸ì°¨, ê°ë§ˆ, ë² íƒ€?
      mini-batch vs batch
    ì´ë¯¸ì§€ì™€ ë”¥ëŸ¬ë‹ ê´€ì ì—ì„œ Serialize?
      ê³µê°„ì ì¸ íŠ¹ì§•ì„ ì¶”ì¶œí•´ì„œ ë„£ì. í•´ì„œ ANN -> CNN ì´ ì¶”ê°€ë¨? Missing Spatial Relationship
      + ANN ì€ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ë‹¤ ë„£ì–´ì„œ(?ë§ë‚˜?) ë©”ëª¨ë¦¬ê°€ ë„ˆë¬´ ë§ì€ ì–‘ì„ ì‚¬ìš©í•´ì•¼í•œë‹¤.
      "Feature Engineering" ì´ ì°¨ì´ê°€ìˆìŒ ANN
        ANN ì€ plattern í•˜ê³  ì˜ë¼ì„œ ë²¡í„°ë¡œ ì´ì–´ë¶™ì¸ë‹¤??? ê·¸ë˜ì„œ íŠ¹ì§•ì´ ìª¼ê°œì§„ë‹¤.
        CNN ì€ ì»¨ë³¼ë£¨ì…˜..í•„í„°ë¥¼ ì‚¬ìš©í•´ì„œ ê³µê°„ì ìœ¼ë¡œ ì£¼ë³€ í”½ì…€ê³¼ ì—°ê´€ë„ê°€ ìˆë„ë¡ íŠ¹ì§• í•™ìŠµì´ ëœë‹¤.
  CNN: Spatially-local correlation . ì¸ì ‘ í”½ì…€ ê°„ ë†’ì€ ìƒê´€ê´€ê³„
    Invariant feature? ..ì‚¬ì§„ ì¢Œìš° ë°˜ì „ì‹œì—ë„ íŠ¹ì§• ë˜‘ê°™ìŒ.. ì˜ˆ: ê·€?
    >> í•©ì„±ê³± ì—°ì‚° ì œì•ˆë¨. Convolution
      ..? ë©”ëª¨ë¦¬ë¥¼ ë” ì ê²Œ ì‚¬ìš©í•œë‹¤?
    multi-channel.. ??
  Convolution e.g.: original, sharpen, emboss, horizontal/vertical line,
  weights, bias?

  loss = binary_crossentrpoy vs .. sparse?..

  íšŒê·€/í„ì…‰íŠ¸ë¡  ëª¨ë¸ì—ì„œ W ëŠ” ë²¡í„°ë¼ëŠ”ë°, ë²¡
  Adaptive ...? - Moementum (velocity ?), Adagrid, RMSProp, Adam, 
    ê°ê° ì´ì „ ëª¨ë¸ì— ëŒ€í•´ ë¬´ì–´ì—‡ì„ ê°œì„ í–ˆëŠ”ì§€
  ã…ã…‡ë¯€; í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì„¤ì •ì— ê°€ì¥ robust í•˜ë‹¤ê³  ì•Œë ¤ì§.
  
  https://en.wikipedia.org/wiki/Hadamard_product_(matrices)
    - Hadamard product (also known as the element-wise product, entrywise product[1]:â€Šch. 5â€Š or Schur product
     ì›ì†Œë³„ ê³±(element-wise product) or ì„±ë¶„ë³„ ê³±
  
  Activation functinon
    Softmax ì˜ ì—­í• : normalize ë¥¼ í•´ì„œ ... ~?
    input ê°’ì„ exponential í•¨ìˆ˜ë¡œ ë§¤í•‘í•´ë†“ì•„ì„œ, í° ê°’ì€ ë” í¬ê²Œ í•˜ê³ ,ì‘ì€ ê°’ì€ ë” í¬ê²Œí•˜ëŠ”íš¨ê³¼?.. ì¦í­íš¨ê³¼.

  Error back propagation

  CNN.. Fully connected ?
  ì»¬ëŸ¬ ì´ë¯¸ì§€ëŠ” 3ì°¨ì›ì˜ tensor ë¡œ í‘œí˜„ë¨.. tensor?
  weights, shared weight?
  Feature Engineering
    Feature map.... Feature map ì„ RGB ë¥¼ ë”°ë¡œ êµ¬ì„±í•˜ë‚˜? CNN ì„ ì—¬ëŸ¬ë²ˆ í• í…ë°.. ê·¸ëŸ¬ë©´ ì´ë¯¸ì§€ í¬ê¸°ê°€ ê³„ì† ì¤„ì§€ ì•Šì•„? í’€ë§?
    filter ëŠ” í•™ìŠµìœ¼ë¡œ íŠ¹ì§•ì´ ìƒê¸°ì§€ë§Œ, filter layer ì˜ ìˆ˜ëŠ” ì‚¬ìš©ìê°€ ê²°ì •
  CNN
    stride.. ì´ìŠˆ: í•œ ë²ˆì— í•œ ì¹¸ì”© ì´ë™í•˜ë©´ ë„ˆë¬´ ì˜¤ë˜ê±¸ë¦¬ì§€ ì•Šì„ê¹Œ?
    í•´ê²°ì±…: filter ê°€ í•œë²ˆì— ì—¬ëŸ¬ ì¹¸ ì´ë™í•˜ë„ë¡ í—ˆìš©í•˜ì. >> Stride // ì˜ì—­ì„ ëŒ€í‘œí•˜ëŠ” ê°’ì„ ê°€ì ¸ì˜¤ì.
    ê·¼ë° ë°ì´í„° ì†ì‹¤ì´ ì¼ì–´ë‚˜ì§€ ì•Šë‚˜? ë¹„ëŠ” ì˜ì—­ë§Œ ì—†ê²Œ í•˜ê³ , ê²¹ì¹˜ëŠ” í…Œë‘ë¦¬?íŒ¨ë“œ ë¶€ë¶„ë§Œ ê°–ê²Œ í•˜ë©´ ê´œì°®ì€ê±´ê°€
    >> Convolution + RELU // POOLINg ì„ ë°˜ë³µ ... --> Flatten -> fully connected -> ..soft max?
      // íŠ¹ì§• ì¶”ì¶œ                                //               ????
    - flatten: matrix/tensor êµ¬ì¡°ë¥¼ 1ì°¨ì›ì˜ vector ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •.

  Stride ë¥¼ í¬ê²Œ ë§Œë“œëŠ” ê²ƒì´ í’€ë§?
  padding. stride=1 ì´ ê¸°ë³¸ê°’? ã…‡ã…‡.. 
  !! Outut size... <<< ..
    Mxa pooling vs average pooling.. ì°¨ì´.. 
    ë¬¸ì œì : ê³ ì°¨ì›ì˜ tensor ë¥¼ ë³´ë‹¤ compact í•˜ê²Œ ì¶•ì•½í•´ì•¼ í•˜ì§€ ì•Šì„ê°€?
    Pooling: ì¼ì • ì˜ì—­ì˜ ì •ë³´ë¥¼ ì¶•ì•½í•˜ëŠ” ì—­í• .
    ?? ì•Œë ‰ìŠ¤?ì¸ê°€ì—ì„œ ë§¥ìŠ¤ í´ë§ í–ˆë”ë‹ˆ ë” ì„±ëŠ¥ì´ ì˜ ë‚˜ì™€ì„œ average ë³´ë‹¤ max pooling ì„ ì“´ë‹¤ê³  í•¨
  ?? pooling ì„ í• ìˆ˜ë¡ ìƒ‰ì´ ì—°í•´ì§„ë‹¤? ì‹¤ì œ ê³ í™”ì§ˆ ê½ƒì—ëŒ€í•œ í´ë§ì— ë”°ë¥¸ ê²°ê³¼ë¬¼ ì°¨ì´..?
  >>>>>>>>>>> Feature map ì´ í•™ìŠµë˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì»¤ë„ì´ í•™ìŠµë˜ëŠ” ê²ƒì´ë‹¤!!!
  CNN ì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„°: Convolution filter ì˜ í¬ê¸°, ê°œìˆ˜
  Dense? ê°€ Full connected layer ì— í•´ë‹¹ë˜ëŠ” ë¶€ë¶„?
  Dense ì— í™œì„±í•¨ìˆ˜ sigmoid ì´í›„ softmax í•œ ì´ìœ ? conv layer ì—ì„œë§Œ relu ì”€ã„´
  ğŸ‘ https://netron.app/
VGGNet
  .. 3*3 ìœ¼ë¡œ í•˜ë”ë¼ë„
    - í•„í„° í¬ê¸° ì‘ê²Œí•˜ë©´ ë©”ëª¨ë¦¬ í¬ê¸°ë¥¼ ì¤„ì¼ ìˆ˜ ìˆê³ ,
    - layer ê¹Šì´ë§Œ í‹€ë¦¬ë©´ ë§ì€ íŠ¹ì§•ì„ ì¶”ì¶œí•  ìˆ˜ ìˆì–´ì„œ.? 3*3 ì„ ì‚¬ìš©í•œë‹¤ëŠ”ë“¯?
Transfer learning? ì´ ê°€ëŠ¥í•œ ì´ìœ ?. low-level feature, mid-level feature, high-level feature
  ..
  // input size ë§ì¶°ì¤˜ì„œ í•™ìŠµ ì‹œì¼œì•¼ í•œë‹¤? ê°€ì¥ ì¤‘ìš”...resize ë“±.
  ?? Batch & layer normalization?
    batch ì˜ ìˆ˜ì— ë”°ë¼ ì„±ëŠ¥ì— ì˜í–¥ì„ ë°›ì§€ ì•Šë„ë¡ í•˜ëŠ” ê²ƒ? layer normalization ??
  ?? ì›ë¦¬.. source task labels
  --> taget task labels.. ê°€ ë‹¤ë¥¼ ìˆ˜ì‡ëŠ”ë° ë‚´ë¶€ì ìœ¼ë¡œ êµ¬í˜„ì´ ì–´ë–»ê²Œ ë˜ì–´ìˆë‚˜?
  Training images..Sliding Patches.. C1 ~ C5 ..
Machine learning vs deep learning..
  input -> feature extraction -> classification -> output (mask)
  input -> feature extraction + clasification -> output (mask)
>>>>>>>>.ì„¤ëª… ê°€ëŠ¥í•œ AI.. ì‘ì—…? ìˆ˜ì¹˜ë¥¼ ì˜ë¯¸ìˆê²Œ ë½‘ì•„ë‚¼ ìˆ˜ ìˆë‹¤?
mono depth vs super resolution
  ?? ì‹ ê¸°.. ë©€ë¦¬ ìˆëŠ”ê±°ë‘ ê°€ê¹Œì´ ìˆëŠ”ê±° í•´ìƒë„? ìƒ‰ì´ ë‹¤ë¥´ê²Œ ë‚˜ì˜¨ë‹¤.
CNN use case.. cont.
  ì•„ë§ˆì¡´ ì¬ê³  íŒŒì•…..
    https://www.slideshare.net/awskorea/amazon-deeplearningcasesandmlonaws
ResNet.. GoLeNet-v4, SENet .. ì—ì„œëŠ” layer ê°€ ê¹Šì–´ì ¸ì„œ gradiant vanishing ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í–ˆë‚˜?
   5%.. IMagenet.. ì˜¤ë¥˜ìœ¨ ë¯¸ë§Œ..
AlexNet: Relu + local response normalization
  overlapping pooling/drouput/data augmentation
    stride ë¥¼ 2*2ë¡œ í–‡ë‹¤ê³  í•¨.
  multiple GPU  .. ì–´ë–»ê²Œ?
  normalizatino ì„ ì²˜ìŒ ì‚¬ìš©í•¨.

Convolution architecture..
GoogLeNet (Inception), 2014
  3*3.. ..? Inception? Concatenation?.. ì´ê²Œã… ë¬´ìŠ¨..
  ë³´ì¡°ë¶„ë¥˜ê¸°ë¥¼ ì¶”ê°€í•œê±´ê°€? Auxsilary classifier.. ì™œ? vanishing í˜„ìƒì„ ë§‰ê¸° ìœ„í•´? ì—°ì‚°ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´? íŒŒë¼ë¯¸í„° ê°œìˆ˜ê°€ VGGNet ë³´ë‹¤ í›¨ì”¬ ì ì€ë° ì„±ëŠ¥ì´ ì¢‹ë‹¤ê³  í•¨.ã„´
  global average pooling
  channel concat
  ? 1*1 convolution ì„ í•˜ë©´ í”¼ì³ë§µ ê°œìˆ˜ê°€ ì¤„ì–´ë“ ë‹¤?
Detection / Segmentation Annotation..

The \include command doesn't allow relative paths starting with ../. It is safer to use \input if you're working with subdirectories, as \input is more flexible in handling relative paths.


https://help.ubuntu.com/stable/ubuntu-help/shell-workspaces-switch.html.en
ğŸŒŸ //////////// ìˆ˜ì‹ ë‹¤ í•œ ë‹¤ìŒì— ì»´í“¨í„° ê·¸ë˜í”½ìŠ¤ì—ì„œ ì–´ë–»ê²Œì‚¬ìš©ë˜ëŠ”ì§€ ì§ì ‘ ì½”ë“œ ì§œë³´ê¸°

https://en.wikipedia.org/wiki/Mathematical_Alphanumeric_Symbols

ë‹¤ìŒê³¼ ê°™ì€ ë¶„ë¥˜ë¡œ ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ latex ë¡œ ì‘ì„±í•´ì¤˜.
* ì§€ì‹œì‚¬í•­
  - ë§¤ìš° êµ¬ì²´ì ì´ê³  ì •êµí•˜ê²Œ ì‘ì„±í•´ì¤˜. ê°„ë‹¨íˆê°€ ì•„ë‹ˆë¼. (ê·¸ë ‡ë‹¤ê³  ê°€ë…ì„±ì´ ì•ˆì¢‹ì•„ì§€ë©´ ì•ˆ ëŒ)
  - (ì—†ëŠ” ê²½ìš°) ê°ê° ì—°ì‚°ì‹ì´ ì •ì˜ëœ ì‚¬í•­ì— ëŒ€í•´ ì‹¤ì œ ê°’ ìˆ˜ì‹ì„ ë„£ì–´ì„œ ì˜ˆì‹œë„ ë“¤ê²ƒ. ë˜í•œ ì˜ˆì‹œë¥¼ ë“¤ê¸° ì „ì— "ğŸ›ï¸ e.g." ë¡œì„œ í•œ ì¤„ ì¶”ê°€í•œë‹¤.
    - ë‹¨, ì‹¤ì œë¡œ ì‹ì— ê°’ì„ ëŒ€ì…í•˜ì—¬ ì˜ˆì‹œë¥¼ ë“  ê²ƒì—ë§Œ \emoji{shopping} e.g. ë¼ê³  í‘œì‹œí•˜ê¸°.
  - (ì—†ëŠ” ê²½ìš°) ë¬¸ë§¥ì—ì„œì˜ Lexicon/Glossary/Terminology ë“¤ì€ ì˜ì–´ë¡œë„ í‘œì‹œí• ê²ƒ
    ğŸ›ï¸ e.g.
      ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (Cosine Similarity)
      ì„ í˜• ë…ë¦½ì„± (Linear Independence)
  - ê·¸ ì™¸ ì´ë¯¸ ë§Œë“¤ì–´ì§„ ë‹¤ë¥¸ ì£¼ì œì˜ latex ì˜ êµ¬ì„±ì„ ë”°ë¥¼ ê²ƒ.
    ì˜ˆë¥¼ ë“¤ì–´ emoji ì‚¬ìš© ë°©ë²•.
  - ì‹¤ì œ ì •ì˜ì— ëŒ€í•œ ëŒ€ìˆ˜ ìˆ˜ì‹ì´ ì‚­ì œë˜ì§€ ì•Šë„ë¡ ë‹¤ì‹œ í•œ ë²ˆ ì“´ ê²ƒì„ í™•ì¸í•´ë´, ì´í›„ ë‚´ìš©ì„ ë§ì´ ë³´ì¶©í•´ì¤˜.
  - ì ˆëŒ€ì ìœ¼ë¡œ ì˜ˆì‹œ latex ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì°¸ì¡°í•˜ì—¬ ì´ì™€ ê°™ì€ ìµœìƒìœ„ë¶„ë¥˜ë¥¼ ê°–ë„ë¡ í•´.
    // ì—¬ëŸ¬ê°œì˜ í•˜ìœ„ ì£¼ì œë¥¼ ê°–ëŠ” ê²½ìš° (ì˜ˆ: ë¯¸ë¶„ -> í¸ë¯¸ë¶„), ì´ëŸ¬í•œ ë¯¸ë¶„, í¸ë¯¸ë¶„ì„ ìµœìƒìœ„ ë¶„ë¥˜ë¡œ ë‘ê³ , í•˜ìœ„ ì£¼ì œë“¤ì„ ë‹¤ìŒê³¼ ê°™ì´ ë‘ì–´ êµ¬ì„±í• ê²ƒ. ("í•˜ìœ„ ì£¼ì œ"ì— ëŒ€í•´ì„œë§Œì„. í”„ë¡œì ì…˜ì˜ ê°œë…ì—ì„œ ì™¸ì ì˜ ê°œë…ì´ ë‚˜ì˜¤ë©´ ê°œë³„ì ìœ¼ë¡œ êµ¬ì„±í•˜ì§€ ë§ê³  ê°„ë‹¨íˆë§Œ "ì™¸ì "ì—ëŒ€í•´ ì„¤ëª…í•˜ê³  ë„˜ì–´ê°ˆ ê²ƒ)
    1. ë°°ê²½ê³¼ ì—­ì‚¬
      // ì£¼ì œì˜ ê¸°ì›ê³¼ ì—­ì‚¬ì  ë°°ê²½ì„ íŒŒì•…í•˜ëŠ” ì§ˆë¬¸ì„ í†µí•´ ê°œë…ì´ ì²˜ìŒ ì–´ë–»ê²Œ ë“±ì¥í–ˆê³ , ì–´ë–¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ê³  í–ˆëŠ”ì§€ë¥¼ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      "ì´ ê°œë…(ë˜ëŠ” ì´ë¡ )ì€ ì–¸ì œ ì²˜ìŒ ë„ì…ë˜ì—ˆê³ , ì–´ë–¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë“±ì¥í–ˆë‚˜ìš”?"
      "ì´ ì£¼ì œì˜ ì—­ì‚¬ì  ë°°ê²½ì€ ë¬´ì—‡ì¸ê°€ìš”?"
      // ì˜ˆ: "ë²¡í„° ë‚´ì ì€ ì–¸ì œ ì²˜ìŒ ì •ì˜ë˜ì—ˆê³ , ê·¸ ê¸°ì›ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    2. ì •ì˜ì™€ ëª©ì 
      //ì£¼ì œê°€ ë¬´ì—‡ì¸ì§€ ì •ì˜í•˜ê³ , ê·¸ê²ƒì´ ì–´ë–¤ ëª©ì ì„ ìœ„í•´ ì¡´ì¬í•˜ëŠ”ì§€ë¥¼ ëª…í™•í•˜ê²Œ ë¬»ìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê°œë…ì˜ ê¸°ë³¸ì ì¸ ì„±ì§ˆì„ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      "ì´ ê°œë…ì€ ë¬´ì—‡ì„ ì •ì˜í•˜ë‚˜ìš”?"
      "ì´ ì—°ì‚° ë˜ëŠ” ê°œë…ì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì–´ë–¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì¡´ì¬í•˜ë‚˜ìš”?"
      // ì˜ˆ: "ì»¤ë„ convolution ì—°ì‚°ì€ ì •í™•íˆ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ë‚˜ìš”, ê·¸ë¦¬ê³  ì™œ ê·¸ëŸ° ë°©ì‹ìœ¼ë¡œ ì •ì˜ë˜ì—ˆë‚˜ìš”?"
    3. ì—°ì‚° | ë©”ì»¤ë‹ˆì¦˜ì˜ ì´ìœ 
      // íŠ¹ì • ë°©ì‹ìœ¼ë¡œ ì •ì˜ëœ ì´ìœ ë¥¼ ë¬»ìŠµë‹ˆë‹¤. ì£¼ì œì˜ ìˆ˜í•™ì , ê³¼í•™ì  ë˜ëŠ” ê¸°í•˜í•™ì  ì´ìœ ì— ëŒ€í•´ íƒêµ¬í•˜ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤.
      "ì™œ ì´ ì—°ì‚°ì€ ì´ëŸ° ì‹ìœ¼ë¡œ ì •ì˜ë˜ì—ˆë‚˜ìš”?"
      "ì´ ë©”ì»¤ë‹ˆì¦˜ì´ ì´ë ‡ê²Œ ë™ì‘í•˜ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
      // ìˆ˜í•™ì  ì •ì˜ê°€ ì™œ ê·¸ë ‡ê²Œ ë˜ì—ˆëŠ”ì§€ ì„±ë¶„ ìœ ë„. (ì´ë¯¸ ì•Œë ¤ì§„ ì›ë¦¬ë¥¼ ì´ìš©í•˜ëŠ” ê²½ìš°, ê°„ë‹¨íˆ í•´ë‹¹ ê³µì‹ë§Œ ì´ìš©í–ˆë‹¤ê³  ì–¸ê¸‰ë§Œ. e.g. í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ë¥¼ ì´ìš©í•¨. ì´ë¼ê³  í‘œì‹œ.)" 
      // ì˜ˆ: "ì™œ ë²¡í„° ë‚´ì ì€ ë‘ ë²¡í„°ì˜ í¬ê¸°ì™€ ë°©í–¥ì˜ ê³±ìœ¼ë¡œ ì •ì˜ë˜ì—ˆë‚˜ìš”?"
    4. ë¹„êµ | ëŒ€ì¡° | ì„±ì§ˆ
      // ë“±ë“±. í•˜ìœ„ 4.1, 4.2 .. ì´ëŸ°ì‹ìœ¼ë¡œ ì¶”ê°€ êµ¬ì„±
      // ë¹„ìŠ·í•œ ê°œë…ì´ë‚˜ ì—°ì‚°ê³¼ ë¹„êµë¥¼ í†µí•´ ê·¸ ì°¨ì´ì ê³¼ ìœ ì‚¬ì ì„ ë¬»ìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì£¼ì œë¥¼ ë” ê¹Šì´ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      "ì´ ê°œë…ì€ ë‹¤ë¥¸ ê°œë…ê³¼ ì–´ë–»ê²Œ ë‹¤ë¥´ë©°, ìœ ì‚¬í•œ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
      "ì´ ì—°ì‚°ì€ cross-correlationê³¼ ì–´ë–»ê²Œ ë‹¤ë¥¸ê°€ìš”?"
      // ì˜ˆ: "ë²¡í„° ë‚´ì ê³¼ ë²¡í„° ì™¸ì ì€ ì–´ë–»ê²Œ ë‹¤ë¥´ê³ , ì–´ë–¤ ìƒí™©ì—ì„œ ê°ê°ì„ ì‚¬ìš©í•˜ëŠ”ê°€ìš”?"
    5. ì‘ìš© | ì‹¤ì œ ì‚¬ë¡€
      // ì´ ê°œë…ì´ ì‹¤ì œë¡œ ì–´ë–»ê²Œ ì ìš©ë˜ëŠ”ì§€ë¥¼ ë¬¼ì–´ë³´ë©´, ì´ë¡ ì  ê°œë…ì˜ ì‹¤ì§ˆì  í™œìš© ë°©ë²•ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      "ì´ ê°œë…ì€ ì‹¤ì œë¡œ ì–´ë””ì—ì„œ ì‚¬ìš©ë˜ë‚˜ìš”?"
      "ì´ ì—°ì‚°ì€ ì‹¤ìƒí™œì—ì„œ ì–´ë–¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ë‚˜ìš”?"
      // ì˜ˆ: "ì»¤ë„ convolutionì€ ì»´í“¨í„° ë¹„ì „ì—ì„œ ì–´ë–»ê²Œ ì‚¬ìš©ë˜ë‚˜ìš”?"
      //  , ë‹¨ìœ„ë²¡í„°ì˜ ë¬¼ë¦¬ì  ë° ìˆ˜í•™ì  ì˜ë¯¸
    6. ê´€ë ¨ ë…¼ë¬¸ | ì°¸ê³  ìë£Œ
      // ì£¼ì œì— ëŒ€í•´ ë” ê¹Šì€ íƒêµ¬ë¥¼ ì›í•  ë•ŒëŠ” ê´€ë ¨ëœ ë…¼ë¬¸, ì„œì , ì—°êµ¬ ìë£Œ ë“±ì„ ë¬¼ì–´ë³´ëŠ” ê²ƒì´ ìœ ìš©í•©ë‹ˆë‹¤.
      "ì´ ì£¼ì œì™€ ê´€ë ¨ëœ ì¤‘ìš”í•œ ë…¼ë¬¸ì´ë‚˜ ì—°êµ¬ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
      "ì´ ê°œë…ì— ëŒ€í•œ ë” ê¹Šì€ ì´í•´ë¥¼ ìœ„í•´ ì°¸ê³ í•  ë§Œí•œ ë¬¸í—Œì€ ë¬´ì—‡ì¸ê°€ìš”?"
      // ì˜ˆ: "ë²¡í„° ë‚´ì ì˜ ì •ì˜ì™€ ê¸°ì›ì„ ë‹¤ë£¬ ì¤‘ìš”í•œ ë…¼ë¬¸ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    7. ê´€ë ¨ ìš©ì–´
      // ì˜ˆ: í–‰ë ¬ì´ë¼ë©´, "íŒë³„ì‹" ì— ëŒ€í•´, "ê°€ìš°ìŠ¤-ì¡°ë˜ ì†Œê±°ë²•" ë“±ì— ëŒ€í•´ ê¸°ë¡í•œë‹¤. í•˜ìœ„ë¶„ë¥˜ê°€ ë  ìˆ˜ ìˆëŠ” ì—­í–‰ë ¬, ë‹¨ìœ„í–‰ë ¬ ë“±ì€ ê°œë³„ì ìœ¼ë¡œ ë¬¸ì„œë¥¼ ì‘ì„±í•  ê²ƒì´ë¯€ë¡œ ì‘ì„±í•˜ì§€ ì•ŠëŠ”ë‹¤.
      // ê´€ë ¨ìš©ì–´ì— ìˆ˜í•™ì  ì •ì˜ê°€ ì•˜ë‹¤ë©´ 2ì°¨ ë¶„ë¥˜ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë°°ê²½ê³¼ ì—­ì‚¬, ì •ì˜ì™€ ëª©ì , ì—°ì‚° | ë©”ì»¤ë‹ˆì¦˜ì˜ ì´ìœ , ì‘ìš© | ì‹¤ì œ ì‚¬ë¡€ë¥¼ í•¨ê»˜ë¥¼ ì“´ë‹¤. (í•˜ìœ„ ë¶„ë¥˜ë¡œì„œ!!!)
	- ë¬¸ë‹¨ ê°„ì— ì ì ˆí•œ ë„ì–´ì“°ê¸°ë¥¼ ì¶”ê°€í•˜ê³ , ë‹¤ìŒ ë¬¸ë‹¨ì„ ìƒˆ ì¤„ì—ì„œ ì‹œì‘í•´. (latex ì—ì„œ ë Œë”ë§ ë˜ëŠ” ê¸°ì¤€ìœ¼ë¡œ)
	- ìˆ˜í•™ì‹ì´ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸ë¥¼ êµµê²Œ í•˜ëŠ” ê²ƒì€ ** ** í‘œì‹œê°€ ì•„ë‹ˆë¼ \textbf{}ë¥¼ ì‚¬ìš©í•´.





ì°¨ì›ì´ ë†’ìœ¼ë©´ ì™œ ì¢‹ì€ê°€?
	Local Minima
		loss contour of a VGG-56 DNNâ€™s loss function
			Gradient of local and global minima is zero
			Improper initialization point may cause convergence to a local minima
				â€“ youâ€™re doomed!
Multi dimension
	Saddle Points, Edge Length, Truncation Parameter
		â€¢ A minima in one direction, a maxima in another direction
		â€¢ Occurs where two maxima meet
	ë‹¤ì°¨ì› ë²¡í„°ì˜ ë‚´ì 
		â€¢ ë‘ ë²¡í„° ğ‘¥1, ğ‘¥2 ì˜ ë‚´ì ì€ ë‘ ë²¡í„° ê°„ì˜ projection ì—ë„ˆì§€ì˜ ì ë¶„ìœ¼ë¡œ ì •ì˜ë¨
		â€¢ ë‘ ë²¡í„°ê°€ ì‹ í˜¸ì´ê³ , ê°™ì€ ì‹ í˜¸ì¼ ê²½ìš° ì‹ í˜¸ì˜ ì—ë„ˆì§€ê°€ ë¨
		ë²¡í„° ê°„ì˜ ì—°ì‚°ì´ë¯€ë¡œ ì°¨ì›ì´ ê°™ì•„ì•¼ í•¨
			â€¢ ë‚´ì ì˜ ê²°ê³¼ëŠ” ìŠ¤ì¹¼ë¼!! ?
	ë°©í–¥ì„±ë¶„ ì¶”ì¶œ
		â€¢ ğ‘¥ğ‘› ì— ê´€í•œ ê¸°ì €í•¨ìˆ˜ âˆ…ğ‘› ì˜ ê°€ì¤‘ì¹˜ í˜¹ì€ ê³„ìˆ˜ëŠ” ğ‘¥ğ‘› ì™€ âˆ…ğ‘› ì˜ ë‚´ì ìœ¼ë¡œ ì¶”ì¶œë¨
		â€¢ ğ‘¥ğ‘› ì™€ âˆ…ğ‘› ì˜ ë‚´ì ì€ ğ‘¥ğ‘› ì˜ âˆ…ğ‘› ë°©í–¥ì˜ ì •ì‚¬í˜• ì„±ë¶„ìœ¼ë¡œ âˆ…ğ‘› ë°©í–¥ì˜ ê°€ì¤‘ì¹˜ë¡œ í•´ì„ë¨
	ì§êµì„±ê³¼ ê¸°ë³¸ ë²¡í„°(basis function)
		â€¢ ì§êµì„±(orthogonal & orthonormal)
			â€¢ ì‹ í˜¸ ğ‘¥(ğ‘¡)ì— ê´€í•œ ì‹ì˜ ê¸°ì €í•¨ìˆ˜ë¥¼ ğœ™ğ’ ë¼ê³  í•  ë•Œ, ë‹¤ë¥¸ ê¸°ì €í•¨ìˆ˜ ê°„ì˜ ë‚´ì ì´ 0ì¼ ê²½ìš° orthogonalì´ë¼ê³  í•¨
			â€¢ ë™ì¼ ê¸°ì €í•¨ìˆ˜ ê°„ì˜ ë‚´ì ì´ 1ì¼ ê²½ìš°, orthonormalì´ë¼ê³  í•¨
	sin/cosí•¨ìˆ˜ ê¸°ë³¸ ë²¡í„°
		â€¢ ì§€ìˆ˜ ê¸°ì €í•¨ìˆ˜(íŒŒë™ì˜ ì£¼íŒŒìˆ˜ ê¸°ë³¸ìœ¼ë¡œ ëª¨ë¸ë§)
	matrix í™•ì¥
		â€¢ matrixë¡œ í™•ì¥í•˜ë©´ ì—¬ëŸ¬ ë²¡í„°ì˜ ë‚´ì ì„ í•œêº¼ë²ˆì— ì§„í–‰ ê°€ëŠ¥
		â€¢ ì»¤ë„í–‰ë ¬ì„ ì¸ê³µì‹ ê²½ë§ í˜•íƒœë¡œ í‘œí˜„í•˜ë©´, í”¼ì³ë§µì„ ê° ê°€ì¤‘ì¹˜ê°€ ê³±í•´ì§„ ì±„ë„ì˜ í•©ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŒ.

		


ë²•ì„ ë²¡í„°? í‘œë©´ë²•ì„ ? (normal vector) ì— ëŒ€í•´ì„œë„
  ===========
  ë²¡í„°ì˜ ë‚´ì ..
  3.6 ì»´í“¨í„° ê·¸ë˜í”½ìŠ¤ì—ì„œì˜ ì‘ìš©
  ì»´í“¨í„° ê·¸ë˜í”½ìŠ¤ì—ì„œ ë‚´ì ì€ ë¬¼ì²´ì˜ í‘œë©´ê³¼ ë¹›ì˜ ê°ë„ë¥¼ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë¬¼ì²´ í‘œë©´ì— ë¹›ì´ ë‹¿ì„ ë•Œ, ë¹›ê³¼ í‘œë©´ ë²•ì„  ë²¡í„° ê°„ì˜ ë‚´ì ì„ ê³„ì‚°í•˜ì—¬ í‘œë©´ì˜ ë°ê¸°ë‚˜ ê·¸ë¦¼ìë¥¼ ê²°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  ë²¡í„°ì˜ ì™¸ì ..
  3.6 ì»´í“¨í„° ê·¸ë˜í”½ìŠ¤ì—ì„œì˜ ì‘ìš©
  ì»´í“¨í„° ê·¸ë˜í”½ìŠ¤ì—ì„œëŠ” ë¬¼ì²´ì˜ íšŒì „ê³¼ ë³€í™˜ì„ ì²˜ë¦¬í•˜ëŠ” ë° ì™¸ì ì„ ì‚¬ìš©í•˜ë©°, íŠ¹íˆ ë¬¼ì²´ì˜ í‘œë©´ì— ìˆ˜ì§ì¸ ë²•ì„  ë²¡í„° (normal vector)ë¥¼ ê³„ì‚°í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.
  
  3.3 ğŸ–¼ï¸ ì»´í“¨í„° ê·¸ë˜í”½ìŠ¤ì—ì„œì˜ ë‹¨ìœ„ë²¡í„° ì‘ìš© (Applications of Unit Vector in Computer Graphics)
  ì»´í“¨í„° ê·¸ë˜í”½ìŠ¤(Computer graphics)ì—ì„œëŠ” ì¹´ë©”ë¼ì˜ ë°©í–¥(Direction), ë¬¼ì²´ì˜ í‘œë©´ ë²•ì„ (Normal vector) ë“±ì„ ë‚˜íƒ€ë‚´ê¸° ìœ„í•´ ë‹¨ìœ„ë²¡í„°ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë‹¨ìœ„ë²¡í„°ëŠ” ë¬¼ì²´ì˜ ì¡°ëª…(Lighting), ê·¸ë¦¼ì(Shadow) ì²˜ë¦¬ ë“±ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.

  https://numpy.org/doc/stable/reference/generated/numpy.sum.html

https://marketplace.visualstudio.com/items?itemName=DavidAnson.vscode-markdownlint
https://marketplace.visualstudio.com/items?itemName=shd101wyy.markdown-preview-enhanced

>> ë‹¤ìŒ ì˜ˆì‹œ êµ¬ì„±ê³¼ ê°™ì´ ë‹¨ìœ„ë²¡í„°ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜  
    Norm
      L1 Norm
        ë²¡í„°ì™€ ì›ì†Œì˜ ì ˆëŒ€ê°’ì˜ í•©
      L2 Norm
        ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ë¡œ ê³„ì‚°ëœ ë²¡í„°ì˜ ê¸¸ì´
      ë¬´í•œ ë†ˆ
        ë²¡í„°ì˜ ì›ì†Œ ì¤‘ ì ˆëŒ€ê°’ì´ ê°€ì¥ í° ê°’.
      Entropy
      í‰ê· ê³¼ ë¶„ì‚°..
      BN.. Batch Normalization ..? // layer ë¥¼ ì¶”ê°€í•œ ê²ƒê³¼ ê°™ë‹¤?..
        mini-batch mean
        mini-batch variance
        normalize
        scale and shift
    // ê°ê°ì— ëŒ€í•œ ìˆ˜í•™ ê¸°í˜¸ë„ í‘œì‹œ.

  Entropy~
    ì†ŒìŠ¤ ì‹¬ë³¼ì— ëŒ€í•œ ì •ë³´ëŸ‰ I ì‹¬ë³¼ì˜ ë°œìƒí™•ë¥ (ì˜ì™¸ì„±) P?
      ì‹¬ë³¼ì˜ í‰ê·  ì •ë³´ëŸ‰
        ì—”íŠ¸ë¡œí”¼(entropy, ë¬´ì§ˆì„œë„ë¡œ í‘œí˜„)
        Shannon ì´ ìˆ˜í•™ì ìœ¼ë¡œ ì •ì˜

        Entropy: ìˆ˜ì‹..
        Corss-Entropy: ... ìˆ˜ì‹..
        KL-divergence: .. ìˆ˜ì‹..
      Cost function
        MSE (Mean Squared Error)
        Binary cross-entropy
        Optimizer adam?
        Categorical across-entropy
          ..vs spare categorical crossentropy.. ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜?
      ì¡°ê±´ë¶€ í™•ë¥ 
        ë² ì´ì§€ì•ˆ ì´ë¡ ..
          P(A) ì‚¬ì „í™•ë¥  (prior probability)
          P(B|A) ìš°ë„í™•ë¥ (likelihood probability)
          P(A|B) ì‚¬í›„ í™•ë¥ (posterior probability)
  Convolution..
  êµí™˜ë²•ì¹™ì„ ì„±ë¦½í•˜ê²Œ í•˜ê¸° ìœ„í•´ì„œ convolution ì‹œ ìƒí•˜ì¢Œìš° ë°˜ì „ì„ ì‹œì¼œì•¼ í•œë‹¤.
    ì´ë¯¸ì§€ ë³µêµ¬? ë¥¼ ìœ„í•´ì„œ ?ë„?.. ì „ì¹˜ë¥¼ í•œë‹¤ê³  í•œë‹¤.....
    cv2, wiki ì—ì„œë„ ì´ë¯¸ì§€ í”„ë¡œì„¸ì‹±ì—ì„œëŠ” ì»¨ë³¼ë£¨ì…˜ ì‹œ ë’¤ì§‘ì–´ì¤¬ëŠ”ë° ì™œ keras ëŠ” ì•ˆë’¤ì§‘ëŠ”ê±´ì§€?

    https://angeloyeo.github.io/2019/08/06/determinant.html

  Euler's number; ë„¤ì´í”¼ì–´ ìƒìˆ˜, ì˜¤ì¼ëŸ¬ ìˆ˜, ìì—°ìƒìˆ˜
    ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜
  e?.. ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜??..
    convlution í•  ë•Œ ì™œ ë’¤ì§‘ë‚˜? flip ìœ„ìƒì„...

  â“ ANN ì€ Flatten ì„ ë¨¼ì € í•˜ë‚˜?


í¸ë¯¸ë¶„ ê¸°í˜¸.. ì½ëŠ” ë°©ë²•, ê¸°í˜¸ âˆ‚
ìŒì„±ì¸ì‹ê³¼ ìƒì„±í˜• AIë¥¼ í™œìš©í•œ ì˜ë¥˜ ê°€ìƒ í”¼íŒ… í‚¤ì˜¤ìŠ¤í¬ -  ê°ë‹¤ê³µ
  í”¼íŒ… íšŸìˆ˜ ì œí•œ, ë‹ˆíŠ¸, í°ìƒ‰, ì…”ì¸  
  ..
  ì¹´ë©”ë¼ì— ã…‡ã…‡.. 
  íŒ¨ì…˜ì‹œì¥ ê·œëª¨ ã…‡ã…‡.
  íŠ¸ë Œë“œ ë¦¬ë”
  d;stpds
  > ê¸°ëŒ€íš¨ê³¼
  ë°œë ¤ë™ë¬¼ë¡œ ëŒ€ìƒ ë„“íˆê¸°, ëª¨ë¸ì´ ì§ì ‘ ê´‘ê³ ë¥¼ ì´ã…œí•´.. 

  ì–¼êµ´ ì¸ì‹ -> ì„±ë³„ ë° ì—°ë ¹ì¸ì‹ -> ì˜ìƒ ì¶”ì²œ
  >> Vector DB ì—ì„œ ì˜ìƒì¶”ì¶œ ??
    ìŒì„± -> í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë³€í™˜
    
  Stable diffusion  >> txt2img

    ê°„íŠ¸ ì°¨íŠ¸

  3ì›”?
    ìŠ¤ì¼ˆë ˆí†¤ì„ í†µí•œ ì‹ ì²´ ì‚¬ì´ì¦ˆ ì¸¡ì •
  UI í†µí•©..
ë§ˆì´í¬ ì„±ê³µ..
  ë¬¸ì œ
  >>>>>>>>>>>>>. ì™¸ë¶€ í™˜ê²½ 
    ê³ ê¸‰ ì†ŒìŒ ì œê±° ì•Œê³ ë¦¬ì¦˜ ì¡ìŒ ì œê±°.
    ì‚¬ìš©ì-ì¹´ë©”ë¼ ê°„ì˜ ê±°ë¦¬ ë³€í™”ì— ë”°ë¥¸ í”½ì…€ ì™œê³¡ìœ¼ë¡œ ì¸í•´ ìŠ¤ì¼ˆë ˆí†¤ì˜ ì‹ ì²´ ë°ì´í„°ì˜ ì •í™•í•œ ì¸¡ì •ì´ ì–´ë ¤ì›€

    ì†ëª¨ì–‘ì— ë”°ë¥¸ ì •í™•í•œ ì˜ë¯¸ ì¸ì‹ì´ ì–´ë ¤ì›€. Yolo-tiny.. íŠ¹ì • ë™ì‘ì— ë”°ë¼ ëª¨ì…˜ ì¸ì‹ìœ¼ë¡œ 
      >>>>>>>> 
    ì‚¬ìš©ìì™€ ì£¼ë³€ í™˜ê²½ì˜ êµ¬ë¶„ì´ ì–´ë ¤ì›€..

  Google trnaslate?? ë¥¼ ì‚¬ìš©? speech regonition ?

  openvino ê°€ ì„œì–‘..ì‚¬ëŒìœ¼ë¡œ ì¸ì‹


  pytorch ëª¨ë¸ì¸ text encoder ë¥¼ openvino ì˜ IR í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©
  U-Net... 
  íŒŒì´ì¬ìœ¼ë¡œ í¬ë¡¤ë§í•˜ì—¬ SQL DB í™”

  acgpn ? ë”¥ëŸ¬ë‹ëª¨ë¸... ì—¬ì„± ì˜·ì— ìµœì í™”.. 
  Stable diffusion

Opencv
  opencv ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ ê°ì§€ í›„ ì„±ë³„ê³¼ ì—°ë ¹ ì¸ì‹. ; OPEN-source Computer Vision
  Main modules
    core.
    imgproc.
    imgcodecs.
    videoio.
    highgui.
    video.
    calib3d.
      ê´‘ê°ì  ì™œê³¡ì„ ì¤„ì´ëŠ” ìš©ë„
    features2d
    objdetect
    dnn.
    ml.
    flann.
    photo.
    stiching
    gapi.
  Extra modules
    alphamat.
    aruco.
    bgsegm.
    bioinspired.
    ccalib.
    cudararithm.
    cudabgsegm.
    cudacodec.
    cudafeaturse2d.
  >> Codec ì´ë€?
  ë¹›ì˜ 3ì›ìƒ‰ vs ìƒ‰ì˜ 3ì›ìƒ‰

  jpeg ëŠ” ì••ì¶•ë¥ ì´ ë†’ë‹¤. png ëŠ” ë¬´ì†ì‹¤ì— ê°€ê¹Œìš´? ì••ì¶•ë°©ì‹??
  âš“ Flags for video I/O ; https://docs.opencv.org/3.4/d4/d15/group__videoio__flags__base.html
    idiom... cv::VideoCaptureProperties
      # Set desired frame width and height
      cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
      cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    CAP_DSHOW 
      Python: cv.CAP_DSHOW
      DirectShow (via videoInput) 
      https://en.wikipedia.org/wiki/DirectShow
  SAVINg video ; https://docs.opencv.org/3.4/dd/d43/tutorial_py_video_display.html
  ì¹´ë©”ë¼ë¥¼ í†µí•œì„±ë³„, ì—°ë ¹ ì¸ì‹ -> ìŒì„± ì¸ì‹ ë° ìŒì„±ëœ ìŒì„± í™•ì¸ ë° í‚¤ì›Œë“œ ì¶”ì¶œ - >ì¶”ì¶œëœ í‚¤ì›Œë“œ ê¸°ë°˜ì˜ ì˜· ì¶”ì²œ -> ì‚¬ì§„ í•©ì„±ì„ ìœ„í•œ ì‚¬ìš©ì ì´¬ì˜

  ì–´ê¹¨ë³´ë‹¤ ì†ì´ ë°–ì— ìˆìœ¼ë©´ ? ìë™ìœ¼ë¡œ ì¹´ìš´íŠ¸? ë˜ë„ë¡ í•´ì„œ ì‚¬ìš©ìì™€ ì˜ìƒ ì´ë¯¸ì§€ í•©ì„±í•˜ì—¬ ì¶œë ¥.ë°°ê²½ë„ ë˜‘ê°™ì´.
    

ì§€í–¥ì„± ë§ˆì´í¬ >>
  ì•±ì½” ë§ˆì´í¬
  ë¡œì»¬ì— ìŠ¤í…Œì´ë¸” ë””í“¨ì „ ..ì„ ë°›ì•„ì™€ì„œ ì‚¬ìš©í•˜ëŠ” í˜€ìµ

LoRA(Low-Rank Adaptation, ì € ë­í¬ ì ì‘?)ì€ Stable Diffusion ëª¨ë¸ì„ ì„¸ë¶€ ì¡°ì •í•˜ê¸° ìœ„í•œ í•™ìŠµ ê¸°ë²•ì…ë‹ˆë‹¤. Stable
  ì»¨íŠ¸ë¡¤ë„·ìœ¼ë¡œ ì‚¬ì§„ì˜ ë¼ˆëŒ€ë¥¼ ê°€ì ¸ì™€ì„œ, ì˜· ì…í˜€ì•¼ í•¨.. 

  ã…’ã…”ë‘í„ã…œã… .. ã„»ã…Šã„· ã…‡ã„·ã……ã„·ã…Šìƒ¤ã…ã…œ. ã…ã…ã„·, ã…ë‘—ã……ã„·ã„±
  ã…†ë¦¬ã…‘ã……ã„·ã„´ë””ë»-ã„´ã„¸íë‘£ã…ìƒ¤ã…ã…œ
  https://github.com/CMU-Perceptual-Computing-Lab/openpose


ì°¨ëŸ‰        ---
stm32 mcu // RTOS:Free.. ROS      <-->     Embedded Linux jetson nano + ìˆ˜ì‹ í˜¸ ì²˜ë¦¬
guvcview


>>>>>>>>>> https://netron.app/ ëª¨ë¸ í•™ìŠµ ì–´ë–»ê²Œ ë¬ëŠ”ì§€ í™•ì¸
â­• Functional API !1
  https://www.tensorflow.org/guide/keras/functional_api


  class Layer(BackendLayer, Operation, KerasSaveable):
    @traceback_utils.filter_traceback
    def __call__(self, *args, **kwargs):
      ...
      # ì‹¤ì œë¡œ ë ˆì´ì–´ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ìƒìœ„ í´ë˜ìŠ¤ì˜ __call__ í˜¸ì¶œ
      outputs = super().__call__(*args, **kwargs)
      ...
      return outputs

    ?? Keras.. method chaining pattern.. 


  super()ëŠ” ë¶€ëª¨ í´ë˜ìŠ¤ì˜ ë©”ì„œë“œë¥¼ í˜¸ì¶œí•  ë•Œ ì‚¬ìš©ë˜ì§€ë§Œ,
  
  ë‹¤ì¤‘ ìƒì† ìƒí™©ì—ì„œëŠ” MROì— ë”°ë¼ ë©”ì„œë“œ íƒìƒ‰ì´ . ì¦‰, super().__call__(*args, **kwargs)ëŠ” MROì—ì„œ ê°€ì¥ ë¨¼ì € ë‚˜ì˜¤ëŠ” ë¶€ëª¨ í´ë˜ìŠ¤ì˜ __call__() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
  BackendLayer ì—ëŠ” ì—†ê³ , Operation ì—ëŠ” ìˆë‹¤.
  
  - call() ì€ ì˜ˆì•½ì–´ê°€ ì•„ë‹˜.. __call__() ì€ ì˜ˆì•½ì–´ì´ê³ . call() ì€ í…ì„œí”Œë¡œìš° ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜.
    __call__() ì€ ë‹¤ìŒê³¼ ê°™ì´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ í•¨ìˆ˜ì²˜ëŸ¼ ì‚¬ìš©í•  ë•Œ í˜¸ì¶œë¨.
      model = Flatten()(model) # ì´ì „ ANN dataset í•™ìŠµ ì‹œ ì‚¬ìš©í•œ Functional API í˜¸ì¶œ ë°©ì‹.

  - MultiHeadAttention layer ëŠ” Layer í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ìŒ.
  
  - class Layer ëŠ” def __call__() ì—ì„œ super().__call__() ë¥¼ ì‚¬ìš©í•œë‹¤.
    ì´ëŠ” ë¶€ëª¨ í´ë˜ìŠ¤ (Layer ëŠ” ë‹¤ì¤‘ ìƒì†ë¨) ì¤‘ MRO (Method Resolution Order) ì— ë”°ë¼ __call__() ì´ ì •ì˜ë˜ì–´ìˆëŠ” í´ë˜ìŠ¤ë¥¼ ì°¾ì•„ì„œ í•´ë‹¹ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œëŠ” keras.src.ops.operation.Operation.

    @keras_export(["keras.Layer", "keras.layers.Layer"])
    class Layer(BackendLayer, Operation, KerasSaveable):
        """
        This is the class from which all layers inherit.
        A layer is a callable object that takes as input one or more tensors and that outputs one or more tensors. It involves computation, defined in the call() method, and a state (weight variables).
        ...
        """
        @traceback_utils.filter_traceback
        def __call__(self, *args, **kwargs):
          ...
            ####################
            # 7. Call the layer.
            ...
                    if new_scope is not None:
                        with new_scope:
                            outputs = super().__call__(*args, **kwargs)
                    else:
                        outputs = super().__call__(*args, **kwargs)
  - ê²°êµ­ ì´ ê³³ì—ì„œ call() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    // keras.src.ops.operation.Operation
    @traceback_utils.filter_traceback
    def __call__(self, *args, **kwargs):
        # Plain flow.
        if any_symbolic_tensors(args, kwargs):
            return self.symbolic_call(*args, **kwargs)
        if getattr(self, "quantization_mode", None) is not None:
            return self.quantized_call(*args, **kwargs)
        else:
            return self.call(*args, **kwargs)

    ì½”ë“œì—ì„œ traceback_utils.is_traceback_filtering_enabled()ë¥¼ í™•ì¸í•˜ëŠ” ì´ìœ ëŠ”, ì˜ˆì™¸ê°€ ë°œìƒí•  ë•Œ ë” ìœ ìš©í•œ ë””ë²„ê¹… ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ì„œì…ë‹ˆë‹¤. ì´ ë¶€ë¶„ì€ call ë©”ì„œë“œë¥¼ ê°ì‹¸ì„œ, ì˜ˆì™¸ê°€ ë°œìƒí•˜ë©´ ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
    ë ˆì´ì–´ê°€ ì‹¬ë³¼ë¦­ í…ì„œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ì—ëŠ” self.symbolic_callë¥¼ í˜¸ì¶œ.
    ë§Œì•½ ì–‘ìí™”(quantization) ëª¨ë“œê°€ í™œì„±í™”ëœ ê²½ìš°ì—ëŠ” self.quantized_callë¥¼ í˜¸ì¶œ
    ê·¸ ì™¸ì—ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ self.call ë©”ì„œë“œë¥¼ í˜¸ì¶œë©ë‹ˆë‹¤.
  ğŸ“° TODO
    // ê³ ì°¨í•¨ìˆ˜ êµ¬í˜„í•´ë³´ê¸°

@keras_export("keras.Operation")
class Operation:

>>>>>>>>>>>>> í¬ë¡¤ë§ í•œ ì´ë¯¸ì§€: svg, png .. waifu ncnn py ë¡œ wsl ì—ì„œ í™•ëŒ€ ì‹œ ìƒ‰ìƒì´ ì´ìƒí•´ì§€ëŠ” ë¬¸ì œ?

ğŸ“° Real-ESRGAN >> ì‚¬ìš©í•´ë³´ì. WSL, Ubuntu ì—ì„œ ëª¨ë‘ ì‘ë™í•œë‹¤ê³  í•œë‹¤.  ğŸ“…2024-09-17 01:46:50
  https://github.com/xinntao/Real-ESRGAN
  Real-ESRGANì€ ìµœê·¼ì— ë°œí‘œëœ ìµœì‹  ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§ ëª¨ë¸ë¡œ, ê¸°ì¡´ì˜ ESRGAN(Enhanced Super-Resolution GAN)ì„ ê°œì„ í•œ ë²„ì „ì…ë‹ˆë‹¤. íŠ¹íˆ ì¼ë°˜ ì‚¬ì§„ ë° ì• ë‹ˆë©”ì´ì…˜ ì—…ìŠ¤ì¼€ì¼ë§ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    ì¥ì 
    ê³ í•´ìƒë„ ì—…ìŠ¤ì¼€ì¼ë§ì— ì í•©í•˜ë©°, íŠ¹íˆ ë…¸ì´ì¦ˆê°€ ìˆëŠ” ì´ë¯¸ì§€ë‚˜ ë””í…Œì¼ì´ ë§ì€ ì´ë¯¸ì§€ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.
      Waifu2xì²˜ëŸ¼ ì• ë‹ˆë©”ì´ì…˜ê³¼ ì¼ë°˜ ì´ë¯¸ì§€ ë‘˜ ë‹¤ì— ì˜ ë™ì‘í•©ë‹ˆë‹¤.
      ì´ë¯¸ì§€ì˜ ì „ë°˜ì ì¸ í’ˆì§ˆì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ë©°, ì„¸ë¶€ ì‚¬í•­ì´ ì˜ ìœ ì§€ë©ë‹ˆë‹¤.

    ë‹¨ì :
      SRGANë³´ë‹¤ êµ¬í˜„ì´ ë³µì¡í•˜ê³ , ë” ë§ì€ ì—°ì‚° ìì›ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      íŠ¹íˆ ì €ì„±ëŠ¥ GPUì—ì„œëŠ” í•™ìŠµ ë° ì¶”ë¡  ì‹œê°„ì´ ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


"editor.tabSize": 2
  + auto detect..

ğŸª± req ; https://en.wiktionary.org/wiki/req
  Abbreviation of request.
Runet GoogleNet VGGNet, RNN/LSTM .. Segment detection ì´í›„ 
  Attention, Sequneced Sequnece.. Tansformer ê¸°ë°˜ GPT?

  GoogleNet; 3ê°€ì§€ íŠ¹ì§•
    inception, ë³´ì¡° ë¶„ë¥˜ê¸° (gradient vanisihin ë¬¸ì œ í•´ê²°), global average poolin (ì—°ì‚°ëŸ‰ ì¤„ì„)
      ?? ì™œ ì–´ë–»ê²Œ ë¬¸ì œí•´ê²°í•œê±°ì§€ ì–´ë–»ê²Œ
ResNet
  ê°€ì¥ ê¹Šê³  ì„±ëŠ¥ì´ ì¢‹ì€ ë„¤íŠ¸ì›Œí¬. Revolution of depth.
    better recognition than human. ê¹Šì´ì˜ í˜ëª…
  input ì„ ì£¼ê¸°ì ìœ¼ë¡œ ë„£ì–´ì£¼ëŠ” skip connection êµ¬ì¡°.
  output sizeê°€ ì¤„ ë•Œë§ˆë‹¤, ì±„ë„ì„ 2ë°°ì”© ëŠ˜ì–´ë‚¨.
  1*1.. ? ìœ¼ë¡œ ì—°ì‚°ëŸ‰ì„ ì™œ..
  bottleneck layer: 1*1. 3*3. 1*1.. ì´ê±° ì™œ ì‚¬ìš©/ ì´ê²Œë¬´ìŠ¨êµ¬ì¡°?
    improve efficiency. simliar to googleNet
  Residual running.
  weight layer... ì°¨ë¶„ êµ¬ì¡°..? weighting ì— ë°˜ì˜ì´ ëœë‹¤..
Image Localization: CNN Class Activiation Map;
  ì™œ ê·¸ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ì§€ íŒë‹¨í•˜ëŠ”ã„± ã…“ã…….
  CNN Class Activation Map
  Fully Conneced layer ëŒ€ì‹  Global average polling (GAP) ì´ë¼ëŠ” ê°œë…ì„ ë„ì…
  !!! ê³µê°„ì ì¸ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆë‹¤. ì´ë¥¼ yolo ì—ì„œë„ ì‚¬ìš©í•œë‹¤.

  Grad-CAM..
  ReLU
  Grad-CAM ìœ¼ë¡œ .. Heatp map êµ¬ì„±?
  ğŸš£ >>> "Imagenet 1000 class list" search.
  FCN models..
Segmentation
  í”½ì…€ ë‹¨ìœ„ì˜ ì˜ˆì¸¡ì„ ìœ„í•œ ìµœì´ˆì˜  ë‘¥-ìƒˆ-ë‘¥  ë°©ì‹.
    skip cmbine downsampling upsampling
    ???
  Fully Convolutionalization
    FC ê³„ì¸µì„ ëª¨ë‘ Conv ê³„ì¸µìœ¼ë¡œ ëŒ€ì²´í—¤ íˆíŠ¸ë§µì„ íšë“.

  input image title --> output segmentation map
  ì•½ê°„ ì‚¬ì´ì¦ˆ ì°¨ì´ê°€ ìˆì„ ìˆ˜ ìˆìŒ. concatenate í•´ì„œ ë¶™ì¸ë‹¤ê³  í•¨.
ğŸ’¡ Confusion Matrix
  + ì •í™•ë„ì™€ ì¬í˜„ìœ¨ì˜ ì°¨ì´?
    ì˜ˆë¥¼ ë“¤ì–´ ì•”ì„¸í¬... ì— ëŒ€í•´ì„œ ìˆëŠ” ê²ƒë“¤ì„ ë‹¤ ì°¾ì•„ë‚´ëŠ” ê²ƒì´ ì¤‘ìš”í•´ì„œ.. 
    Precision, Recall
    ğŸª± PR Cruve... ì„œë¡œ ë°˜ë¹„ë¡€í•˜ëŠ” íŠ¹ì„±. ì™œ?
    ğŸª± iOU
Object Detectoin Yolu
  ë©€í‹° ë ˆì´ë¸” ì´ë¯¸ì§€ ë¶„ë¥˜ì™€ ë°”ìš´ë”© ë°•ìŠ¤ íšŒê·€ë¥¼ ìœ„í•œ ê¸°ë³¸ì ì¸ ì˜ì—­ì„ ì •í•˜ê¸° ì–´ë ¤ìš´ ë¬¸ì œê°€ ìˆìŒ.

  models
    2-Stage model
      Region proposal -> classification (Plain cnns) -> multi-class classification, bounding box regression
      e.g. RCNN, fastRCNN, fasterRCNN
    1-Stage model
      Conv layers (Faeature extraction) -> Features Map -> For each grid/spatial location
      e.g. Yolo, SSD
      ë‘ ê°€ì§€ ë„¤íŠ¸ì›Œí¬ë¥¼ í•˜ë‚˜ë¡œ í•©í•´ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”ì‹œí‚¬ ìˆ˜ ìˆëŠ” 1-stage
      2-stage network ëŠ” ì •í™•í•˜ê³  ëŠë¦°ë°, 1-stage ëŠ” ë¹ ë¥¸ë° ì •í™•ë„ëŠ” ë‹¤ì†Œ ë–¨ì–´ì§.
      ê° ê·¸ë¦¬ë“œ ì…€ì€ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë§Œì„ ì˜ˆì¸¡í•˜ê¸° ë•Œë¬¸ì— ê°ì²´ê°€ ê²¹ì³ ìˆìœ¼ë©´ ì œëŒ€ë¡œ ì˜ˆì¸¡í•˜ê¸° ì–´ë ¤ì›€.


  ğŸ†š RCNN, fastRCNN, fasterRCNN
    fasterRCNN ì€ ROI pulling? pollinG? ì´ë¼ëŠ” ê²ƒì„ í•œë‹¤ê³  í•œë‹¤. RPN
      ì •ì‚¬ê°í˜• ì˜ì—­ì„ ë§Œë“¤ê¸° ìœ„í•´ resizeë¥¼ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ pooling ì„ ì‚¬ìš©í•œë‹¤?
      >> resize ë¥¼ í•¨ìœ¼ë¡œì„œ ì™œê³¡ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤ê³  í•œë‹¤?
  ğŸ”ª 1-Stage object detection
    -------------------- CNN Layers --------------------
    spatial details <---- Our approach ---> Semantics
    ..? Semantics (?? Last layer of CNN e.g., fc7 in VGGNet)
  x, y, w, h,confidnence, probability of class ë¥¼ ê°™ì´ ê°€ì§€ê³  ìˆìŒ.. grid cell? ì´ ë­ì§€?
  bounding box descripter
    ??tx1
  iou .. Intersection over Union.. 

  ğŸš£ Yolo V3 (Prediction Across Scales)
    ?? 13*13, 26*26, 52*52  
  Feature Pyramid.. ?map?
  Dark architecture again?
2023 ë…„ LLM. ë´ë§ˆí¬ ê³µëŒ€. ë¯¸ë˜ ìƒì„±í•˜ëŠ” ëª¨ë¸ ê°œë°œ.
multi-modal.. ì–¸ì–´ì™€ ì˜ìƒì„ í†µí•©í•˜ëŠ”?..
  ì–¸ì–´ëª¨ë¸?
  RNN-> LSTM -> Seq2Seq -> Attension -> Transformer -> GPT-1 -> BERT -> GPT-3 (2020) -> GPT-3.5 (2022)
    Long Short-Term Memory
    ğŸª± Hyperbolic tangentH..
    ì´ì „ì˜ ì…€ ìƒíƒœ

  RNN: ì–¸ì–´ì˜ ìˆœì„œ ì²˜ë¦¬ë¥¼ ìœ„í•´ recursiveí•œ path ìƒì„±. gradiant vanishing ë¬¸ì œ ìƒì„±.
  Attension: ë°ì´í„°ê°€ ìˆœì„œëŒ€ë¡œ ë“¤ì–´ê°€ì•¼í•´ì„œ batch ë¥¼ ì“°ê¸°ê°€ë„ˆë¬´ ì–´ë ¤ì›€. ë™ì‹œì— ë„£ì„ ìˆ˜ ìˆë„ë¡ Transformer ì—ì„œ ìˆœì„œë¥¼ í‘œì‹œí•  ìˆ˜ ìˆë„ë¡ ê°œì„ ..
Open source vs Private Models, 5-Shot MMLU Performance
  https://www.aitimes.com/news/articleView.html?idxno=155196
Non-sequential Data, Sequential Data
  ìˆœì„œê°€ ìˆëŠ” ì¸ê³µì‹ ê²½ë§ êµ¬ì¡°? ë²¡í„° í‘œí˜„?

ì‹œê°„ ê°œë…ì„ ë°˜ì˜í•  ìˆ˜ìˆëŠ” ì¸ê³µ ì‹ ê²½ë§..
  one ton one
  one to many
    image captioning?
  many to one
  many to many
    .. 2 ì¢…ë¥˜..
    ğŸª± Abnormal Score 
  encoading block? decoading block?
  forward path.. h_t = f
ë‹¨ì–´ ì„ë² ë”©.:ì»´í“¨í„°ê°€ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë‹¨ì–´ë¥¼ ë²¡í„°ë¡œ ë³€í™˜.
  tensor ì˜ embedding?
  ë‹¨ì–´ì˜ ê¸ì •/ë¶€ì •ì ì¸ ê²ƒì„ ë¶„ë¥˜?
  https://word2vec.kr/search/
Word2Vec -> CBOW, Skip gram.
  Continuous Bag of Words.
  Skip gram ëª¨ë¸
FastText // Facebook
ELMo- Embeddings from Language Models
Seq2Seq
  Neural Machine Translation...
  encoder--->
    LSTM (I) -> LSTM (am) -> LSTM (a) -> LSTM (student)..
  --> contenxt
  decoder
    LSTM(...) -> ...
  hideen layer ë‘ í•©ì³ì ¸ì…”?..
Attention
  ë‹¨ì–´ ê°„ì˜ ë‚´ì ì„ ê³„ì‚°í•œë‹¤. ìƒê´€ê´€ê³„; attension score?
  ??? Attention mechanism
  start of sentence?
  coefficient?
  >>>>> ì—¬ê¸°ì„œ key, query, value ê°€ íˆë“  ë²¡í„°ì¸ë° transformer ì—ì„œëŠ” hidden vector ê°€ ì•„ë‹ˆë¼ê³  í•œë‹¤? 
  ì»¨í…ìŠ¤íŠ¸ ë²¡í„°
  ë¬¸ì œì 
    ì…ë ¥ ì‹œí€¸ìŠ¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•´ì„œ ë³‘ë ¬ ì²˜ë¦¬  
positional encoading?
  sign(ì£¼íŒŒìˆ˜ + ...)
    ì£¼íŒŒìˆ˜ê°€ ë‹¤ë¥¸ ì• ë“¤ë¼ë¦¬ëŠ” ë‚´ì ì´ 0ì´ ëœë‹¤?ìœ„ì¹˜ë§ˆë‹¤ ì„œë¡œ ë‹¤ë¥¸ frequency ë¥¼ ..
Attention Is All You Need
  https://arxiv.org/abs/1706.03762
  .. "Add & Norm" ì´ batch ê°€ ì•„ë‹ˆë¼ layer normalization ë¼ëŠ”ë° ë¬´ìŠ¨ ëœ»ì´ì•¼?
  GPT ì—ì„œëŠ” ?? ë­ê°€ ë¹ ì§„ë‹¤ê³  í•¨..

  https://codingopera.tistory.com/43
  cross-attention
  maksed self-attention
  encoder-decoder cross-attention ?? ì´ê²Œ ë­ì•¼...
ğŸª± turn-by-turn navigation ; https://en.wiktionary.org/wiki/turn-by-turn_navigation#English
ğŸª± emergent abilities .. in GPT?
  in-context learning ? meta-learning? zero short inference ?
  GPT 3~ Hallucination ì œê±°.
  AI Open Community
RNN .. SimpleRNN ì—ì„œ(Return sequences=True) ???

ğŸŒŸ AI ì¸ê³µì§€ëŠ¥ ê²½ì§„ëŒ€íšŒ ; https://dacon.io/
  >>> keras vision ì½”ë“œ snippet ; https://keras.io/examples/vision/
    https://keras.io/examples/vision/video_classification/
      RNN; Sequentiald data.. ë™ì‘ íŒë‹¨.
      CNN-RNN ê°™ì´ ì‚¬ìš© ì´ìœ ?
    https://keras.io/examples/vision/video_transformers/

    ... https://keras.io/api/layers/attention_layers/multi_head_attention/

>> ì˜¤í”ˆë¹„ë…¸ -> ë¼ì¦ˆë² ë¦¬ íŒŒì´ì— ì˜¬ë ¤ì„œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥.



RNN: Abnormal Score: Min square error.... ë¡œ ì‚¬ìš©?? ì™œ?
  forward path.

ELMO ? deep contexturalized word Embeddings from Language Models
  BERT ì™€ ì°¨ì´? BERT ëŠ” encoderë§Œ ìˆì–´ì„œ ìˆœì„œëŒ€ë¡œ ë‚˜ì˜¤ì§€ ì•ŠëŠ”ë‹¤? ìì—°ì–´ ì²˜ë¦¬?
  gpt 5 sora 5

âš“ Convolutional Neural Network ; https://en.wikipedia.org/wiki/Convolutional_neural_network
  # Fully connected layers
    ğŸª± logit; ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’ì— ëŒ€í•œ ì„ í˜• ê²°í•© ??
      ì´ logitì€ ì •ë‹µ í™•ë¥ ë¡œ ë³€í™˜ë˜ì–´ì•¼ í•˜ëŠ”ë°, ê·¸ë•Œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ í™œì„± í•¨ìˆ˜ì…ë‹ˆë‹¤.
# Differentiable computing 
  # Concepts
    âš“ Activation function ; https://en.wikipedia.org/wiki/Activation_function
      # Contents
        The activation function of a node in an artificial neural network is a function that calculates the output of the node based on its individual inputs and their weights.
        #ï¸âƒ£ğŸ’¡ Mathematical details ; https://en.wikipedia.org/wiki/Activation_function#Mathematical_details
          # Ridge Activation Functions:
            - âš“ ReLU (Rectified Linear Unit) | rectifier ; https://en.wikipedia.org/wiki/Rectifier_(neural_networks)
              # Variant ; https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Variants
                - ELU (Exponential Linear Unit)
            - Leaky ReLU

          # Radial Activation Functions:
            - Radial Basis Function (RBF)
            - Gaussian Activation Function

          # Folding Activation Functions:
            - âš“ Sigmoid function ; https://en.wikipedia.org/wiki/Sigmoid_function
              ğŸª± sigmoid curve
            - Tanh (Hyperbolic Tangent)
            - âš“ Softmax function | Normalized exponential function | softargmax ; https://en.wikipedia.org/wiki/Softmax_function
              .. ì—¬ê¸°ì„œ z_iâ€‹ëŠ” **ì¶œë ¥ ë…¸ë“œ i**ì˜ logit, **N**ì€ í´ë˜ìŠ¤ì˜ ì´ ê°œìˆ˜ì…ë‹ˆë‹¤.

ğŸŒŸ Mathematical notation ; https://en.wikipedia.org/wiki/Mathematical_notation
  âš“ Hat notation ; https://en.wikipedia.org/wiki/Hat_notation
    In statistics, a circumflex (Ë†), called a "hat", is used to denote an estimator or an estimated value.
  << Mathematical operators and symbols in Unicode ; https://en.wikipedia.org/wiki/Mathematical_operators_and_symbols_in_Unicode
  << âš“ Glossary of mathematical symbols ; https://en.wikipedia.org/wiki/Glossary_of_mathematical_symbols
    # Calculus
      << âš“ cursive d ; https://en.wikipedia.org/wiki/%E2%88%82
        ... usually to denote a partial derivative such as âˆ‚ z / âˆ‚ x {\displaystyle {\partial z}/{\partial x}} (read as "the partial derivative of z with respect to x").
        ì–´ë–¤ ë³€ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê·¸ í•¨ìˆ˜ì˜ ë³€í™”ë¥¼ ì¸¡ì •í•œë‹¤ê³  í‘œí˜„í•˜ë¯€ë¡œ "with respect to" (; ~ì— ê´€í•˜ì—¬) ë¥¼ ì‚¬ìš©.
    # â„; Real number ; https://en.wikipedia.org/wiki/Real_number
    # â„â¿; Real coordinate space ; https://en.wikipedia.org/wiki/Real_coordinate_space
      â„Â¹, â„Â², â„Â³ ...
      Eâ¿ (Euclidean -)
      EÂ¹ (Euclidean line)
      EÂ² (Euclidean plane)
      EÂ³ (Euclidean three-dimensional space)
Hiddenì´ë¼ëŠ” ìš©ì–´ëŠ” ì…ë ¥ì¸µê³¼ ì¶œë ¥ì¸µ ì‚¬ì´ì—ì„œ ë°œìƒí•˜ëŠ” ì¤‘ê°„ ê³„ì‚°ì„ ì„¤ëª…í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤. RNNì—ì„œëŠ” ì€ë‹‰ ìƒíƒœê°€ ì´ì „ íƒ€ì„ìŠ¤í…ì˜ ì •ë³´ë¥¼ ì €ì¥í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ íƒ€ì„ìŠ¤í…ì— ì „ë‹¬ë©ë‹ˆë‹¤. ì´ë•Œì˜ ì¤‘ê°„ ì •ë³´ë“¤ì´ ì™¸ë¶€ì—ì„œëŠ” ë³´ì´ì§€ ì•Šì§€ë§Œ ì¤‘ìš”í•œ ì •ë³´ì´ë¯€ë¡œ **"Hidden"**ì´ë¼ê³  ë¶ˆë¦½ë‹ˆë‹¤.
1.
"""
Rectification (ì •ë¥˜) ê°œë…ì—ì„œ ì˜¨ ê²ƒì…ë‹ˆë‹¤. ì›ë˜ rectifierëŠ” êµë¥˜(AC)ë¥¼ ì§ë¥˜(DC)ë¡œ ë³€í™˜í•˜ëŠ” ì¥ì¹˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ReLUëŠ” ìŒìˆ˜ ì…ë ¥ì„ 0ìœ¼ë¡œ ë³€í™˜í•˜ëŠ”ë°, ì´ëŠ” ì „ê¸° ê³µí•™ì—ì„œ êµë¥˜ ì‹ í˜¸ì˜ ìŒìˆ˜ ê°’ì„ ì—†ì• ëŠ” ê³¼ì •ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤.
ReLUì˜ ìˆ˜ì‹:
ReLU(x)=maxâ¡(0,x)
ReLU(x)=max(0,x)

    ì…ë ¥ ê°’ì´ 0ë³´ë‹¤ í¬ë©´ ê·¸ëŒ€ë¡œ ì¶œë ¥ë˜ê³ , 0ë³´ë‹¤ ì‘ìœ¼ë©´ **0ìœ¼ë¡œ "ì •ë¥˜"**ë©ë‹ˆë‹¤.
"""
ë¥¼ ì˜ì–´ë¡œ. 


2. ì„ í˜•ì„±ê³¼ ë¹„ì„ í˜•ì„±ì„ ì˜ì–´ë¡œ. wikipedia ì— ë¬¸ì„œê°€ ìˆë‚˜?

Gradient Vanishing

Feed Forward ê°€ ë­ì•¼? Dense layer ë¼ê³  í•˜ëŠ”ê±´ê°€?


TODO: crawling
  python docs
  "sidebar" like in https://en.wikipedia.org/wiki/Softmax_function
  "navbox" like in https://en.wikipedia.org/wiki/Softmax_function

âš“ Functional Programming ; https://en.wikipedia.org/wiki/Functional_programming
  âš“ fold | reduce | accumulate | aggregate | compress | inject ; https://en.wikipedia.org/wiki/Fold_(higher-order_function)
    ğŸ’¡ ... refers to a family of higher-order functions that analyze a recursive data structure and through use of a given combining operation, recombine the results of recursively processing its constituent parts, building up a return value. 
CoCo format. 

ğŸ‘ Sites
  Youtube ìš”ì•½ - Lily
  Power Point AI ì¡°ìˆ˜ - Gamma https://gamma.app/
  Ai Video ìƒì„±ê¸° - https://www.heygen.com/

Ctrl + Shift + U. >> Unicode input
>>>>>>>>>>> VSCOde extension ; Unicode Latex https://marketplace.visualstudio.com/items?itemName=oijaz.unicode-latex
  X.. latex ë¬¸ë²•ê³¼ ì¡°ê¸ˆì”© ë‹¤ë¦„.
  or Latex - (Ctrl+Alt+X): Side bar tab - Snippet view  e.g. Letter syltes - \mathbb{R} 
>>>>>>>>>>> VSCOde extension ; Insret Unicode ; https://marketplace.visualstudio.com/items?itemName=brunnerh.insert-unicode
  â„ Double-STRUCK CAPTIAL R
  Advantages: human-readable.Â¹â‚
  e.g. superscript, subscript
  + math preview
  \(X^{sup}_{sub}\)

  \int_{a}^{b} f(x) \, dx
\( ax + by + cz + d = 0 \)
\[\frac{\partial}{\partial x} (ax + by + cz + d) = a, \quad \frac{\partial}{\partial y} (ax + by + cz + d) = b, \quad \frac{\partial}{\partial z} (ax + by + cz + d) = c\]
https://marketplace.visualstudio.com/items?itemName=Hyeon.c-math-viewer



TODO: https://en.wikipedia.org/wiki/Activation_function#Table_of_activation_functions
  https://en.wikipedia.org/wiki/Ridge_function
Gaussian-error linear unit (GELU)

in https://docs.nvidia.com/cuda/cuda-installation-guide-linux/ ğŸ“… 2024-09-23 09:14:56
  lspci | grep -i nvidia
  uname -m && cat /etc/*release
  gcc --version
  # https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=24.04&target_type=deb_network
  
  # CUDA Toolkit Installer
  wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb && \
  sudo dpkg -i cuda-keyring_1.1-1_all.deb && \
  sudo apt update -y && \
  sudo apt -y install cuda-toolkit-12-6

  # Install the open-source NVIDIA driver
  # `nvidia-open` is based on NVIDIA's open-source kernel module, offering better compatibility with the Linux kernel and allowing the community to contribute and access the code.
  sudo apt install -y nvidia-open
  
  # checks your system for hardware components (like GPUs) and shows the available drivers for them
  sudo ubuntu-drivers devices

  # Install the proprietary NVIDIA driver
  # `nvidia-driver-560` is a closed-source driver provided by NVIDIA, optimized for performance in tasks like gaming, machine learning, and other GPU-accelerated workloads.
  sudo apt install -y nvidia-driver-560

  # ...  13. Post-installation Actions ; https://docs.nvidia.com/cuda/cuda-installation-guide-linux/#post-installation-actions
  echo 'export PATH=/usr/local/cuda-12.6/bin${PATH:+:${PATH}}' >> ~/.bashrc
  echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.6/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}' >> ~/.bashrc
  
  ## â¡ï¸ Reboat your computer
  # 13.2. Recommended Actions
  # 13.2.1. Install Persistence Daemon
  #  CUDA Samples are now located in https://github.com/nvidia/cuda-samples, which includes instructions for obtaining, building, and running the samples.
  #   NVIDIA is providing a user-space daemon on Linux to support persistence of driver state across CUDA job runs. The daemon approach provides a more elegant and robust solution to this problem than persistence mode. For more details on the NVIDIA Persistence Daemon, see the documentation here.
  #   The NVIDIA Persistence Daemon can be started as the root user by running:
  sudo /usr/bin/nvidia-persistenced --verbose
  # it may be already run. check by either of 
  #   sudo cat /var/log/syslog | grep nvidia
  #   sudo journalctl -xe | grep nvidia
  ps aux | grep nvidia-persistenced
  sudo nvidia-smi -pm 1
  # you can check persistence mode by $shell> nvidia-smi
  
  # 13.2.3. IDE Integration
  #  âš“ Nsight Visual Studio Code Edition ; https://marketplace.visualstudio.com/items?itemName=NVIDIA.nsight-vscode-edition

  # 13.2.2. Install Writable Samples ; https://github.com/nvidia/cuda-samples

https://docs.ultralytics.com/#yolo-a-brief-history
YOLOv8 is the latest version of YOLO by Ultralytics. 

  https://docs.ultralytics.com/datasets/detect/coco/

yolo 8
  âš“ğŸš£ Yolo clsses name ;
    https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml
  # https://github.com/ultralytics/ultralytics
  git clone https://github.com/ultralytics/ultralytics.git
  ğŸ‘ IDE integration; https://docs.ultralytics.com/integrations/vscode/
    https://marketplace.visualstudio.com/items?itemName=Ultralytics.ultralytics-snippets

wbfw109v2@wbfw109v2-500TFA-500SFA ~/r/i/p/python-study (main) [1]> poetry add torch=^2.4.1
  Updating dependencies
  Resolving dependencies... (0.4s)

  Because no versions of torch match >2.4.1,<3.0.0
  and torch (2.4.1) depends on nvidia-cudnn-cu12 (9.1.0.70), torch (>=2.4.1,<3.0.0) requires nvidia-cudnn-cu12 (9.1.0.70).
  And because tensorflow[and-cuda] (2.17.0) depends on nvidia-cudnn-cu12 (8.9.7.29)
  and no versions of tensorflow match >2.17.0,<3.0.0, torch (>=2.4.1,<3.0.0) is incompatible with tensorflow[and-cuda] (>=2.17.0,<3.0.0).
  So, because python-study depends on both tensorflow[and-cuda] (^2.17.0) and torch (^2.4.1), version solving failed.

  CUDAì™€ cuDNNì„ ì§ì ‘ ì„¤ì¹˜í•œ í›„ì—ëŠ” tensorflowë¥¼ tensorflow[and-cuda] ì—†ì´ë„ GPUì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. tensorflow ê¸°ë³¸ íŒ¨í‚¤ì§€ ìì²´ëŠ” CPUì™€ GPU ëª¨ë‘ì—ì„œ ë™ì‘í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì–´ ìˆìœ¼ë©°, ì‚¬ìš©ìê°€ CUDA ë° cuDNNì„ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  â¡ï¸ tensorflow ì—ì„œ ì§€ì¹¨ëŒ€ë¡œ ì„¤ì¹˜í–ˆë”ë‹ˆ ë¬¸ì œê°€ ë˜ëŠ”ë“¯.. tensorflow[and-cuda] ë¥¼ ì§€ìš°ê³  cuda ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì„¤ì¹˜í•´ë³´ì. tensorflow ë§Œ ì„¤ì¹˜ë˜ë„ë¡ í•´ë³´ì.

>>>>>>>> bash script
  Shell Parameter Expansion ; https://www.gnu.org/software/bash/manual/html_node/Shell-Parameter-Expansion.html
    ${parameter:+word}
    ğŸ›ï¸e.g. idiom
      export PATH=/usr/local/cuda-12.6/bin${PATH:+:${PATH}}


Ubuntu ESM (Expanded Security Maintenance)
# if remote os is linux, ... otherwise it may requires Xming, XQuartz
sudo apt install -y xauth
xauthë€?
  xauthëŠ” "X Authority"ì˜ ì•½ìì´ë©°, X11 ì„œë²„ê°€ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì ‘ê·¼ ê¶Œí•œì„ ë¶€ì—¬í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ì¸ì¦ ì •ë³´ë¥¼ ê´€ë¦¬í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. X11ì€ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ê·¸ë˜í”½ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì „ì†¡í•  ìˆ˜ ìˆëŠ”ë°, ì´ë•Œ í´ë¼ì´ì–¸íŠ¸ê°€ X ì„œë²„ì— ì ‘ê·¼í•  ë•Œ ê¶Œí•œì„ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. xauthëŠ” ì´ëŸ¬í•œ ì ‘ê·¼ì„ ìœ„í•œ ì¸ì¦ íŒŒì¼(.Xauthority íŒŒì¼)ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
  X11 í¬ì›Œë”©ì„ ì‚¬ìš©í•  ë•Œ, ì›ê²© ì„œë²„ê°€ ë¡œì»¬ X ì„œë²„ì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ ì¸ì¦ ì •ë³´ë¥¼ ê³µìœ í•˜ëŠ” ì—­í• ì„ í•˜ë©°, ì›í™œí•œ ê·¸ë˜í”½ ì „ì†¡ì— í•„ìš”í•©ë‹ˆë‹¤.
choco install vcxsrv
  https://community.chocolatey.org/packages/vcxsrv
  %shell: Powershell> XLuanch
    Select display settings; Choose how Xming displays programs
      âœ”ï¸ Multiple Windows
    Select how to start Xming; Choose session type and whether a client is tsarted immediately.
      âœ”ï¸ Start no client
        This will just start Xming. You will be able to start local clients layer.
    Speicify paraemter settings; Enter clipboard, remote font server, and all other parameters.
      âœ”ï¸ Clipboard
    ... ğŸ“°ğŸ“ Can not find Native OpenGL option
      
nameserverì˜ ì˜ë¯¸ì™€ ìœˆë„ìš° IP ì£¼ì†Œ: cat /etc/resolv.conf | grep nameserver ëª…ë ¹ì€ WSL2ì˜ ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì—ì„œ DNS ì„œë²„ ì£¼ì†Œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ nameserverëŠ” ì¼ë°˜ì ìœ¼ë¡œ ìœˆë„ìš° ì‹œìŠ¤í…œì˜ ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ IP ì£¼ì†Œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ IP ì£¼ì†ŒëŠ” WSL2ê°€ ìœˆë„ìš°ì™€ í†µì‹ í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ì—ì„œ í• ë‹¹ëœ ê²ƒìœ¼ë¡œ, ë¡œì»¬ ìœˆë„ìš°ì˜ X ì„œë²„ì™€ í†µì‹ í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
  

https://docs.openvino.ai/2024/notebooks/async-api-with-output.html
OpenVINO Training Extensions ; https://openvinotoolkit.github.io/training_extensions/stable/guide/get_started/introduction.html
  https://openvinotoolkit.github.io/training_extensions/stable/guide/get_started/installation.html#install-openvino-training-extensions-for-users-cuda-cpu
  https://openvinotoolkit.github.io/training_extensions/stable/guide/get_started/installation.html#run-tests
mermaid ê·¸ë˜í”„ì— ì¶”ê°€.
  tensort / openvino .. 
  .
âš“ https://docs.docker.com/engine/install/ubuntu/
  #ï¸âƒ£ Uninstall old versions ; https://docs.docker.com/engine/install/ubuntu/#uninstall-old-versions
  #ï¸âƒ£ Instasll using the apt repository
# Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc
# Add the repository to Apt sources:
echo "deb [arch=(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu (source /etc/os-release; echo $VERSION_CODENAME) stable" \
    | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
# Update the package list:
sudo apt-get update
https://docs.docker.com/desktop/install/linux/
https://docs.docker.com/desktop/install/linux/ubuntu/
sudo apt-get update
sudo apt-get install ./docker-desktop-<arch>.deb
# install docker
sudo apt install -y docker.io
GPG stands for GNU Privacy Guard, a cryptographic system used to verify the integrity and authenticity of downloaded files or software. In the context of Docker installation, the GPG key is used to ensure that the Docker packages you're installing are indeed from the official Docker repository and havenâ€™t been tampered with.
sudo apt-get install ca-certificates curl gnupg lsb-release
ğŸ†šğŸ“° Why is apt-key being deprecated? keyrings....
ğŸ›º automation script: install docker ğŸ”— https://docs.docker.com/engine/install/ubuntu/
  # Add Docker's official GPG key:
  sudo apt update -y
  sudo apt install -y ca-certificates curl
  sudo install -m 0755 -d /etc/apt/keyrings
  sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
  sudo chmod a+r /etc/apt/keyrings/docker.asc
  # Add the repository to Apt sources:
  bash -c 'echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null'
  # 
  sudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
  sudo chown -R $USER:$USER ~/.docker
  #
  sudo systemctl status docker
  sudo systemctl start docker
  sudo systemctl enable docker
  
  # 
  sudo docker run hello-world
ğŸš£ OTX as docker
  git clone https://github.com/openvinotoolkit/training_extensions.git
  cd training_extensions/docker
  bash ./build.sh
  docker image ls | grep otx
  export OTX_VERSION=2.1.0
  docker run -it --rm -v ~/data:/workspace/data otx:${OTX_VERSION}-cuda /bin/bash
  docker run -it --rm otx:${OTX_VERSION}-cuda otx train --task classification --model mobilenet_v2 --train-data /tmp/train --val-data /tmp/val --output /tmp/output
sudo update-alternatives --install /usr/bin/python python /usr/bin/python3 1
ModuleNotFoundError: No module named 'otx'
  poetry shellë¡œ ê°€ìƒí™˜ê²½ì„ í™œì„±í™”í•œ ìƒíƒœì—ì„œ sudoë¥¼ ì‚¬ìš©í•˜ë©´, root ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰ë˜ê¸° ë•Œë¬¸ì— ê°€ìƒí™˜ê²½ì´ ì œëŒ€ë¡œ ì ìš©ë˜ì§€ ì•ŠëŠ” ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤. sudoëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìƒˆë¡œìš´ ì„¸ì…˜ì—ì„œ ì‹¤í–‰ë˜ê¸° ë•Œë¬¸ì—, í˜„ì¬ í™œì„±í™”ëœ ê°€ìƒí™˜ê²½ ì •ë³´ê°€ root ì‚¬ìš©ìì—ê²Œ ì „ë‹¬ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ë•Œë¬¸ì— ModuleNotFoundErrorê°€ ë°œìƒí•œ ê²ƒì…ë‹ˆë‹¤.
  cd ~/repo/intel-edge-academy-6/prototypes/python-study && poetry shell
  docker build ëª…ë ¹ì–´ê°€ ê¸°ë³¸ì ìœ¼ë¡œ root ê¶Œí•œì„ í•„ìš”ë¡œ í•˜ê¸° ë•Œë¬¸ì¼ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, ê¸°ë³¸ì ìœ¼ë¡œ DockerëŠ” sudo ì—†ì´ ì‹¤í–‰ë  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, Dockerë¥¼ sudo ì—†ì´ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ê¶Œí•œ ì„¤ì •ì„ í•´ë‘ì§€ ì•Šì•˜ì„ ê²½ìš° sudoê°€ í•„ìš”í•˜ê²Œ ë©ë‹ˆë‹¤.
    # -a: append. G: group
    sudo usermod -aG docker $USER
    newgrp docker # new group
CDMA; LTE, 5G
https://github.com/tailscale/tailscale/issues/5160





nvidia-persistenced
  Roles
    - GPU ë“œë¼ì´ë²„ ìƒíƒœ ìœ ì§€: nvidia-persistenced ë°ëª¬ì€ GPUì˜ ë“œë¼ì´ë²„ ìƒíƒœë¥¼ ì—¬ëŸ¬ ì‘ì—… ì‚¬ì´ì— ìœ ì§€í•©ë‹ˆë‹¤. ì´ëŠ” GPUê°€ ì‘ì—…ì„ ì¢…ë£Œí•  ë•Œë§ˆë‹¤ ë“œë¼ì´ë²„ê°€ í•´ì œë˜ê³  ë‹¤ì‹œ ë¡œë“œë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
    - ì„±ëŠ¥ í–¥ìƒ: ë“œë¼ì´ë²„ ìƒíƒœë¥¼ ìœ ì§€í•¨ìœ¼ë¡œì¨, ì‘ì—… ê°„ ë“œë¼ì´ë²„ ë¡œë“œ ë° ì´ˆê¸°í™” ì‹œê°„ì„ ì¤„ì´ê³  ì„±ëŠ¥ì„ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  WSL ì—ì„œ flask ë¡œ model ì„ ì¶”ë¡ í•˜ê³  ëŒë ¤ë³´ë‚´ì£¼ëŠ” ì„œë²„ë¥¼ ë§Œë“¤ ë–„ ë¡œë”©ì‹œê°„ì´ ë§¤ìš° ê¸¸ì–´ì§ˆ ìˆ˜ ìˆë‹¤. (ì´ì „ ê²½í—˜...)
    nvidia-persistencedê°€ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ìƒí™©ì´ ë°”ë¡œ ê·¸ëŸ° ê²½ìš°ì…ë‹ˆë‹¤. Flask ì„œë²„ì—ì„œ ëª¨ë¸ ì¶”ë¡ ì„ ìˆ˜í–‰í•  ë•Œ, íŠ¹íˆ WSL í™˜ê²½ì—ì„œ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ë“œë¼ì´ë²„ê°€ ì´ˆê¸°í™”ë˜ëŠ” ë° ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§¤ë²ˆ ìƒˆë¡œìš´ ì¶”ë¡  ìš”ì²­ì´ ë“¤ì–´ì˜¬ ë•Œ GPUê°€ ë‹¤ì‹œ ì´ˆê¸°í™”ë˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆê³ , ì´ë¡œ ì¸í•´ ê¸´ ë¡œë”© ì‹œê°„ì´ ìƒê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


Current pwd: /home/wbfw109v2/repo/intel-edge-academy-6 
  e.g. %shell>
    yolo train data=/home/wbfw109v2/datasets/kct-yh2hv-cat_dog_dataset-2023-01-30-2015/data.yaml model=yolov8n.pt epochs=10 batch=4 && \
    yolo val data=/home/wbfw109v2/datasets/kct-yh2hv-cat_dog_dataset-2023-01-30-2015/data.yaml model=yolov8n.pt split=test && \
    # check result files in /home/wbfw109v2/datasets/kct-yh2hv-cat_dog_dataset-2023-01-30-2015/runs/detect/val. you can see also confusion_matrix.png


yolo v8
wbfw109v2@wbfw109v2-500TFA-500SFA ~/r/intel-edge-academy-6 (main)> yolo help

    Arguments received: ['yolo', 'help']. Ultralytics 'yolo' commands use the following syntax:

        yolo TASK MODE ARGS

        Where   TASK (optional) is one of {'detect', 'segment', 'pose', 'classify', 'obb'}
                MODE (required) is one of {'benchmark', 'predict', 'train', 'val', 'track', 'export'}
                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.
                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'

    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01
        yolo train data=coco8.yaml model=yolov8n.pt epochs=10 lr0=0.01

    2. Predict a YouTube video using a pretrained segmentation model at image size 320:
        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320

    3. Val a pretrained detection model at batch-size 1 and image size 640:
        yolo val model=yolov8n.pt data=coco8.yaml batch=1 imgsz=640

    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)
        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128

    5. Explore your datasets using semantic search and SQL with a simple GUI powered by Ultralytics Explorer API
        yolo explorer data=data.yaml model=yolov8n.pt
    
    6. Streamlit real-time webcam inference GUI
        yolo streamlit-predict
        
    7. Run special commands:
        yolo help
        yolo checks 
        yolo version
        yolo settings
        yolo copy-cfg
        yolo cfg

    Docs: https://docs.ultralytics.com
    Community: https://community.ultralytics.com
    GitHub: https://github.com/ultralytics/ultralytics

    yolo train --data 



Road Traffic Controller
traffic controller Hand Gesture

#!/bin/bash
sudo chmod 664 /mnt/gdrive/book/*

ì‹¤ë¬´ì—ì„œëŠ”
yolo8
  torch

ë¹„ë³´í˜¸ ì¢ŒíšŒì „ ë³´ì¡° ì‹œìŠ¤í…œ.
ë¹„ë³´í˜¸ ì‚¬ê³ ëŸ‰ ê°ì†Œ ë° ê°œë… í™•ë¦½.

ADAS ì‹œìŠ¤í…œ ìˆ˜ì‹ í˜¸
  Dataset download
    wget --recursive --no-parent --no-host-directories --cut-dirs=3 --reject "index.html*" https://mwt-www.e-technik.uni-ulm.de/downloads/publicData/Kern2023/misc/


%shell>  # check directory structure
  wget --spider --recursive --no-parent https://mwt-www.e-technik.uni-ulm.de/downloads/publicData/Kern2023/
  rclone tree https://mwt-www.e-technik.uni-ulm.de/downloads/publicData/Kern2023/
  rclone lsf --recursive https://mwt-www.e-technik.uni-ulm.de/downloads/publicData/Kern2023/



ğŸ†š ROI, bounding box
  https://universe.roboflow.com/yolodataset/person-dataset-mvbk4
2024/05/24
  âœ”ï¸ latex
    for file in note/sorted_note/*.tex; latexmk -pdf -lualatex -synctex=1 -interaction=nonstopmode -auxdir=/tmp -outdir=(pwd)/build/note $file; end

    latexmk -pdf -lualatex -synctex=1 -interaction=nonstopmode -f -auxdir=/tmp -outdir=$(pwd)/build/note note/sorted_note/about_vector.tex
    for file in note/sorted_note/*.tex; latexmk -pdf -lualatex -synctex=1 -interaction=nonstopmode -f -auxdir=$(pwd)/build/tmp -outdir=$(pwd)/build/note $file; end
    EXINPUTS=.:$(pwd)/note/sorted_note//: latexmk -pdf -lualatex -synctex=1 -interaction=nonstopmode -f -auxdir=/tmp -outdir=$(pwd)/build/note note/sorted_note/*.tex

    env TEXINPUTS=.:$PWD/note/sorted_note//: latexmk -pdf -lualatex -synctex=1 -interaction=nonstopmode -f -auxdir=$PWD/build/note -outdir=$PWD/build/note $PWD/note/sorted_note/about_vector.tex
    >>> ğŸ…¾ï¸ env TEXINPUTS=.:$PWD/note/sorted_note//: latexmk -pdf -lualatex -synctex=1 -interaction=nonstopmode -auxdir=$PWD/build/note -outdir=$PWD/build/note $PWD/note/sorted_note/about_vector.tex -f
  âœ”ï¸âœ… (how); study scanned Book
    * orders
      1. Download Pdf viewer
        * For Windows, https://community.chocolatey.org/packages/okular
          %shell> choco install okular
        * For Linux, https://snapcraft.io/okular
          %shell> snap install okular
      2. Syncrhonize Google Drive
        * For Windows, https://community.chocolatey.org/packages/googledrive
          %shell> choco install googledrive
          and drag and drop any unused files, right-click and set 'Offline Access - âœ”ï¸ Available offline'.

        * For Linux
          use Rclone (MIT License)
            https://rclone.org/
            https://en.wikipedia.org/wiki/Rclone
            https://github.com/rclone/rclone
          Install ; https://rclone.org/downloads/
            sudo -v ; curl https://rclone.org/install.sh | sudo bash && \ 
            rclone config
            # ... many settings..; e.g. 19: google drive
          ğŸ›ï¸ e.g. 
            Google cloud API wbfw109v2 Oauth client json file.
              OAuth client created
                Client ID
                    279512517955-mlohe28s7f294fv996t4c6j9b3fjv98i.apps.googleusercontent.com
                Client secret
                    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
                Creation date
                    September 10, 2024 at 10:07:42 AM GMT+9
                The client ID and secret can always be accessed from Credentials in APIs & Services 
            https://rclone.org/drive/#making-your-own-client-id
            https://console.cloud.google.com/apis/library/drive.googleapis.com?project=inner-geography-435200-k4&supportedpurview=project
            https://en.wiktionary.org/wiki/consent
            https://developers.google.com/drive/api/guides/api-specific-auth
            https://developers.google.com/identity/protocols/oauth2/
            https://support.google.com/cloud/answer/10311615#user-type
          Syncrhonize  
            # ??? not use mount location as /mnt/. it requires permission when save file in pdf viewer Ockular
            ğŸ›ï¸ e.g. %shell> sudo rclone --config ~/.config/rclone/rclone.conf sync gdrive:book ~/drive/gdrive/book
            //ğŸ“ ì“°ê¸° ê¶Œí•œ ë¶€ì—¬í•˜ê¸°!!
              sudo chown -R $USER:$USER ~/drive
              sudo chmod -R u+w ~/drive
              

        â“...1ì£¼ì¼ë§ˆë‹¤ í† í° ë°œê¸‰ë°›ì•„ì•¼í•˜ë‚˜? dd.. ì¸ì¦í™”ë©´ì´ëœ¬ë‹¤ê³  í•œë‹¤.. rclone ì—ì„œ íŒŒì¼ë™ê¸°í™” ë˜ëŠ” ì ‘ê·¼í•˜ëŠ” ëª…ë ¹ ì‚¬ìš© ì‹œ..
          ë˜ëŠ” ìˆ˜ë™ ê°±ì‹  ëª…ë ¹ sudo rclone sync gdrive:book /mnt/gdrive/book
        >>> sudo rclone sync gdrive:book /mnt/gdrive/book
        # Check the list of all configured remotes (such as Google Drive, OneDrive, etc.)
        sudo rclone listremotes --config ~/.config/rclone/rclone.conf
      
        ### synchronize when you want
        ## â­• firstly use with flag --dry-run for safe operation
        ## Use this when you want to download or update the local folder with the latest changes from Google Drive.
        # upload from local file to remote file
        # sudo rclone sync ~/drive/gdrive/book gdrive:book --config ~/.config/rclone/rclone.conf

        # Use this when you want to upload or update the Google Drive folder with the latest changes from the local folder.
        

        rclone mountëŠ” ì›ê²© ë“œë¼ì´ë¸Œë¥¼ íŒŒì¼ ì‹œìŠ¤í…œì²˜ëŸ¼ ë‹¤ë£¨ì§€ë§Œ, íŒŒì¼ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì¦‰, PDF íŒŒì¼ì„ ìˆ˜ì •í•  ë•Œë§ˆë‹¤ ì „ì²´ íŒŒì¼ì´ ë‹¤ì‹œ ì—…ë¡œë“œë©ë‹ˆë‹¤. ë”°ë¼ì„œ PDF íŒŒì¼ì— ì£¼ì„ì„ ì¶”ê°€í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ë©´, íŒŒì¼ ì „ì²´(ì˜ˆ: 300MB)ë¥¼ ë‹¤ì‹œ ì—…ë¡œë“œí•˜ê²Œ ë©ë‹ˆë‹¤. rclone mountëŠ” íŒŒì¼ì˜ ì¼ë¶€ë§Œ ë³€ê²½í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ì‘í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—, ì£¼ì„ë§Œ ìˆ˜ì •ëœ ê²½ìš°ì—ë„ ì „ì²´ íŒŒì¼ì„ ë‹¤ì‹œ ë™ê¸°í™”í•©ë‹ˆë‹¤.  
        ì¼ë¶€ í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ì„œë¹„ìŠ¤ëŠ” ë„¤ì´í‹°ë¸Œ í´ë¼ì´ì–¸íŠ¸(ì˜ˆ: Google Driveì˜ ê³µì‹ í´ë¼ì´ì–¸íŠ¸)ì—ì„œ ì°¨ë“± ë™ê¸°í™”(íŒŒì¼ì˜ ì¼ë¶€ë§Œ ë³€ê²½ëœ ê²½ìš°, ê·¸ ë¶€ë¶„ë§Œ ì—…ë¡œë“œ)ë¥¼ ì§€ì›í•  ìˆ˜ ìˆì§€ë§Œ, rcloneì—ì„œëŠ” ì´ëŸ¬í•œ ê¸°ëŠ¥ì´ ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

        ğŸš¨ (issue): bug; Could not open file:///home/wbfw109v2/drive/gdrive/book/...
          ë§Œì•½ Snapìœ¼ë¡œ ì„¤ì¹˜ëœ Okularì—ì„œ ì´ëŸ¬í•œ ë¬¸ì œê°€ ë°œìƒí–ˆë‹¤ë©´, Snapì˜ ë³´ì•ˆ ìƒŒë“œë°•ìŠ¤ ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš° Snap ëŒ€ì‹  aptë¡œ ì„¤ì¹˜ëœ ë²„ì „ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
            ...
          sudo snap remove okular
          sudo apt update
          sudo apt install -y okular
        O ë§ìŒ;;
  >>>>>
    ë™ì‘íŒë³„ì„ ìœ„í•œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì‚¬ìš©ë°©ë²• ì²´í¬
    âš“ Hierarchical Data Format (HDF) ; https://en.wikipedia.org/wiki/Hierarchical_Data_Format
    * Action recognition

    * Action recognition
      - PoseC3D: A newer approach that uses a combination of pose information and 3D convolutions to detect actions based on pose sequences.
        It's a top choice for cases where the focus is on human movements rather than environmental context.

    rtxa 6000...  
      ë¹Œë¦´ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤.


tech_stack
  remote_acces_tools
    anydesk.txt
  langugae
    c++
    


ğŸ“°ë©´ì ‘.. NVIDIA TensorRT vs. Cuda vs OpenVINO
  CUDA is a parallel computing platform and programming model created by NVIDIA.
  TensorRT is an SDK designed specifically for deep learning inference acceleration on NVIDIA GPUs.

  TensorRT
  pytorch -> .pt
  keras -> .keras

ğŸš£ Labeling tool
  https://www.cvat.ai/



https://docs.opencv.org/4.x/d4/dd5/highgui_8hpp.html
  https://docs.opencv.org/4.x/d7/dfc/group__highgui.html#ga89e7806b0a616f6f1d502bd8c183ad3e 
  typedef void(* 	cv::MouseCallback) (int event, int x, int y, int flags, void *userdata)
    Callback function for mouse events. see cv::setMouseCallback. More...
  typedef void(* 	cv::TrackbarCallback) (int pos, void *userdata)
    Callback function for Trackbar see cv::createTrackbar. More...
https://docs.opencv.org/4.x/dc/d4d/tutorial_py_table_of_contents_gui.html
  https://docs.opencv.org/4.x/db/d5b/tutorial_py_mouse_handling.html
  https://docs.opencv.org/4.x/d9/dc8/tutorial_py_trackbar.html



Ctrl + Alt + -
Ctrl + Shift + -

>>>>>>>> in fish, poetry add (grep -v '^#' requirements.txt)

https://github.com/openvinotoolkit/openvino_notebooks/tree/2023.1/notebooks/001-hello-world

poetry add openvino>=2024.2.0 nncf>=2.11.0
poetry source add pytorch https://download.pytorch.org/whl/cpu
poetry add --source pytorch "surya-ocr==0.4.0" torch datasets "gradio>=4.19" Pillow


poetry add openvino nncf
poetry add torch datasets
poetry add openvino nncf surya-ocr torch datasets gradio pillow

sudo apt install python3-tk
import matplotlib
matplotlib.use("TKAgg")


os.environ["GIT_CLONE_PROTECTION_ACTIVE"] = "false"

%pip install -q "openvino>=2024.2.0" "nncf>=2.11.0"
%pip install -q --extra-index-url https://download.pytorch.org/whl/cpu "surya-ocr==0.4.0" torch datasets "gradio>=4.19" Pillow


????????????
AVX-512 ????
  ROcm

Distribution  ì´ pip, openvino archives, apt, github ë¡œ  ë§ë˜ë° ë­ë¡œ ì„¤ì¹˜ í•´ì•¼ í•˜ì§€? https://docs.openvino.ai/2024/get-started/install-openvino.html?PACKAGE=OPENVINO_BASE&VERSION=v_2024_4_0&OP_SYSTEM=LINUX&DISTRIBUTION=ARCHIVE
Machine leraning Pipeline; MLOps
  DL Type
  Data preparation
  Train
  Optimization
  Deployment
Open VINo ; https://en.wikipedia.org/wiki/OpenVINO
  https://github.com/openvinotoolkit/openvino_notebooks/tree/2023.1/notebooks/004-hello-detection
  https://github.com/openvinotoolkit/openvino_notebooks/tree/2023.1/notebooks/003-hello-segmentation
  https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/notebooks/vehicle-detection-and-recognition/vehicle-detection-and-recognition.ipynb
  Monodepth Estimation with OpenVINO ; https://docs.openvino.ai/2024/notebooks/vision-monodepth-with-output.html
  Image Background Removal with U^2-Net and OpenVINO ; https://docs.openvino.ai/2024/notebooks/vision-background-removal-with-output.html
  Background removal with RMBG v1.4 and OpenVINO ;   https://docs.openvino.ai/2024/notebooks/rmbg-background-removal-with-output.html
  Live Object Detection with OpenVINOâ„¢ ; https://docs.openvino.ai/2024/notebooks/object-detection-with-output.html

  https://github.com/openvinotoolkit/open_model_zoo
  Used Docs in classrooms
    https://github.com/kccistc/intel-05
    openvinotoolkit/openvino_notebooks: ğŸ“š Jupyter notebook tutorials for OpenVINOâ„¢
    
    git clone --recurse-submodules https://github.com/kccistc/intel-05.git
    git clone --dept=1 https://github.com/openvinotoolkit/openvino_notebooks.git

  âš“ GitHub OpenVino Notebooks ; https://github.com/openvinotoolkit/openvino_notebooks
    ğŸ‘ notebooks search by category ; https://openvinotoolkit.github.io/openvino_notebooks/?search=hello+image
      from https://github.com/openvinotoolkit/openvino_notebooks/tree/latest/notebooks
      
    # Hello Image Classification
    Line-level text detection with Surya ; https://docs.openvino.ai/2024/notebooks/surya-line-level-text-detection-with-output.html

    Getting Started
    Convert & Optimize
    Model Demos
    Model TrainingLive demos
  Open Visual Inferencing and Neural network Optimization
  ONNX -> IR í¬ë§·ìœ¼ë¡œ ëª¨ë¸ ì €ì¥.
  intel N100
  https://coral.ai/

  hOW oPENvINO WORKS?
    MODEL
      ...model training..
      Open Model Zoo
      Model compression

    OPTIMIZE
      Model Conversion API & Tools
      Training optimiztion with NNCF
      Intel Developer Cloud for the Edge
    DEPLOY
      OpenVINO Model Server
      OpenVINO Runtime
        Primary CPU and GPU Options
        xeon, core, atom, arm, iris, arc, gpu
        Secondary VPU and FPGA Options
          VPU .. https://en.wikipedia.org/wiki/Movidius
          ğŸ‘ğŸ“° FPGA // í”„ë¡œê·¸ë˜ë°ì„ ê±°ì³ì„œ íšŒë¡œë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆë‹¤ê³  í•œë‹¤.

      Intel, arm coretex
  Benefits of OpenVINO
    6ì„¸ëŒ€ì´ìƒë¶€í„° ì§€ì› ê°€ëŠ¥.. í–‰ë ¬ì—°ì‚°ì´ ê°€ëŠ¥í•˜ë‹¤ê³  í•¨?
    10 ~ 11 ì„¸ëŒ€ì—ì„œ instruction set ì´ ëˆ„ë½ëœ ì œí’ˆë„ ìˆì–´ì„œ ì˜ ë´ì•¼ í•œë‹¤ê³  í•¨.
  Caching model
    GPU ë“±ê³¼ ê°™ì´ loading time ì´ ê¸´ device ë“¤ì€ cache ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ 2ë²ˆì§¸ ì‚¬ìš©ë¶€í„°ëŠ” loading íƒ€ì„ì„ ìµœì†Œí™” í•  ìˆ˜ ìˆë‹¤.
    isReadNetwork
    ...
cat /proc/cpuinfo




%shell> lspci

ì°¨ëŸ‰ CAN í†µì‹ 
  acc acc active.
  ì¡°í–¥ê°
  NVIDIA Jetson TX2 
  ì™¸ì¥ ë°°í„°ë¦¬..
  ROS
  ğŸ‘ ìŠ¤í…Œë ˆì˜¤ìŠ¤ì½”í”¼ ì¹´ë©”ë¼ë¥¼ í™œìš©í•œ ë¹„ì „ ê¸°ìˆ .. ë¡œë´‡ íšŒì‚¬ë“¤
  ì§ˆê° ì²˜ë¦¬ë„ í•„ìš”í•œê°€?
  Image Background Removal with U^2-Net and OpenVINO
>>>>>>> âš™ï¸ settings: Firefox - Add-ons and themes     // change Menu bar color.
  Manage Your Themes
    https://addons.mozilla.org/en-US/firefox/addon/beautiful-dark-wall/?utm_source=addons.mozilla.org&utm_medium=referral&utm_content=search
>>>>>>> 0 settings: Ubuntu - Okular change Menu bar titles
  code  ~/.config/okularrc
  code /usr/share/plasma/desktoptheme/breeze-dark/colors

  sudo apt install kde-style-breeze kde-standard plasma-workspace


configure sddm
  gdm3 vs sddm

https://www.reddit.com/r/kde/comments/7ww4ja/changing_okular_colour_scheme/

poetry show openvino-dev

Released: Sep 19, 2024
  %shell> omz_
  omz_downloader --print_all
  omz_downloader --help

import https://docs.python.org/3/library/tkinter.html
  it requirses.. sudo apt-get install python3-tk
  poetry add ultralytics 
    https://github.com/ultralytics/assets/releases/

  /tmp/ipykernel_59372/2076527990.py:15: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.
    cmap = matplotlib.cm.get_cmap(colormap)
  Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolo_nas_s.pt to 'yolo_nas_s.pt'...
  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83.3M/83.3M [04:46<00:00, 305kB/s]
  WARNING âš ï¸ yolo_nas_s.pt appears to require 'super_gradients', which is not in Ultralytics requirements.
  AutoInstall will run now for 'super_gradients' but this feature will be removed in the future.
  Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official Ultralytics model, i.e. 'yolo predict model=yolov8n.pt'
  requirements: Ultralytics requirement ['super_gradients'] not found, attempting AutoUpdate...


def normalize_minmax(data):
    return (data - data.min()) / (data.max() - data.min())


https://matplotlib.org/stable/api/cm_api.html#matplotlib.cm.get_cmap
  https://matplotlib.org/stable/api/_as_gen/matplotlib.colors.Colormap.html#matplotlib.colors.Colormap

dron gesture
  e.g. https://github.com/kinivi/tello-gesture-control
    https://developers.googleblog.com/en/drone-control-via-gestures-using-mediapipe-hands/

pyserial
paddle ocr, naver api, droidCam
RestNet50 ??
  ğŸŒŸ ì‚¬ëŒ íŠ¹ì§•>> ë½‘ì•„ë‚´ì„œ ë‚´ì ìœ¼ë¡œ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•´ì„œ CCTV ì— ë¹„ì¹˜ëŠ” 
    Cos íŠ¹ì„±: cos ìœ í´ë¦¬ë“œ ê°’ìœ¼ë¡œ .. ResNet ìœ¼ë¡œ ì•Œì•„ë‚¼ ìˆ˜ ìˆë‚˜?
    ì €ì¸µì—ì„œ ê³ ì¸µìœ¼ë¡œ ê°€ëŠ”êµ¬ì¡°.
      ì €ì¸µ. ì¤‘ì¸µ. ì™¸í˜•.
    ì´ ë°ì´í„°ë¥¼ ë²¡í„° (íŠ¹ì§•)ìœ¼ë¡œ ì²˜ë¦¬í•´ì£¼ëŠ”ê²ƒ.
    ë‹¤ì–‘í•œ ë²¡í„°ê°’ì„ í•œì‚¬ëŒìœ¼ë¡œ ì¸ì‹í•˜ë„ë¡ í´ëŸ¬ìŠ¤í„°ë§í•˜ëŠ” ê²ƒ.
    í´ëŸ¬ìŠ¤í„°ë§ì´ë€? ì´ ë°ì´í„°ë¥¼ ê°€ì§€ê³ , ...
  >> ğŸª± Anomaly Detection
    https://github.com/kccistc/intel-05/blob/miniProject_09_suit/class01/mini-project/09_suit/source_09_suit_final.py
duck typing.. threading

âœ… (how); to use Remote Power On/Off and connect Remote Desktop ğŸ“… 2024-10-02 10:29:22
  [Remote Power On/Off]     // Optional
    - check whehter your BIOS support AC back, and turn on
      %shell> sudo apt updtae && sudo apt install -y cpu-x
    - and ...
  connect Remote Desktop
    Any desk account ; https://support.anydesk.com/knowledge/account-creation
      wbfw109v2@gmail.com     // a..
    https://anydesk.com/ko/downloads/linux
    # http://deb.anydesk.com/howto.html
    - add repository key to Trusted software providers list
      %shell> sudo wget -qO - https://keys.anydesk.com/repos/DEB-GPG-KEY | sudo apt-key add -
    - add the repository:
      %shell> echo "deb http://deb.anydesk.com/ all main" | sudo tee /etc/apt/sources.list.d/anydesk-stable.list
    - update apt cache and install anydesk
      %shell> sudo apt update -y && sudo apt install -y anydesk
    
    - run anydesk
      %shell> anydesk
    - settings
      Security - Permissions
        - âœ”ï¸ Enable unattended access
          Password: ...
          Confirm Passsword: ...
          Permissions Profile: Full Access
    # 607 í˜¸ desktop anydesk address: 1 896 175 971
  connect Remote by SSH
    - check remote desktop public IP
      - in Browser: https://www.whatismyip.com/
      - as command
        # curl icanhazip.com
        # python3 -c "import requests; print(requests.get('https://ifconfig.me').text)"
        curl ifconfig.me
    - https://forcloud.tistory.com/210
    - settings
      Security - Permissions
        - âœ”ï¸ Create TCP tunnels
    - check what is your Local port
      Connection - General - Local port


https://velog.io/@minkyu4506/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0-EfficientFormer-Vision-Transformers-at-MobileNet-Speed-%EB%A6%AC%EB%B7%B0 

Arduino
  ls -al /dev/ttyACM0
  Clone code
    git clone --recurse-submodules https://github.com/kccistc/intel-05.git
        --recurse-submodules option ì—†ì´ clone í•œ ê²½ìš°, ì•„ë˜ë¥¼ í†µí•´ submodule update
    ğŸ“ git submodule update --init --recursive
  sudo chmod a+rw /dev/ttyACM0
  # ??? âš ï¸ You need to make flash every time connecting arudino to Windows
  sudo chmod -R 777 /dev/ttyACM0

  ls -al /dev/ttyACM0
  # https://www.kernel.org/doc/html/latest/search.html?q=dialout not found..
  # https://wiki.debian.org/SystemGroups#Other_System_Groups dialout
  sudo usermod -aG dialout $USER

  ... cd arduino/...
  make init && make build && make flash
  # flash; (transitive, computing) To write to the memory of (an updatable component such as a BIOS chip or games cartridge).    https://en.wiktionary.org/wiki/flash
  cd ../ (smart-factory)
    bash build.sh

The tee command in Unix-like systems gets its name from the T-splitter used in plumbing, which splits the flow of water into two directions. Similarly, the tee command in Linux splits the output of a program into two: one going to standard output (usually the terminal) and the other going to a file or another command.

Maximal Softmax Prediction (MSP)
Mahalanobis Distance
Outlier Exposure

â“ OOD Detection
  https://velog.io/@yetsyl0705/Out-of-Distribution-OOD
Range-Doppler Maps

I wonder how MMPose + MoViNet can be used simultaniosuly.
  you said MoViNet is not based on Pose. but MMPose estimates Human Pose.
  but your recommendation uses "MMPose + MoViNet"


1. Person recognition
  - YOLO-NAS

2. Pose Recognition
  - MMPopse

3. Action Recognition
  - PoseC3D


MMPopse Movinet vs PoseC3D
hand signals and body pose are critical.
MoVinet
but some signals could become less distinct or harder to differentiate, especially quick gestures like raising or waving a hand.
Requires
Performance: 30FPS

https://en.wikipedia.org/wiki/Vienna_Convention_on_Road_Signs_and_Signals
ğŸ“ Jetn nano
  ìš°ë¶„íˆ¬ì—ì„œ SD ì¹´ë“œ ë¦¬ë”ê¸°ë¥¼ ì—°ê²°í•˜ë©´ ìë™ìœ¼ë¡œ íŠ¹ì • ë””ë ‰í† ë¦¬ì— ë§ˆìš´íŠ¸ë©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œëŠ” /media/ì‚¬ìš©ìì´ë¦„/ ê²½ë¡œ ì•„ë˜ì— SD ì¹´ë“œê°€ ë§ˆìš´íŠ¸ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ìš©ì ì´ë¦„ì´ userì´ê³  SD ì¹´ë“œì˜ ë ˆì´ë¸”ì´ MySDCardì¸ ê²½ìš°, ë§ˆìš´íŠ¸ ì§€ì ì€ /media/user/MySDCardê°€ ë  ê²ƒì…ë‹ˆë‹¤.
ğŸ”³ Jetson Nano History
  iwlwifi-8000C-*.ucode failed with error -
  failed to read out thermal zone
  imx219 7-0010: error during i2c read probe ë° no acknowledge from address 0x50
  SQUASHFS error: unable to read xattr id index table




ì ¯ìŠ¨ ë‚˜ë…¸ì—ì„œ ì‘ì—… - âš“ https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#intro
  #ï¸âƒ£ Write Image to the microSD card ; https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#write
  #ï¸âƒ£ Setup and First Boot ; https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#setup
    Keyboard Shortcut ; https://miro.medium.com/v2/resize:fit:4800/format:webp/1*M9VeLZpfsPQSsnd3kEocvw.png
https://developer.nvidia.com/embedded/l4t/r32_release_v7.1/jp_4.6.1_b110_sd_card/jeston_nano/jetson-nano-jp461-sd-card-image.zip
  Jetson Nano Developer Kit SD Card Image (ver. 4.6.1) ; https://developer.nvidia.com/embedded/null ğŸ“… 2022/02/23
    ğŸ“ 4.6.1 is lastest version for Jetson Nano. successor models (e.g. Jetson Orin Nano) use version 5.x.
    https://developer.nvidia.com/embedded/jetpack

    https://yeonsozzz.tistory.com/36
  # ğŸ‘¨ Manuallly.. check your mount drive. e.g. my SDCARD_DRIVE is sdc
  # ğŸª± lsblk ; list block devices
  %shell> lsblk
  set SDCARD_DRIVE /dev/sdc
  # ğŸª± dd ; Data Definition ; https://en.wikipedia.org/wiki/Dd_(Unix)
  # if; input file. of; output file. bs; block size
  sudo dd if=$HOME/Downloads/jetson-nano-jp461-sd-card-image/sd-blob-b01.img of=/dev/sdc bs=1M status=progress

  WIFI:
    - AP ëª… : choi í˜¹ì€ choi_5G
    - security: WPA & WPA2 Perosnal (Wi-Fi Protected Access 2)
    - PW : s1234567890
  userName: jetsonnano
  Select Nvpmodel Mode (NVIDIA Power Model)
    MAXN


  ğŸ“° TODO >>>>>>>>>>>> https://pajamacoder.tistory.com/21
    ê°€ì¥ ë¨¼ì € í•œì¼ì€ sudo ëª…ë ¹ ì—†ì´ ë„ì»¤ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ docker groupì— userë¥¼ í¬í•¨ì‹œí‚¤ëŠ” ì¼ì´ë‹¤. nvidiaì—ì„œ ì œê³µí•˜ëŠ” jetson nano os ë¥¼ ì„¤ì¹˜ í•˜ê³  ë‚˜ë©´ ê¸°ë³¸ì ìœ¼ë¡œ dockerëŠ” ì„¤ì¹˜ ë˜ì–´ìˆì§€ë§Œ userë¥¼ ìë™ìœ¼ë¡œ dockerê·¸ë£¹ì— í¬í•¨ì‹œì§€ëŠ” ì•ŠëŠ”ë‹¤.
    

    display message
    dmesg | tail | awk '$3 == "sd" {print}'
    sudo eject /dev/sd<x>

jetson nano server
sudo apt install ssh ssh-server
sudo systemctl enable ssh
systemctl status  
system controlì˜

>> ycoto -> https://developer.ridgerun.com/wiki/index.php/Yocto_Support_for_NVIDIA_Jetson_Platforms_-_Setting_up_Yocto
ğŸ†š is a relationship, hsa a relationship
  https://stackoverflow.com/questions/36162714/what-is-the-difference-between-is-a-relationship-and-has-a-relationship-in

ë°œìƒí•œ ë¬¸ì œê°€ ë¬´ì—‡ì´ê³ , 

â¡ï¸ pytorch torchrun
  torch.distributed.elastic ; https://pytorch.org/docs/stable/distributed.elastic.html
    # Usage
      Quickstart ; https://pytorch.org/docs/stable/elastic/quickstart.html
      Train script ; https://pytorch.org/docs/stable/elastic/train_script.html
      Example ; https://github.com/pytorch/elastic/tree/master/examples

    # API
      torchrun (Elastic Launch) ; https://pytorch.org/docs/stable/elastic/run.html
      
* Seller from https://developer.nvidia.com/buy-jetson
  NVIDIAÂ® Jetson Nanoâ„¢ Developer Kit - B01 ; https://www.seeedstudio.com/NVIDIA-Jetson-Nano-Development-Kit-B01-p-4437.html
  NVIDIAÂ® Jetson Orinâ„¢ Nano Developer Kit ; https://www.seeedstudio.com/NVIDIAr-Jetson-Orintm-Nano-Developer-Kit-p-5617.html

* Requirements
  Hardware Requirements
    - Embedded Board:   [NVIDIA] Jetson Nano (4 GiB)                        1 â‚© 453,330 ; https://prod.danawa.com/info/?pcode=17458712&keyword=NVIDIA+Jetson+NANO+Developer+Kit&cate=112751
    - âš“ Arduino UNO R3 ; https://docs.arduino.cc/hardware/uno-rev3/
        Datasheet ; https://docs.arduino.cc/resources/datasheets/A000066-datasheet.pdf
  Software Requiements
    - Selectable deployement (Exculsive): [OpenVino, TensorRT]
* Architecture
  Hardware
    - Embedded Board:   [NVIDIA] Jetson Nano (4 GiB)                        1 â‚© 453,330 ; https://prod.danawa.com/info/?pcode=17458712&keyword=NVIDIA+Jetson+NANO+Developer+Kit&cate=112751
    - Camera:           [Intel] Depth Camera D435                           1 â‚© 541,410 ; https://prod.danawa.com/info/?pcode=5797839&keyword=%EC%9D%B8%ED%85%94+%EB%A6%AC%EC%96%BC%EC%84%BC%EC%8A%A4+%EC%B9%B4%EB%A9%94%EB%9D%BC&cate=112810
    - Display:          ë¼ì¦ˆë² ë¦¬íŒŒì´/ì ¯ìŠ¨ë‚˜ë…¸/RDK-X7ìš© 7ì¸ì¹˜ ì •ì „ì‹ í„°ì¹˜ ìŠ¤í¬ë¦° 1 â‚© 88,000 ; https://www.devicemart.co.kr/goods/view?no=1273487
  Software
    - Python
      ğŸ“¦ OpenVino
      ğŸ“¦ Pytorch

      # Optimization
        ğŸ“¦ OpenVINO ; https://docs.openvino.ai/2024/index.html
          OpenVINO ğŸ”ª Python API Docs ; https://docs.openvino.ai/2024/api/ie_python_api/api.html
        ğŸ“¦ TensorRT ; https://developer.nvidia.com/tensorrt
          TensorRT ğŸ”ª Python API Docs ; https://docs.nvidia.com/deeplearning/tensorrt/api/python_api/index.html

    - OpenMMLab project ğŸ”ª MMPose
      MMPose is an open-source ğŸš£ toolbox for pose estimation based on PyTorch.
      https://github.com/open-mmlab/mmpose?tab=readme-ov-file
      https://mmpose.readthedocs.io/en/latest/
* Paper
  ğŸ“ Paper review urls
    âš“ğŸ‘ğŸ“° good Paper review: https://ai-easy.tistory.com/
  âš“ PYSKL: Towards Good Practices for Skeleton Action Recognition ; https://arxiv.org/abs/2205.09443
    ```PoseC3D has good spatio- temporal modeling capability and achieves state-of-the-art recognition performance on 6 of 9 benchmarks.```
* Model Pipeline
  - YOLO11m-pose 71.7 FLOPS  /  4(Quantization)  *  15 (FPS) = 268.87500 gFLOPS
    *âš™ï¸ Tracker settings
      https://docs.ultralytics.com/modes/track/#tracker-selection
      https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/trackers/botsort.yaml
    * outputs
      classses id ; https://docs.ultralytics.com/tasks/pose/
        0: Nose
        1: Left Eye
        2: Right Eye
        3: Left Ear
        4: Right Ear
        5: Left Shoulder
        6: Right Shoulder
        7: Left Elbow
        8: Right Elbow
        9: Left Wrist
        10: Right Wrist
        11: Left Hip
        12: Right Hip
        13: Left Knee
        14: Right Knee
        15: Left Ankle
        16: Right Ankle
      # Keypoints ; https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco-pose.yaml
        kpt_shape: [17, 3] # number of keypoints, number of dims (2 for x,y or 3 for x,y,visible)

* Optimizations
  - 
FAQ
  â” Pose-based vs. Skeleton-based Action Recognition ğŸ“… 2024-10-02 15:25:28

    ### Pose-based vs. Skeleton-based Action Recognition

    #### **Pose-based Recognition**:
    - **Definition**: Uses **keypoints** or **landmarks** (joints) of the human body, such as shoulders, elbows, and knees, either in 2D or 3D coordinates.
    - **Data**: Works with the **positions of joints** over time, treating each keypoint individually.
    - **Models**: Commonly uses **CNNs** or **3D CNNs** to analyze pose sequences (e.g., **PoseC3D**).

    #### **Skeleton-based Recognition**:
    - **Definition**: Models the human body as a **graph** where **joints are nodes** and **bones are edges**.
    - **Data**: Focuses on the **spatial connections** between joints and captures their relationships over time.
    - **Models**: Uses **Graph Convolutional Networks (GCNs)** to process the **skeleton structure** (e.g., **MS-G3D**).

    #### **Key Differences**:
    - **Pose-based**: Works with **keypoints** independently, focusing on the temporal evolution of joint positions.
    - **Skeleton-based**: Uses a **graph structure** to model the relationships between joints and bones, offering more detailed spatial insights.

    ---

    ### Key Additions:
    - **Pose-based models** treat joints as independent **keypoints**, so the model doesn't inherently know how joints are connected (like the shoulder to the elbow). The AI may learn these relationships through training but doesn't explicitly model them.
      
    - **Skeleton-based models** explicitly model the relationships between joints as **graph edges** (e.g., shoulder connected to elbow). This makes it more effective at understanding **relative distances** and the **structure** of the body, which improves action recognition.

    - **Relative distance** between joints is critical in both approaches, but **skeleton-based models** handle these connections explicitly, making them more suitable for recognizing complex or multi-joint actions.


  â” Summary of Single-board Computers (SBCs) for AI Processing (Recent Release Order) ğŸ“… 2024-10-02 01:16:00
    ### Summary of Single-board Computers (SBCs) for AI Processing (Recent Release Order)


    | **Device**                                   | **Price** | **TFLOPS**   | **Release Date (ISO)** | **Supports OpenVINO Optimized Models** | **Comparison (Jetson Nano)**                                                                             |
    | -------------------------------------------- | --------- | ------------ | ---------------------- | -------------------------------------- | -------------------------------------------------------------------------------------------------------- |
    | **Intel UP Xtreme i12**                      | $700~$900 | 2~4 TFLOPS   | 2023-02-10             | Yes                                    | Much more powerful, but higher cost and power consumption.                                               |
    | **Intel NUC 12 Pro**                         | $600~$800 | 2~3 TFLOPS   | 2022-06-15             | Yes                                    | Higher performance and price, suitable for various IoT and AI applications.                              |
    | **Intel UP Squared Pro 7000**                | $400~$600 | 1.5~2 TFLOPS | 2022-04-05             | Yes                                    | Offers decent performance at low power and cost.                                                         |
    | **NVIDIAÂ® Jetson Orinâ„¢ Nano Developer Kit**  | $499      | 40 TOPS      | 2022-09-20             | No                                     | 100x the performance of Jetson Nano, higher price, for high-performance AI tasks.                        |
    | **Intel Elkhart Lake AAEON PICO-EHL4**       | $300~$400 | 1~1.5 TFLOPS | 2021-12-01             | Yes                                    | Similar performance to Jetson Nano, for low-power AI applications.                                       |
    | **Intel NUC 11 Pro Kit**                     | $500~$700 | 2 TFLOPS     | 2021-03-15             | Yes                                    | Better performance, but more expensive and higher power consumption than Jetson Nano.                    |
    | **NVIDIAÂ® Jetson Nanoâ„¢ Developer Kit - B01** | $149      | 0.472 TFLOPS | 2019-03-18             | No                                     | Great price-to-performance ratio, ideal for beginners and lightweight AI tasks.                         |

    ---

    ### Intel Lunar Lake Overview

    Intel's **Lunar Lake** was launched on **2024-09-24** and is designed for **up to 120 TOPS** in AI performance, with **48 TOPS** from the **NPU** alone. This makes it highly suitable for **AI-based edge computing**. Compared to older Intel models like **Elkhart Lake** and **Alder Lake**, which lacked dedicated AI acceleration, Lunar Lake brings significant improvements in performance-per-watt for AI tasks.

    However, there are **no Lunar Lake-based embedded boards** available yet, similar to NVIDIA's **Jetson Nano** series. Jetson remains a leading choice for **real-time AI inference** and **edge computing**, with the Jetson Nano and Jetson Orin Nano being popular models.

  â” Project Application Review: OpenVINO vs MediaPipe Framework ğŸ“… 2024-10-02 00:22:47
    # Project Application Review: OpenVINO vs MediaPipe Framework

    ## 1. OpenVINO
    - **Purpose**: OpenVINO is a platform designed to provide **optimized deep learning inference** on **Intel hardware** (CPU, GPU, VPU, etc.).
    - **Key Features**:
      - Converts models from **TensorFlow, ONNX**, etc., into **IR (Intermediate Representation)** format for optimized inference on **Intel-based hardware**.
      - Built for **high-performance inference**, suitable for both **edge and server environments**.
      - Supports a wide range of **Intel platforms** (CPU, iGPU, VPU), and is especially designed to maximize **real-time inference** performance.

    ## 2. MediaPipe Framework
    - **Purpose**: MediaPipe is a **framework for managing model pipelines** and **real-time data processing** across various platforms (Android, iOS, embedded devices).
    - **Key Features**:
      - Primarily supports **TensorFlow Lite** models and is optimized for **mobile and embedded devices** with a focus on **real-time processing**.
      - It optimizes the **data flow between models** through **asynchronous pipeline management**, handling real-time input data efficiently.
      - MediaPipe is designed for **lightweight environments** where real-time data streams are a priority, but is heavily optimized for **TensorFlow Lite** models.

    ---

    ## Project Application Review

    ### 1. **OpenVINO Requirements**
    - **The current project's software requirements align with OpenVINO**.
    - **OpenVINO** provides **optimized inference for Intel hardware**, while **MediaPipe is incompatible** as it primarily works with **TensorFlow Lite** and other lightweight formats.
    - **Conclusion**: Since the projectâ€™s software requirements necessitate **OpenVINO**, the **MediaPipe Framework is not suitable**, and **OpenVINO** should be used.

    ### 2. **Synchronous Process between Two Inferences**
    - The project workflow involves **pose recognition**, followed by **action recognition** based on joint position data, which requires the **pose data** to be processed first before action recognition can occur.
    - **MediaPipeâ€™s asynchronous pipeline** excels at parallel processing between models, but the project requires a **synchronous process** between the two models.
    - **Conclusion**: Since **synchronous inference** is necessary, **MediaPipeâ€™s asynchronous nature** does not align with the projectâ€™s requirements, and using a **MediaPipe pipeline would not be effective** in this case.
  â” Project Application Review: Why Hand Landmark Detection is Necessary ğŸ“… 2024-10-02 02:39:37
    # Project Application Review: Why Hand Landmark Detection is Necessary

    ## Why Hand Landmark Detection is Essential for the Project

    1. **Gesture Differentiation**:
      - Gestures like **"Push Away"** and **"Come Closer"** rely heavily on **hand orientation** (palm facing the camera or not). Simply using joint position data may not capture these subtle differences.
      - Hand Landmark Detection provides detailed keypoints of the hand, which help in recognizing the **front vs. back of the hand**.

    2. **Precise Hand Pose Data**:
      - **MediaPipe Hand Landmark Detection** offers high precision tracking of hand keypoints (finger tips, knuckles, etc.).
      - This data can be integrated with body joint data to improve the accuracy of **gesture recognition** in complex scenarios.

    3. **Improved Action Recognition**:
      - By using **hand landmark data** alongside **joint data**, the model can learn more nuanced movements, such as **hand rotations** and **finger positions**, which are crucial for distinguishing between similar gestures.

    ## Conclusion
    Using **Hand Landmark Detection** in combination with **joint position data** allows for a more robust and accurate gesture recognition system, making it essential for the successful implementation of your traffic signal recognition project.

  â” Why MMPose is a Better Choice than MediaPipe Pose ğŸ“… 2024-10-02 00:22:50
    # Why MMPose is a Better Choice than MediaPipe Pose

    ### 1. **Higher Joint Accuracy**
      - MMPose provides **more accurate joint coordinates** through various backbones (ResNet, HRNet, etc.), making it better for recognizing traffic signals from different angles as the vehicle moves.

    ### 2. **Handling Complex Poses and Angle Variations**
      - When a vehicle observes traffic signals from various angles, **pose recognition across different perspectives** becomes crucial. MMPose excels at managing such changes.

    ### 3. **Scalability and Customization**
      - MMPose allows for **retraining with custom datasets**, enabling fine-tuning for specific environments or actions.

    ### 4. **Precision in Joint Data**
      - For traffic signal recognition, **precise joint distances and changes** are essential. MMPose provides more detailed joint information, making it ideal for such tasks.

  â” About Parallel Processing ğŸ“… 2024-10-01 23:17:21
    in OpenVINO, https://ilya-lavrenov.github.io/openvino/openvino_docs_OV_UG_Python_API_exclusives.html#release-of-gil
      Some functions in Python API release the Global Lock Interpreter (GIL) while running work-intensive code
      #ï¸âƒ£ List of Functions that Release the GIL
        ğŸš£ openvino.runtime.Core.compile_model

    In MediaPipe, https://ai.google.dev/edge/mediapipe/framework/getting_started/python_framework
      ... MediaPipe framework sits on top of the ğŸš£ pybind11 library. The C++ core framework is exposed in Python via a C++/Python language binding.
        ğŸ“ Pybibnd ; https://pybind11.readthedocs.io/en/stable/index.html
      ... In the MediaPipe Framework, all processing takes places within the context of a CalculatorGraph.
      
ì˜ì‚¬ ê²°ì •
  - Prepare model
    - í˜„ì¬ í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­ì—ì„œ ì •ìƒì ìœ¼ë¡œ ëŠê¹€ì—†ì´ ì˜ ì‘ë™í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.
    - about Action Recognition model
      - ê´€ì ˆ ìœ„ì¹˜ì™€ ë³€í™” ê¸°ë°˜ í–‰ë™ ì¸ì‹
        ì´ë¯¸ì§€ì—ì„œ ë°°ê²½ë³´ë‹¤ëŠ” í¬ì¦ˆ ë°ì´í„°ê°€ ì¤‘ìš”í•˜ë¯€ë¡œ í•˜ë¯€ë¡œ, í–‰ë™ ì¸ì‹ì— ëŒ€í•œ ëª¨ë¸ì€ Based on pose data (ê´€ì ˆ ìœ„ì¹˜) ì´ ë˜ì–´ì•¼ í•œë‹¤. Based on vison ë³´ë‹¤ëŠ”.
      - ì‹œê³µê°„ì  ì •ë³´ë¥¼ ë‹´ì„ ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.
        ì œìŠ¤ì²˜ ì¸ì‹ì€ ë‹¨ìˆœíˆ í•˜ë‚˜ì˜ í”„ë ˆì„ì—ì„œ í¬ì¦ˆë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒë¿ë§Œ ì•„ë‹ˆë¼, ì—°ì†ëœ ì‹œê°„ì˜ í”„ë ˆì„ì—ì„œ ê´€ì ˆì˜ ìœ„ì¹˜ê°€ ì–´ë–»ê²Œ ë³€í™”í•˜ëŠ”ì§€ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì¤‘ìš”.
        ğŸ›ï¸ e.g.
          - Spatio-Temporal Multilayer Perceptron (ST-MLP)
          - CNN (Convolutional Neural Network)
          - RNN (Recurrent Neural Network)
          - LSTM (Long Short-Term Memory)
          - Transformer ê¸°ë°˜ ëª¨ë¸
          - ... ì´ì „ì— ë‚˜ì˜¨ ëª¨ë¸ë“¤ì˜ ë‹¨ì ì„ ë³´ì™„í•œ ëª¨ë¸ë“¤
      - í¬ì¦ˆ ì¸ì‹ (ê´€ì ˆ ìœ„ì¹˜ íƒì§€) ëª¨ë¸
        This reduces the complexity by focusing on the skeletal motion rather than the entire image.
          ğŸ›ï¸ e.g. 
            - MobileNet ê¸°ë°˜ MMPose
            - ResNet ê¸°ë°˜ MMPose
            - HRNet ê¸°ë°˜ MMPose
            - Lite-HRNet ê¸°ë°˜ MMPose
            - MediaPipe Pose
        filter: lightweight
          ğŸ›ï¸ e.g. 
            - MobileNet ê¸°ë°˜ MMPose
            - MediaPipe Pose
      - í–‰ë™ ì¸ì‹ ëª¨ë¸ (ê¸°ë³¸ì ìœ¼ë¡œ í–‰ë™ ì¸ì‹ì„ ì§€ì›í•˜ëŠ” ëª¨ë¸)
          ğŸ›ï¸ e.g. 
            EfficientGCN
            SGN
            MS-G3D
            DynamicGCN
            PA-ResGCN-b19
            4s-Shift-GCN
            2s-AGCN
            NAS-GCN
        filter: lightweight
          ğŸ›ï¸ e.g. 
            EfficientGCN ; https://github.com/attention-eq-everything/effgcn_cam
            SGN ; https://github.com/microsoft/SGN?tab=readme-ov-file

          These model uses NTU RGB+D 60 Dataset


    * Optimization

        // TensorRT ë“±ìœ¼ë¡œ ìµœì í™” í•„ìš”. ê·¸ëƒ¥ ì„ë² ë””ë“œì—ì„œ ëŒë¦¬ê¸°ì—ëŠ” ë¬´ê±°ì›€.

      - ê²½ëŸ‰ Transformer ê¸°ë°˜ ëª¨ë¸
        ğŸ›ï¸ e.g.
        - EfficientFormer
        - EdgeFormer 
    - ì •í™•ë„ì™€ ì‹¤ì‹œê°„ ì„±ëŠ¥ê³¼ì˜ ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•´, ì„œë¡œ ë‹¤ë¥¸ ê´€ì ˆì˜ ë³µì¡í•œ ê³µê°„ê´€ê³„ë¥¼ ë” ì˜ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” EfficientFormer ë¥¼ ì„ íƒ

  ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ ë‹¤ë£¨ëŠ” ê²½ìš°,
    Action Transformer
    ViViT (Video Vision Transformer): 


  ë¦¬ì†ŒìŠ¤ê°€ ì œí•œëœ ê²½ìš°.

ğŸ“ ì „ ì»¤ë°‹ì—ì„œ íŠ¹ì • íŒŒì¼ì˜ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ë ¤ë©´
  git log -S "from pytubefix import YouTube"

Kaggle with ssh
  https://github.com/Kaggle/kaggle-api
  https://github.com/buidai123/Kaggle_VSCode_Remote_SSH


ğŸ†š git add   vs git restore --staged
git push origin --delete <ì˜ëª»ëœ-ë¸Œëœì¹˜-ì´ë¦„>
git push origin HEAD
   # í˜„ì¬ ì²´í¬ì•„ì›ƒëœ ë¸Œëœì¹˜ë¥¼ ì›ê²© ì €ì¥ì†Œì— ë™ì¼í•œ ì´ë¦„ìœ¼ë¡œ í‘¸ì‹œ
  <refspec>ì€ ë¡œì»¬ì˜ ì°¸ì¡°(ë¸Œëœì¹˜, íƒœê·¸ ë“±)ì—ì„œ ì›ê²©ì˜ ì°¸ì¡°ë¡œ ì–´ë–¤ ê²ƒì„ í‘¸ì‹œí• ì§€ë¥¼ ê²°ì •í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. Gitì—ì„œ HEADëŠ” í˜„ì¬ ì²´í¬ì•„ì›ƒëœ ë¸Œëœì¹˜ë¥¼ ì°¸ì¡°í•˜ëŠ” ì´ë¦„ì´ê¸° ë•Œë¬¸ì—, git push origin HEAD ëª…ë ¹ì–´ì—ì„œ HEADëŠ” ë¡œì»¬ ë¸Œëœì¹˜ë¥¼ ì›ê²© ì €ì¥ì†Œì— í‘¸ì‹œí•˜ëŠ” ëŒ€ìƒ ì°¸ì¡°ë¡œ ë™ì‘í•©ë‹ˆë‹¤.


https://github.com/ultralytics/ultralytics
  #ï¸âƒ£ Integrations
https://openvinotoolkit.github.io/openvino_notebooks/?search=conver

How Does Action Recognition Work with Sequences?
  Multiple Frames: These models require a sequence of frames (for example, 16, 30, or even more frames) to analyze both spatial and temporal patterns (i.e., how body parts move over time).
  Sliding Window: The model might use a sliding window approach, meaning it continually analyzes a fixed number of frames (e.g., 16 frames) and shifts forward as new frames come in.

Mediapipe Object Detection vs YOLOv11: â¡ï¸ ğŸ‘ YOLOv11
  YOLOv11 (nano/tiny versions) is likely better if you need highly optimized person detection and can afford a bit more latency compared to Mediapipe. YOLOv11 models can also be customized for specific tasks.

Action Recognition: MS-G3D vs. ST-GCN: â¡ï¸ ğŸ‘ MS-G3D
  For skeleton-based action recognition, both models are strong contenders.
  MS-G3D provides more multi-scale temporal and spatial analysis, while ST-GCN is more lightweight and may offer higher FPS in real-time applications.


  âš“ Softmax function ; https://en.wikipedia.org/wiki/Softmax_function
  (Subscript | ë°‘ìˆ˜) ì™€ (Superscript | ìœ—ìˆ˜)
  âš“ Attention (machine learning) ; https://en.wikipedia.org/wiki/Attention_(machine_learning)#Scaled_dot-product_attention
    #ï¸âƒ£ Self-attention ; https://en.wikipedia.org/wiki/Attention_(machine_learning)#Self-attention
  âš“ Word embedding ; https://en.wikipedia.org/wiki/Word_embedding

  ë””ì½”ë”ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ RNNLM(RNN Language Model)ì…ë‹ˆë‹¤. RNNLMì˜ ê°œë…ì„ ê¸°ì–µí•˜ê³  ìˆë‹¤ë©´ ì¢€ ë” ì´í•´í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤. ë””ì½”ë”ëŠ” ì´ˆê¸° ì…ë ¥ìœ¼ë¡œ ë¬¸ì¥ì˜ ì‹œì‘ì„ ì˜ë¯¸í•˜ëŠ” ì‹¬ë³¼ <sos>ê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤. ë””ì½”ë”ëŠ” <sos>ê°€ ì…ë ¥ë˜ë©´, ë‹¤ìŒì— ë“±ì¥í•  í™•ë¥ ì´ ë†’ì€ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. 
  https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html

  ğŸ‘
  [íŠ¸ë ŒìŠ¤í¬ë¨¸ ëª¨ë¸ ì´í•´í•˜ê¸°] Self-Attentionì—ì„œ Q, K, V(Query, Key, Value)ì˜ ì˜ë¯¸ ; https://cn-c.tistory.com/68#%EB%AA%A8%EB%93%A0%20%EB%8B%A8%EC%96%B4%EB%8A%94%20%EC%A7%88%EB%AC%B8(Query)%EC%9D%B4%EC%9E%90%20%EB%8B%B5%EB%B3%80(Key)%EC%9D%B4%EB%8B%A4-1
  https://velog.io/@sjinu/%EA%B0%9C%EB%85%90%EC%A0%95%EB%A6%AC-Attention-Mechanism


  c) Separable Convolution (SepLayer)
  ì¼ë°˜ì ì¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ëŠ” ë§ì€ ê³„ì‚°ì„ ìš”êµ¬í•©ë‹ˆë‹¤. Separable Convolutionì€ ì´ëŸ¬í•œ ê³„ì‚°ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ ì»¨ë³¼ë£¨ì…˜ì„ ë‘ ë‹¨ê³„ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤:
  Depth-wise Convolution: ê° ì±„ë„ì— ëŒ€í•´ ê°œë³„ì ìœ¼ë¡œ ì»¨ë³¼ë£¨ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
  Point-wise Convolution: ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ì¶œë ¥ ì±„ë„ì„ ë§Œë“­ë‹ˆë‹¤.
  ì´ë ‡ê²Œ ë‚˜ëˆ„ì–´ì„œ ì²˜ë¦¬í•˜ë©´ ê³„ì‚°ëŸ‰ì´ ì¤„ì–´ë“¤ê³ , ëª¨ë¸ì´ ë” ë¹ ë¥´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë™ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  d) Bottleneck Layer (BottleLayer)
    ì¼ë°˜ì ì¸ CNN ì—ì„œ torch ë¡œ layer ë¥¼ êµ¬ì„±í•  ë•Œ ì½”ë“œëŠ” ë³´í†µ ì–´ë–»ê²Œ ì§œë‚˜?

    - Multiple Input Branches (MIB) ì•„í‚¤í…ì²˜
    - ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´:
      Graph Convolution (GCN) ë ˆì´ì–´
      Temporal Convolution (TC) ë ˆì´ì–´
      Separable Convolution (SepLayer)
      Expanded Separable Layer (EpSepLayer)
      Bottleneck Layer (BottleLayer)
      Sandglass Layer (SGLayer)
      ë“±ì˜ êµ¬ì¡°ë¥¼ GCNì— ì ìš©í•´ ëª¨ë¸ì˜ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.
    - Compound Scaling ì „ëµ:
      EfficientGCN-B0, EfficientGCN-B2, EfficientGCN-B4 ê°™ì€ ë‹¤ì–‘í•œ í¬ê¸°ì˜ ëª¨ë¸


  EfficientGCNv1
    https://github.com/zyxjtu/EfficientGCNv1
    ACMMM 2020 ; https://dl.acm.org/doi/abs/10.1145/3394171.3413802
    Arxiv Preprint ; https://arxiv.org/pdf/2010.09978.pdf

  EfficientGCN 2
    https://github.com/attention-eq-everything/effgcn_cam
    IEEE T-PAMI; https://ieeexplore.ieee.org/abstract/document/9729609
    Arxiv Preprint ; https://arxiv.org/pdf/2106.15125

  MLP (Multi-layer Perceptron): ì—¬ëŸ¬ ê°œì˜ ì¸µìœ¼ë¡œ ì´ë£¨ì–´ì§„ ê¸°ë³¸ì ì¸ ì‹ ê²½ë§ êµ¬ì¡°ì…ë‹ˆë‹¤. ì±„ë„ ë‹¨ìœ„ë‚˜ ê³µê°„ì  ì°¨ì›ì—ì„œ ê°ê° ë…ë¦½ì ìœ¼ë¡œ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
  SENet (Squeeze-and-Excitation Networks): ê° ì±„ë„ì˜ ì¤‘ìš”ë„ë¥¼ í•™ìŠµí•˜ì—¬ ì ì‘ì ìœ¼ë¡œ ì¡°ì ˆí•˜ëŠ” ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤. AGC-LSTMê³¼ MS-AAGCNë„ ì´ëŸ° ë°©ì‹ìœ¼ë¡œ ì±„ë„ë³„ ì¤‘ìš”ë„ë¥¼ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.
    - AGC-LSTM: Attention-Guided Convolution Long Short-Term Memory
      LSTM ê¸°ë°˜ì˜ ê³¨ê²© í–‰ë™ ì¸ì‹ ëª¨ë¸ë¡œ, ê´€ì ˆ ê°„ì˜ ê´€ê³„ë¥¼ í•™ìŠµí•˜ëŠ” ë° MLPì™€ SENet êµ¬ì¡°ë¥¼ ê²°í•©í•˜ì—¬ ì±„ë„ë§ˆë‹¤ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.
    - MS-AAGCN: Multi-Scale Adaptive Graph Convolutional Network
      Spatial Graph Convolutionì„ ì‚¬ìš©í•œ ëª¨ë¸ë¡œ, ì£¼ë¡œ ê³µê°„ì  ì°¨ì›ì—ì„œ í•™ìŠµí•˜ê³  ë‹¤ë¥¸ ì°¨ì›ì„ í‰ê·  ì²˜ë¦¬í•˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.
  LSTM (Long Short-Term Memory):
    ìˆœí™˜ ì‹ ê²½ë§(RNN)ì˜ í•œ ì¢…ë¥˜ë¡œ, ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ ê³¼ê±°ì˜ ì •ë³´ë¥¼ ê¸°ì–µí•˜ë©´ì„œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ ëª¨ë¸ì…ë‹ˆë‹¤.
    íŠ¹íˆ ê¸´ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ì£¼ë¡œ ì‹œê°„ì— ë”°ë¥¸ ë°ì´í„° ì²˜ë¦¬ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
  . EfficientGCN-B0, B2, B4
    ; Base ì˜ ì•½ì. 


  Data input
    ì• ì´ˆì— ì—¬ëŸ¬ í”„ë ˆì„ì„ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ”ë‹¤.
    ì‹œê°„ì  ì •ë³´ê°€ ë³µì¡í•´ì§€ë©´, ë” ë§ì€ í”„ë ˆì„ì„ í†µí•´ ëª¨ë¸ì´ ì •í™•í•˜ê²Œ í–‰ë™ì„ ì¸ì‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ì„±ëŠ¥ì€ **ì •í™•ë„(Accuracy)**ë¥¼ ì˜ë¯¸í•˜ë©°, ë” ë§ì€ ì‹œê°„ì  ë°ì´í„°ë¥¼ ì‚¬ìš©í• ìˆ˜ë¡ í–‰ë™ì˜ ì„¸ë¶€ì ì¸ ë³€í™”ê¹Œì§€ë„ í•™ìŠµí•  ìˆ˜ ìˆì–´ ì •í™•ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤.
    ê·¸ëŸ¬ë‚˜ í”„ë ˆì„ ìˆ˜ê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡ ì¶”ë¡  ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì¦ê°€í•©ë‹ˆë‹¤. ê° í”„ë ˆì„ì— ëŒ€í•´ ì¶”ê°€ì ì¸ ì—°ì‚°ì„ ìˆ˜í–‰í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— TC ë ˆì´ì–´ê°€ ë” ë§ì´ í•„ìš”í•´ì§€ê³ , ì´ëŠ” ê³„ì‚° ë¹„ìš©ì„ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.
    Jetson Nanoì™€ ê°™ì€ ì„ë² ë””ë“œ í•˜ë“œì›¨ì–´ì—ì„œëŠ” ì²˜ë¦¬ ì†ë„ì™€ ë©”ëª¨ë¦¬ê°€ ì œí•œì ì´ê¸° ë•Œë¬¸ì—, ì ì ˆí•œ í”„ë ˆì„ ìˆ˜ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. YOLO, MediaPipe, EfficientGCN ë“±ì˜ ëª¨ë¸ì„ ë™ì‹œì— ì‚¬ìš©í•´ì•¼ í•œë‹¤ë©´, ì‹œê°„ì  í”„ë ˆì„ ìˆ˜ëŠ” ì ì ˆíˆ ì¤„ì´ë©´ì„œë„ ì¤‘ìš”í•œ í–‰ë™ì„ ì¶©ë¶„íˆ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ ì¡°ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. Jetson Nanoì˜ ì„±ëŠ¥ì„ ê³ ë ¤í•˜ë©´, ì´ˆë‹¹ 15~30 í”„ë ˆì„ìœ¼ë¡œ í•™ìŠµ ë° ì¶”ë¡ ì„ ì§„í–‰í•˜ëŠ” ê²ƒì´ ì í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    2. EfficientGCNì˜ N ê°œ í”„ë ˆì„ ì„¤ì • ê°€ëŠ¥ ì—¬ë¶€
      EfficientGCNì—ì„œ Nê°œì˜ í”„ë ˆì„ì„ ì…ë ¥ìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Nì€ ëª¨ë¸ì´ í–‰ë™ì„ ì¸ì‹í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ì‹œê°„ì  ì •ë³´ì˜ ë²”ìœ„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ì¦‰, í•œ ë²ˆì˜ í•™ìŠµ ë˜ëŠ” ì¶”ë¡ ì—ì„œ ëª‡ ê°œì˜ ì—°ì†ëœ í”„ë ˆì„ì„ ì²˜ë¦¬í• ì§€ë¥¼ Nìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

      í”„ë ˆì„ ìˆ˜ë¥¼ ì¡°ì •í•˜ëŠ” ì´ìœ :
      ë” ë§ì€ í”„ë ˆì„(N)ì´ ì‚¬ìš©ë˜ë©´ ëª¨ë¸ì€ ë” ê¸´ ì‹œê°„ ë™ì•ˆì˜ í–‰ë™ì„ ì¸ì‹í•  ìˆ˜ ìˆì–´ ì •í™•ë„ê°€ ë†’ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê³„ì‚° ë¹„ìš©ì´ ì¦ê°€í•˜ê²Œ ë©ë‹ˆë‹¤.
      4ê°œì˜ ëª¨ë¸ ì‚¬ìš© ì‹œ í”„ë ˆì„ ìˆ˜ ì¡°ì •:
      Jetson Nanoì—ì„œ 4ê°œì˜ ëª¨ë¸(YOLO, MediaPipe Hand Landmarks, Pose, EfficientGCN)ì„ ì‚¬ìš©í•  ë•ŒëŠ” í•˜ë“œì›¨ì–´ ì„±ëŠ¥ì— ë”°ë¼ í”„ë ˆì„ ìˆ˜ë¥¼ ì¡°ì ˆí•´ì•¼ í•©ë‹ˆë‹¤.
      ê¶Œì¥ í”„ë ˆì„ ìˆ˜ëŠ” 8~16 í”„ë ˆì„ ì‚¬ì´ê°€ ì í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì¶©ë¶„í•œ ì‹œê°„ì  ì •ë³´ë¥¼ ì œê³µí•˜ë©´ì„œë„ Jetson Nanoì˜ ì„±ëŠ¥ í•œê³„ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ì„¤ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
    EfficientGCN-B0
      x-sub120 ë°ì´í„°ì…‹ì— ëŒ€í•´ ì •í™•ë„ 86.6, x-set120 ë°ì´í„°ì…‹ì— ëŒ€í•´ ì •í™•ë„ 85.0

    90.2 2.73 1Ã— 0.29 1Ã—


  Cross-subjectì™€ Cross-setupì€ í–‰ë™ ì¸ì‹ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë‘ ê°€ì§€ í‰ê°€ ì„¤ì •ì…ë‹ˆë‹¤.
    Cross-subject: í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ë‹¤ë¥¸ ì£¼ì²´ë“¤ë¡œë¶€í„° ë‚˜ì˜¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. í›ˆë ¨ ì‹œ ì‚¬ìš©ëœ ì‚¬ëŒê³¼ í…ŒìŠ¤íŠ¸ ì‹œ ì‚¬ìš©ëœ ì‚¬ëŒì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì¼ë°˜í™”ë˜ì—ˆëŠ”ì§€ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
    Cross-setup: ë‹¤ë¥¸ í™˜ê²½ ì„¤ì •ì´ë‚˜ ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì´ëŠ” ë‹¤ì–‘í•œ ë°°ê²½ì´ë‚˜ í™˜ê²½ì—ì„œì˜ í–‰ë™ ì¸ì‹ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

  , Table 7ì€ X-sub ë²¤ì¹˜ë§ˆí¬ì—ì„œì˜ ì„±ëŠ¥ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ í‰ê°€í•œ ê²ƒì…ë‹ˆë‹¤.
  FLOPsëŠ” íŠ¹ì • ë°ì´í„°ì…‹ì—ì„œ ì¸¡ì •ëœ ì—°ì‚°ëŸ‰ì„ ë‚˜íƒ€ë‚´ë©°, ë‹¤ë¥¸ ë°ì´í„°ì…‹ì—ì„œë„ í° ì°¨ì´ ì—†ì´ ì ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, FLOPsëŠ” ì£¼ì–´ì§„ ëª¨ë¸ì˜ êµ¬ì¡°ì— ë”°ë¼ ê±°ì˜ ê³ ì •ì ì…ë‹ˆë‹¤.

  â“ 5. ì»¤ë„ì˜ ê¸¸ì´ì™€ ê³¨ê²© ëª¨ë¸ì—ì„œì˜ ì˜ë¯¸
    ì»¤ë„ì€ ì¼ë°˜ì ìœ¼ë¡œ í•©ì„±ê³± ì—°ì‚°ì—ì„œ ì‚¬ìš©í•˜ëŠ” í•„í„°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì»¤ë„ì˜ í¬ê¸°ì™€ ê°€ì¤‘ì¹˜ëŠ” ë„¤íŠ¸ì›Œí¬ê°€ í•™ìŠµí•˜ëŠ” ì¤‘ìš”í•œ íŒŒë¼ë¯¸í„° ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.

    L x 1 Convì—ì„œ Lì€ ì»¤ë„ì˜ ê¸¸ì´ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, L=3ì´ë©´ 3ê°œì˜ ê°’ì„ í•©ì„±ê³±ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.

    ê³¨ê²© ê¸°ë°˜ í–‰ë™ ì¸ì‹ì—ì„œì˜ ì»¤ë„ì€ ê´€ì ˆ ê°„ì˜ ê³µê°„ì  ê´€ê³„ë¥¼ í•™ìŠµí•˜ëŠ” í•„í„°ë¡œ ì‘ë™í•©ë‹ˆë‹¤. ì»¤ë„ì€ ê° ê´€ì ˆì´ ë‹¤ë¥¸ ê´€ì ˆê³¼ ì–´ë–¤ ê´€ê³„ë¥¼ ê°€ì§€ëŠ”ì§€ í•™ìŠµí•˜ë©°, ê·¸ í¬ê¸°ì™€ ê¸¸ì´ëŠ” í•™ìŠµí•˜ëŠ” í–‰ë™ íŒ¨í„´ì˜ ë³µì¡ë„ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤.
    LÃ—1 ConvëŠ” 1D í•©ì„±ê³±ì„ ì˜ë¯¸í•˜ë©°, ì‹œê°„ì  ì°¨ì›ì—ì„œ ì—°ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    C_in, CoutëŠ” ê°ê° ì…ë ¥ ì±„ë„ ìˆ˜ì™€ ì¶œë ¥ ì±„ë„ ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

    /2ëŠ” í•©ì„±ê³± ì—°ì‚° í›„ ì¶œë ¥ í¬ê¸°ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì´ëŠ” ì—°ì‚°ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

  EfficientGCNì—ì„œëŠ” SGLayerë¥¼ ë¹„ë¡¯í•œ ë‹¤ì–‘í•œ ë ˆì´ì–´ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.
    ëª¨ë¸ì˜ êµ¬ì¡°ì— ë”°ë¼ BasicLayer, BottleLayer, SepLayer, EpSepLayer, SGLayer ì¤‘ì—ì„œ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    SGLayerëŠ” íš¨ìœ¨ì ì¸ ê³µê°„ì , ì‹œê°„ì  ì •ë³´ë¥¼ í•™ìŠµí•˜ëŠ” ë ˆì´ì–´ë¡œ, depth-wise convolutionê³¼ point-wise convolutionì´ ê²°í•©ëœ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤.

  1. ê³¨ê²© ê¸°ë°˜ í–‰ë™ ì¸ì‹ ëª¨ë¸ì—ì„œ Depth-wise Convolution ì‚¬ìš© ì´ìœ 
    ê³¨ê²© ê¸°ë°˜ í–‰ë™ ì¸ì‹ ëª¨ë¸ì—ì„œëŠ” ê´€ì ˆ ìœ„ì¹˜ ë°ì´í„°(Joint), ì†ë„ ë°ì´í„°(Velocity), ë¼ˆ ì •ë³´(Bone) ë“±ì´ ì±„ë„ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤. ì´ ê° ì±„ë„ì€ í–‰ë™ ì¸ì‹ì„ ìœ„í•œ ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì§•ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

    ê° ì±„ë„ ê°„ ìƒí˜¸ì‘ìš©ì´ ìƒëŒ€ì ìœ¼ë¡œ ì ì€ ì´ìœ :
      ê´€ì ˆ ìœ„ì¹˜(Joint)ëŠ” ê° ê´€ì ˆì˜ 3D ì¢Œí‘œì…ë‹ˆë‹¤.
      ì†ë„(Velocity)ëŠ” ì‹œê°„ì— ë”°ë¥¸ ê´€ì ˆì˜ ì´ë™ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
      ë¼ˆ ì •ë³´(Bone)ëŠ” ê´€ì ˆ ê°„ì˜ ê±°ë¦¬ ë° ê°ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
      ì´ëŸ¬í•œ ì±„ë„ë“¤ì€ ì„œë¡œ ë…ë¦½ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ë©°, ê´€ì ˆì˜ ë¬¼ë¦¬ì ì¸ ìœ„ì¹˜ë‚˜ ì´ë™ ì†ë„, ê´€ì ˆ ê°„ì˜ ê´€ê³„ë¥¼ ê°œë³„ì ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒì´ ë” ì¤‘ìš”í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ê° ì±„ë„ì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” Depth-wise Convolutionì´ ìœ ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì±„ë„ ê°„ì˜ ìƒí˜¸ì‘ìš©ì´ í•„ìˆ˜ì ì´ì§€ ì•Šê¸° ë•Œë¬¸ì—, ì—°ì‚°ëŸ‰ì„ ì¤„ì´ë©´ì„œë„ ê° ì±„ë„ì˜ ì¤‘ìš”í•œ ì •ë³´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


  ê¹Šì´(Depth) í•´ì„
    **Depth(ê¹Šì´)**ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ì˜ ë ˆì´ì–´ ìˆ˜ë¥¼ ì˜ë¯¸í•˜ì§€ë§Œ, êµ¬ì²´ì ì¸ ì˜ë¯¸ëŠ” ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ê³¨ê²© ê¸°ë°˜ í–‰ë™ ì¸ì‹ì—ì„œëŠ” ë„¤íŠ¸ì›Œí¬ê°€ ì–¼ë§ˆë‚˜ ê¹Šì´ ìˆëŠ” íŠ¹ì§•ì„ í•™ìŠµí•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë” ë§ì€ ë ˆì´ì–´ë¥¼ ìŒ“ìœ¼ë©´ ëª¨ë¸ì´ ë” ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    DepthëŠ” ë³´í†µ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ì„¤ì •ë˜ë©°, í•™ìŠµ ê³¼ì •ì—ì„œ ìµœì ì˜ ë ˆì´ì–´ ìˆ˜ë¥¼ ì°¾ê¸° ìœ„í•´ ì¡°ì •ë©ë‹ˆë‹¤. ë³´í†µ ë§ì€ DepthëŠ” ë” ë‚˜ì€ ì„±ëŠ¥ì„ ì œê³µí•˜ì§€ë§Œ, ê³„ì‚°ëŸ‰ì´ ì¦ê°€í•˜ì—¬ ì—°ì‚° ì‹œê°„ì´ ê¸¸ì–´ì§‘ë‹ˆë‹¤.

  ë‚´ê°€ ì´í•´í•œ ê²ƒì„ ê²€í† í•´ì¤˜.
  (a) ì—ì„œëŠ” Df*Df*Cin  (ì´ˆê¸°(?) í”¼ì³ ë§µì´ ê° ì±„ë„ (R, G, B) ë§ˆë‹¤ ìˆìœ¼ë¯€ë¡œ) ì…ë ¥ 1ê³¼  Dk*Dk*Cout(í•„í„° ê°œìˆ˜) ë¥¼  ì»¨ë³¼ë£¨ì…˜ í•´ì„œ Df*Df*Cout (í”¼ì³ ë§µì´ í•„í„° ìˆ˜ë§ˆë‹¤ ìˆìœ¼ë¯€ë¡œ) ì´ ë˜ëŠ”ê±°ì•¼.
  (b) ëŠ” ì• ì´ˆì— ì •ì˜ê°€ í•„í„° ìˆ˜ë¥¼ ê³ ë ¤í•˜ì§€ ì•Šê³ , ê° ê¹Šì´ (ì±„ë„) ë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ Df*Df ë“¤ì— ëŒ€í•´ ì»¨ë³¼ë£¨ì…˜ì„ í•˜ë¯€ë¡œ Dk*Dk*C_in (ê·¸ë˜ì„œ ì»¤ë„ ì…ë ¥ì—ì„œ Cin ì´ ë™ì¼í•˜ë‹¤!)

  (c) ëŠ” ì• ì´ˆì— ì •ì˜ê°€ í•„í„° ìˆ˜ë¥¼ ê³ ë ¤í•˜ì—¬ í•©ì¹˜ëŠ” ì—°ì‚°ì´ë¯€ë¡œ, ê° ì±„ë„ì˜ ë™ì¼í•œ í¬ì¸íŠ¸ (1*1)ì— ëŒ€í•´ convolution ì„ ìˆ˜í–‰í•˜ê³  Cout í•„í„° ìˆ˜ë§Œí¼ ë˜ ë°˜ë³µí•œë‹¤. (ì¶”ê°€ ì°¨ì›) ê·¸ë˜ì„œ ê²°ê³¼ê°€ Df*Df*Cout ì´ ëœë‹¤.

https://roboflow.com/model-task-type/object-detection?name=mdia

Mediapipe
  The input sizes for MediaPipe object detection models vary, with common sizes being 256x256, 320x320, and 448x448 pixel

Ascii Art -> sudo apt install -y jp2a 
Yolo11n ; https://github.com/ultralytics/ultralytics/blob/main/docs/en/tasks/detect.md
  6.5 GFLOPS
  
  YOLO11x 	640 	54.7 	462.8 Â± 6.7 	11.3 Â± 0.2 	56.9 	194.9

https://stackoverflow.com/questions/75691440/how-to-move-yolov8-model-onto-gpu
ìë™ì°¨ì˜ ECO ì¥ì¹˜.

HandLandmarker (full)
Inputs
  â— A video stream or an image of arbitrary size.
  Channels order: RGB with values in [0.0, 1.0]

Singleton PAttern, Observer pattern..
  Observer pattern ì€ ì„ë² ë””ë“œì—ì„œ ìì£¼ ì‚¬ìš©í•œë‹¤ê³  í•¨.


TDD Cycle
  Fail - Pass - Refactoring
  Fail, Pass ë‘ ê°œ ëª¨ë‘ ì‘ì„±í•˜ê¸°.
  Refactoring ì€ ë™ì¼í•œ í…ŒìŠ¤íŠ¸ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì…ë ¥ì— ëŒ€í•´ í™•ì¥í•  ë•Œ ì‚¬ìš©
  mock injection
BDD ëŠ” ì•„ì§ í˜„ì—…ì—ì„œ ì¸ê¸°ë¥¼ ëŒì§€ ëª»í•˜ê³  ìˆë‹¤ê³  í•œë‹¤. ğŸ“… 2024-10-07 11:52:50
pytest-mock
  various currencies.


YOLO11l	EfficientGCN-B4	INT8	4	20	681.7

https://en.wikipedia.org/wiki/Reinventing_the_wheel

ğŸš¨ (issue); %shell> git clone https://github.com/attention-eq-everything/effgcn_cam
  Cloning into 'effgcn_cam'...
  remote: Enumerating objects: 75, done.
  remote: Counting objects: 100% (75/75), done.
  remote: Compressing objects: 100% (49/49), done.
  error: RPC failed; curl 92 HTTP/2 stream 5 was not closed cleanly: CANCEL (err 8)
  # This indicates that the RPC (Remote Procedure Call) failed due to an issue with the curl library.
  # Specifically, HTTP/2 stream 5 was not properly closed, and the operation was canceled (CANCEL with error code 8).
  # This usually points to an unexpected interruption in the network connection.

  error: 6835 bytes of body are still expected
  # This means Git expected 6,835 more bytes of data, but it did not receive them from the remote server.
  # This often happens when the connection is dropped before all the data is transmitted.

  fetch-pack: unexpected disconnect while reading sideband packet
  # This indicates that Git encountered an unexpected disconnect while reading a sideband packet,
  # which is part of the data transmission process. It suggests that the connection was lost abruptly.

  fatal: early EOF
  # "EOF" stands for "End Of File". This error means that Git reached the end of the input stream unexpectedly.
  # The data transmission was cut off before all the expected data was received.

  fatal: fetch-pack: invalid index-pack output
  # This error occurs because the index-pack process received incomplete or corrupted data.
  # Git was unable to process and package the data correctly due to the premature disconnect.

  >>> solution: retry clone


ìš”ì¦˜ì€ íŒŒì¸íŠœë‹ì„ ì´ìš©í•´ì„œ í•™ìŠµì´ ë˜ì„œ, ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¥ë„ í•œë‹¤.


cd ~/repo/effgcn_cam

CVAT  ; https://app.cvat.ai/
ì–‘í’ˆ ë¶ˆëŸ‰ êµ¬ë¶„



MSR Action3D Dataset
  https://uowmailedu-my.sharepoint.com/personal/wanqing_uow_edu_au/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fwanqing%5Fuow%5Fedu%5Fau%2FDocuments%2FResearchDatasets%2FMSRAction3D&ga=1


pytorch nn (neural network) ì‚¬ìš©ì£¼ì¸ë“¯.

microsoft-edge --version


Kinetics (Kinetics Human Action Video Dataset) ; https://github.com/cvdfoundation/kinetics-dataset
  Kinetics paper ; https://paperswithcode.com/dataset/kinetics
  kinetics-400, kinetics-600, kinetics-700

  # Dataset Loaders
    https://pytorch.org/vision/stable/generated/torchvision.datasets.Kinetics.html

https://fishshell.com/docs/current/cmds/and.html

ğŸ“° Datumaro (Dataset Management Framework)
  Dataset
    Train, vAl, Test 
      test set.. ì§€í‘œ..


nturgbd_skeletons_s001_to_s017.zip ; https://drive.google.com/open?id=1CUZnBtYwifVXS21yVg62T-vrPVayso5H
nturgbd_skeletons_s018_to_s032.zip ; https://drive.google.com/file/d/1tEbuaEqMxAV7dNc4fqu1O4M7mC6CJ50w/view

scp ì‚¬ìš©í•˜ê¸°.
  ğŸ›ï¸ e.g. 
  scp -r ./cvat/ gabriely@61.108.166.16:/home/gabriely/tests
  https://pypi.org/project/datum/
OTX example
  Build task
    Find template what we want to train
      $ otx find --template --task DETECTION
    Build task to create model
      Example)
      $ otx build Object_Detection_YOLO_X \
        --train-data-roots ../datumaro/export-coco/ \
        --val-data-roots ../datumaro/export-coco/
  Train
    Start training with parameters
      otx train params --learning_parameters.num_iter 8 \
        --learning_parameters.batch_size 1
      HPO is optional. (Hyperparameter optimization)
      # otx train --enable-hpo
      torch vision
    Start training with configuration files, after updating configuration
      data.yaml
      configuration.yaml
      po_config.yaml
  Evaoluation
  Export & Optimize
    Exports a trained model to the OpenVINO to run it on Intel hardware.
    Optimizes model using NNCF/POT depending on the model format.
  Deploy
    Create openvinio.zip with a demo appliation and exported model.

  otx ì„¤ì¹˜ ëœë‹¤ìŒì—ë„ ì˜¤ë¥˜ê°€ ëœ¨ë©´ mmcv full ì¬ì„¤ì¹˜?

âš“ Action Recognition Datasets: "NTU RGB+D" Dataset and "NTU RGB+D 120" Dataset ; https://rose1.ntu.edu.sg/dataset/actionRecognition/
https://rose1.ntu.edu.sg/challenge/ActionRecognitionChallenge/
  .skeleton íŒŒì¼ êµ¬ì¡° ; https://github.com/shahroudy/NTURGB-D/tree/master/Python
  https://github.com/shahroudy/NTURGB-D/tree/master

ìš°ë¶„íˆ¬ í´ë¦½ë³´ë“œ


EfficientGCN, SGN ì€ ëª¨ë‘ .skeleton ë°ì´í„°ë¥¼ ê°€ì§€ê³  í•™ìŠµì‹œì¼°ë‹¤ê³  í–ˆì–ì•„. ë§ì•„?
ê·¼ë° ë³´í†µ ì¼ë°˜ ì¹´ë©”ë¼ì—ì„œëŠ” ì‚¬ì§„ í”„ë ˆì„ë§Œ ì£¼ì”ì•„. ê·¸ëŸ´ ê²½ìš° ì–´ë–»ê²Œ ì¶”ë¡ í•˜ì§€? ë‚˜ëŠ” mediapipe pose, mediapipe hand landmarks ë‘ ê°œì˜ ëª¨ë¸ì—ì„œ ë‚˜ì˜¨ output ì„ EfficientGCN ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ ì‹¶ì–´.

ê·¸ë¦¬ê³  ìƒˆë¡œìš´ ë™ì‘ì„ EfficientGCN ì—ì„œ í•™ìŠµì‹œí‚¤ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼í•˜ì§€? ì´ ë•Œë„ ë§ˆì°¬ê°€ì§€ë¡œ ì‚¬ì§„ í”„ë ˆì„ë§Œ ìˆì–ì•„. (Fine-tuning ì´ë¼ê³  í•˜ë‚˜?)
  ê·¸ë¦¬ê³  ì˜ˆë¥¼ë“¤ì–´ì„œ .h5 ë°ì´í„°ì…‹ì— í•´ë‹¹ í”„ë ˆì„ì´ ì–´ë–¤ ë™ì‘ì¸ì§€ì— ëŒ€í•´ ë¼ë²¨ë§ ë˜ì–´ìˆëŠ” ë°ì´í„°ì…‹ì˜ ê²½ìš°ëŠ” ë˜ ì–´ë–»ê²Œí•´?


1. Mediapipe Pose detection, Mediapipe Hand landmark detection ìœ¼ë¡œë¶€í„° íƒì§€í•œ 

https://github.com/open-mmlab/mmaction2

https://github.com/MVIG-SJTU/AlphaPose

poseconv3d FLOPS https://ar5iv.labs.arxiv.org/html/2104.13586
  Table 11: PoseConv3D instantiated with: C3D, X3D, SlowOnly. 
ğŸ‘ âš“ posec3d ; https://arxiv.org/abs/2104.13586
  https://arxiv.org/pdf/2104.13586
https://github.com/kennymckormick/pyskl/tree/main/configs/posec3d
https://mmaction2.readthedocs.io/en/latest/model_zoo/skeleton.html#posec3d
https://github.com/open-mmlab/mmaction2/tree/main/configs/skeleton/posec3d

https://github.com/kennymckormick/pyskl/tree/main/configs/posec3d

>> stm32 f103rb
https://github.com/kennymckormick/pyskl/tree/main?tab=readme-ov-file
âš“ SOTA (State of the Art) ; ...
  íŠ¹ì • ë¶„ì•¼ë‚˜ ë¬¸ì œì— ëŒ€í•œ ìµœê³  ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•œ ëª¨ë¸ ë˜ëŠ” ê¸°ìˆ 
Customizing  ; https://github.com/open-mmlab/mmaction2/blob/main/configs/skeleton/posec3d/custom_dataset_training.md
  https://github.com/kennymckormick/pyskl/blob/main/configs/posec3d/x3d_shallow_ntu60_xsub/joint.py
    model = dict(
        type='Recognizer3D',
        backbone=dict(
            type='X3D',
            gamma_d=1,
            in_channels=17,
            base_channels=24,
            num_stages=3,
            se_ratio=None,
            use_swish=False,
            stage_blocks=(2, 5, 3),
            spatial_strides=(2, 2, 2)),
        cls_head=dict(
            type='I3DHead',
            in_channels=216,
            num_classes=60,
            dropout=0.5),
        test_cfg=dict(average_clips='prob'))

  joint limb

https://github.com/kennymckormick/pyskl/tree/main
https://github.com/kennymckormick/pyskl/blob/main/configs/posec3d/x3d_shallow_ntu60_xsub/limb.py


>>>>>>>>>>>> in mmaction2/
  poetry init


poetry lock --no-update
poetry show --tree
poetry add mmengine openmim "mmcv<2.2.0"

mim download mmaction2 --config tsn_imagenet-pretrained-r50_8xb32-1x1x8-100e_kinetics400-rgb --dest .
# The demo.mp4 and label_map_k400.txt are both from Kinetics-400
python demo/demo.py tsn_imagenet-pretrained-r50_8xb32-1x1x8-100e_kinetics400-rgb.py \
    tsn_imagenet-pretrained-r50_8xb32-1x1x8-100e_kinetics400-rgb_20220906-2692d16c.pth \
    demo/demo.mp4 tools/data/kinetics/label_map_k400.txt
https://github.com/open-mmlab/mmaction2
  âš ï¸ poetry add mmengine openmim
    ... mmaciton docs ì—ëŠ” ì—†ì—ˆëŠ”ë°.. github ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ë³´ë„ë¡ í•˜ì. ë¬¸ì„œ ê°±ì‹ ì´ ì•ˆë˜ëŠ”ë“¯ ë³´ì„.


set DISPLAY (tailscale status | grep "active; direct" | awk '{print $1}'):0


iftop

âš“ Docker
  Windows - Docker - Settings - Resources - WSL Integration
    Resources WSL Integration
      - âœ”ï¸ Enable integration with my default WSL distro
      - âœ”ï¸ Ubuntu-24.04
  "NVIDIA Container Toolkit makes host OS GPU drivers accessible to containers, allowing them to run different CUDA versions while ensuring compatibility and GPU acceleration.
  >Dev Containers: New Dev Container...
    https://containers.dev/templates
  # Ubuntuì—ì„œ Docker ê·¸ë£¹ì— ì¶”ê°€ëœ ì‚¬ìš©ì ëª©ë¡ì„ í™•ì¸
    getent group docker


  Ubuntu..
    https://docs.docker.com/engine/install/linux-postinstall/
    sudo usermod -aG docker $USER

1. MMACtion2 (toolbox)
  - Posec3D ëª¨ë¸ ì‚¬ìš© ì˜ˆì •
    Backbone X3D s (FLOPS: 0.6G) ; https://arxiv.org/pdf/2104.13586
    ì´ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë°©ë²• ì°¾ì•¼ì•„ í•¨.
  - íŒŒì¼ë¡œ ì¹´ë©”ë¼ ì‹¤ì‹œê°„ í”„ë ˆì„ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
  - í¬ì¦ˆ ëª¨ë¸ì„ ë”°ë¡œ ì¨ì•¼í•˜ëŠ”ì§€?

  
2. Docker
  >> [O] ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ í˜¸ìŠ¤íŠ¸ì˜ GPU ì‚¬ìš©í•˜ëŠ” ë°©ë²•
  >> ì¹´ë©”ë¼ ì¥ì¹˜ ê¶Œí•œ í—ˆìš©í•˜ëŠ” ë°©ë²• ì°¾ì•„ì•¼ í•¨.
  >> *volume mount ë°©ì‹ export/import ë˜ëŠ” SCP ë¡œ í˜¸ìŠ¤íŠ¸ì— ë°±ì—…í•˜ëŠ” ë°©ë²• ì°¾ì•¼ì•„ í•¨.


>> ë©´ì ‘: bitbake, yocto bblayer (BitBake layer)
ğŸ‘ 
âš“ mpv ; https://en.wikipedia.org/wiki/Mpv_(media_player)
  âš“ Keyboard shortcut ; https://mpv.io/manual/master/
    # Keyboard Control
    # [ and ]
      Decrease/increase current playback speed by 10%.
    # l
      Set/clear A-B loop points. See ab-loop command for details.


âš“ CCID (chip card interface device) ; https://en.wikipedia.org/wiki/CCID_(protocol)

sudo apt install libnvidia-encode1

ğŸš¨ (issue); mpv browse_out/*.mp4
  [vaapi] libva: vaGetDriverNames() failed with unknown libva error
  âš ï¸â­• reqiuired.. ğŸ“… 2024-10-10 13:04:51
  # to use Hardware acceleration
    sudo apt install nvidia-cuda-toolkit
    mpv --hwdec=vdpau browse_out/*.mp4

    ğŸ†š VDPAU, VA-API, NVDEC
      VDPAU (Video Decode and Presentation API for Unix):
        Developed by NVIDIA for video decoding on NVIDIA GPUs.
        Optimized for NVIDIA hardware.

      VA-API (Video Acceleration API):
        Developed by Intel, mainly for Intel integrated GPUs and some AMD GPUs.
        Limited compatibility with NVIDIA GPUs.

      NVDEC:
        NVIDIA-specific API for hardware decoding on modern NVIDIA GPUs.
        Operates through CUDA and works with NVIDIA's official drivers and SDK.

    
ğŸ†šğŸ’¡ Hypervisor vs WSL2
  - Hardware-level virtualization
  - Creates and runs virtual machines
  - Type1: Native/Bare-metal.
  - Type2: (VMWare, QEMU, ...) ?
  BootLoader ê°€ í•˜ë“œì›¨ì–´ë¥¼ ìš´ì˜ì²´ì œê°€ ì“¸ ìˆ˜ ìˆë„ë¡ ì´ˆê¸°í™”ë¥¼ í•œë‹¤. ë¶€íŒ… ì‹œê°„ì´ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì´ ë‹¨ì . 30~60ì´ˆ í•„ìš”.
  ì¢‹ì§€ ì•Šë‹¤ëŠ” ê²ƒì€ ì•„ë‹ˆë‹¤. Windows ë„ ì´ê²ƒ ê¸°ë°˜ìœ¼ë¡œ ëŒì•„ê°€ê³  ìˆìŒ.
  >> ê³ ê¸‰ ì°¨ëŸ‰ì—ëŠ” Hypervisor ì— ì—¬ëŸ¬ OS ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœë‹¤ê³ ë„ í•¨.
    ê³„ê¸°íŒ. ë””ì§€í„¸ í´ëŸ¬ìŠ¤í„°.
    â­• íŠ¸ë Œë“œ ã…‡ã…‡. í•˜ì´í¼ë°”ì´ì €ê°€ ì§€ì›ì´ ë˜ì–´ì•¼ í•¨. RTOS (í•˜ë“œ ë¦¬ì–¼íƒ€ì„ ì²˜ë¦¬ìš©), OS (ê·¸ë˜í”½ ì²˜ë¦¬ìš©), firmare ...
  ë² ì–´ë©”íƒˆ OS ëŠ” ì²˜ë¦¬í•˜ê¸° ì–´ë µê³ 
  RTOS: Hard-real-time
    vs ì¼ë°˜ OS: Soft-real-time
  
  ì¸í…Œë¡œ ë§ˆì°¬ê°€ì§€ë¡œ x86..ì—ì„œë„ ê·¸ëŸ¼. 

Container
  - OS-level virtualization.
  - isolate app from its environment
  - ìš´ì˜ì²´ì œê°€ ê³µìœ ë˜ê³  ìˆë‹¤.



>> ê·¸ëŸ¬ë‹ˆê¹Œ ê³ ì„±ëŠ¥ì´ í•„ìš”í•œ ì‹œìŠ¤í…œì—ì„œëŠ”
ë„ì»¤ê°€ ë¦¬ëˆ…ìŠ¤/ìœ ë‹‰ìŠ¤ì—ì„œ ì“°ê³  
  .. ë„ì»¤ê°€ ëŒ€ê¸°ì—…ì—ì„œëŠ” ì•ˆì“°ì¸ë‹¤. ìœ ë£Œ. containerd

  Container Management ğŸ”ª Podman
  Image Build ğŸ”ª Kaniko   --> Buildsh ë¡œ ë³€ê²½?..
  Image Management ğŸ”ª Skopeo
  Kubernetes Application Management ğŸ”ª Helm

lab ì‹¤ì—ì„œ spin-out
  ë„êµ¬ ì¤‘ ì–´ë–¤ ê²ƒì´ ë” ë³´ì•ˆì„±ì´ ë†’ì€ì§€ëŠ” ì‚¬ìš© í™˜ê²½ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. í´ë¼ìš°ë“œ ë° Kubernetes í™˜ê²½ì—ì„œëŠ” Kaniko, ë¡œì»¬ ë° ë ˆë“œí–‡ ê¸°ë°˜ í™˜ê²½ì—ì„œëŠ” Buildahê°€ ë” ë³´ì•ˆì„±ì´ ë†’ë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


ë¦¬ì–¼ C ì¸í¬í…Œì¸ë¨¼íŠ¸??? 
Key/VAlue
  ETCD
    Distributed Key/alue Store
    Like a Directiory Tree
    JSON/RST API
  Memachced, Redis.
mqtt  vs kafka? ZeroMQ vs 
Image Build ğŸ”ª Kaniko   --> Buildsh ë¡œ ë³€ê²½?..


âŒ¨ï¸ ì›¹ í˜ì´ì§€ ë¡œì»¬ ìºì‹œ í´ë¦¬ì–´: Ctrl + Shift + R: í˜„ì¬ í˜ì´ì§€ë¥¼ ê°•ì œë¡œ ìƒˆë¡œê³ ì¹¨(ìºì‹œ ë¬´ì‹œ)í•©ë‹ˆë‹¤.


IPC (Inter process communication)
  pipe1 pipe2
  messge queue
  shared memory

  tcp/ip // ì˜ê²¬ì— ë”°ë¼ ë‹¬ë¦¼. IPCì— ë„£ì„ì§€ ì•ˆë„£ì„ì§€.


mqtt  vs kafka

dockerc (ë„ì»¤ íšŒì‚¬ê°€ ë§Œë“ ...) vs docker.io (ë°ë¹„ì•ˆì´ ë§Œë“ .. ë„ì»¤ì˜ 100% ê¸°ëŠ¥ì„ ì“°ì§€ ëª»í•  ìˆ˜ ì‡ë‹¤.)

LaTeX
  BibTeX ; BibTeXëŠ” LaTeXì™€ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ì°¸ê³ ë¬¸í—Œ ê´€ë¦¬ ë„êµ¬ì…ë‹ˆë‹¤. ; https://en.wikipedia.org/wiki/BibTeX

# Modify the Config

  â­• Recommend ...

  # Modify Dataset

  # Modify Runtime Config

  # Modify Model Config
Files...
  configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py
  configs/_base_/schedules/sgd_100e.py

ğŸ›ï¸ e.g. tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb
  wget https://download.openmmlab.com/mmaction/kinetics400_tiny.zip
  mkdir -p data/
  unzip kinetics400_tiny.zip -d data/

  python tools/visualizations/browse_dataset.py \
      configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py \
      browse_out --mode pipeline

  configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py
    dataset_type = "VideoDataset"
    data_root = "data/kinetics400_tiny/train"
    data_root_val = "data/kinetics400_tiny/val"
    ann_file_train = "data/kinetics400_tiny/kinetics_tiny_train_video.txt"
    ann_file_val = "data/kinetics400_tiny/kinetics_tiny_val_video.txt"
    // requirees moviepy 


  python tools/train.py configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py

  python tools/test.py configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py \
      work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_5.pth


  #ğŸš£ Model ì¢…ë¥˜ í™•ì¸
    %shell> tree -L 2 configs
    # >> configs/skeleton/posec3d ; https://github.com/open-mmlab/mmaction2/tree/main/configs/skeleton/posec3d

ğŸ›ï¸ e.g. Skeleton-based
  1. Preparing Skeleton Dataset ; https://github.com/open-mmlab/mmaction2/tree/main/tools/data/skeleton
python tools/train.py ${CONFIG_FILE} [optional arguments]

  wget https://download.openmmlab.com/mmaction/kinetics400_tiny.zip
  mkdir -p data/
  unzip kinetics400_tiny.zip -d data/


PoseC3D ; https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_Revisiting_Skeleton-Based_Action_Recognition_CVPR_2022_paper.pdf
  Figure 1. PoseConv3D takes 2D poses as inputs. In general, 2D poses are of better quality than 3D poses. We visualize 2D posesestimated with HRNet for videos in NTU-60 and FineGYM in (a).
  Apparently, their quality is much better than 3D poses collected by sensors (b) or estimated with state-of-the-art estimators (c).
    ğŸ“ Noise and Artifacts in 3D Poses: 3D pose estimation, whether collected by depth sensors (like Kinect) or estimated using state-of-the-art methods (like VIBE)
      , can introduce noise and inaccuracies due to hardware limitations or model errors, especially in real-world conditions.

  Scalability: It efficiently handles scenarios involving multiple persons without increased computational costs, unlike GCNs, which scale linearly with the number of persons.
    because of PoseConv3D use 2D Hitmap volume...?


ëª¨ë“  í–‰ë™ì¸ì‹ ëª¨ë¸ì€ ì—°ì†ì ì¸ í”„ë ˆì„ì— ëŒ€í•´ íŒë‹¨í•´ì•¼ í•˜ëŠ”ë°, ë™ì¼í•œ ì‚¬ëŒì¸ì§€ ì–´ë–»ê²Œ ì¶”ì í•˜ê³  ì´ë¥¼ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì„œ íŒë‹¨í•˜ëŠ”ì§€.. ì‚¬ëŒ Tacking ì•Œê³ ë¦¬ì¦˜ í•„ìš”í•¨. pose data?

Yolo Deep SORT ? íŠ¸ë˜í‚¹ ì•Œê³ ë¦¬ì¦˜?

1. 3D ê³¨ê²© ê¸°ë°˜ GCN ëª¨ë¸ì— ëŒ€í•œ ì˜ê²¬
  ë‹¨ì 
    ë†’ì€ ë¹„ìš© ë° ë³µì¡ì„±:
        3D ê³¨ê²© ê¸°ë°˜ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë ¤ë©´ ì „ìš© í•˜ë“œì›¨ì–´ê°€ í•„ìš”í•˜ë©°, ì´ í•˜ë“œì›¨ì–´ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ ë¹„ìš©ê³¼ ì„¤ì¹˜ ë³µì¡ì„±ì„ ë™ë°˜í•©ë‹ˆë‹¤.
        ì‹¤ë‚´ì™€ ê°™ì´ ì œì–´ëœ í™˜ê²½ì—ì„œëŠ” ë†’ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆì§€ë§Œ, ì•¼ì™¸ í™˜ê²½ì´ë‚˜ ëŒ€ê·œëª¨ ì„¤ì¹˜ì—ì„œëŠ” ë¹„ìš©ê³¼ ìœ ì§€ë³´ìˆ˜ ì¸¡ë©´ì—ì„œ ë¶€ë‹´ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
1. 3D ì„¼ì„œì˜ ê±°ë¦¬ í•œê³„
  Microsoft Kinectì™€ ê°™ì€ ì¼ë°˜ì ì¸ 3D ì„¼ì„œ:
      ë³´í†µ 0.5mì—ì„œ 4.5m ì‚¬ì´ì—ì„œ ìµœì ì˜ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤. ì´ ë²”ìœ„ë¥¼ ë„˜ì–´ê°€ë©´, ê¹Šì´ ì •ë³´ì˜ ì •í™•ë„ê°€ ë–¨ì–´ì§€ê±°ë‚˜ íƒì§€ê°€ ì–´ë ¤ì›Œì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  Intel RealSense:
      ëª¨ë¸ì— ë”°ë¼ ì¡°ê¸ˆì”© ë‹¤ë¥´ì§€ë§Œ, ìµœëŒ€ íƒì§€ ê±°ë¦¬ëŠ” ë³´í†µ 4m ì „í›„ì…ë‹ˆë‹¤. RealSenseì˜ ê³ ê¸‰ ëª¨ë¸(ì˜ˆ: D455)ì€ ì´ë³´ë‹¤ ì¡°ê¸ˆ ë” ë©€ë¦¬ íƒì§€í•  ìˆ˜ ìˆì§€ë§Œ, ì—¬ì „íˆ ì œí•œì´ ìˆìŠµë‹ˆë‹¤.
  Time-of-Flight(TOF) ì¹´ë©”ë¼:
      ëŒ€ë¶€ë¶„ì˜ TOF ì¹´ë©”ë¼ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 10m ì´í•˜ì—ì„œ ì‘ë™í•˜ë©°, ì´ë³´ë‹¤ ë¨¼ ê±°ë¦¬ì—ì„œëŠ” ì‹ í˜¸ì˜ ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ“° ë©€í‹°ë·° 2D ì¹´ë©”ë¼ ??
  3D ê¸°ë°˜ ì†”ë£¨ì…˜ì€ ì •í™•ì„±ê³¼ ì •ë°€í•œ ë°ì´í„° ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°ì— ì„ í˜¸ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´:
      ìŠ¤í¬ì¸  ë¶„ì„: ì„ ìˆ˜ì˜ ìì„¸ë‚˜ ë™ì‘ì„ ì •ë°€í•˜ê²Œ ì¶”ì í•´ì•¼ í•  ë•Œ, 3D ë°ì´í„°ê°€ ìœ ë¦¬í•©ë‹ˆë‹¤.
      ì˜ë£Œ ë° ì¬í™œ: í™˜ìì˜ ì›€ì§ì„ì„ ì •í™•íˆ ì¸¡ì •í•˜ê³  ë¶„ì„í•´ì•¼ í•  ë•Œ, 3D ì†”ë£¨ì…˜ì€ í•„ìˆ˜ì ì…ë‹ˆë‹¤.
      ë¡œë´‡ ê³µí•™: ììœ¨ ì£¼í–‰ ë¡œë´‡ì´ë‚˜ ë¡œë´‡ íŒ”ê³¼ ê°™ì€ ì‹œìŠ¤í…œì—ì„œ ì •ë°€í•œ ë™ì‘ì„ ì¸ì‹í•˜ëŠ” ë° 3D ì •ë³´ëŠ” ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

  2D ê¸°ë°˜ ì†”ë£¨ì…˜ì€ ë‚®ì€ ë¹„ìš©ê³¼ ëŒ€ê·œëª¨ ì ìš©ì´ í•„ìš”í•œ ê²½ìš°ì— ì í•©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´:
      ìŠ¤ë§ˆíŠ¸ ì‹œí‹° ë° êµí†µ ê´€ë¦¬: ëŒ€ê·œëª¨ì˜ ì¸êµ¬ ë°€ì§‘ ì§€ì—­ì—ì„œ ì‚¬ëŒì˜ ì›€ì§ì„ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë° 2D ê¸°ë°˜ ì†”ë£¨ì…˜ì€ ë§¤ìš° íš¨ìœ¨ì ì…ë‹ˆë‹¤.
      ì†Œë§¤ ë° ìƒì—… ì‹œìŠ¤í…œ: ì‡¼í•‘ëª°ì´ë‚˜ ìƒì ì—ì„œ ê³ ê°ì˜ í–‰ë™ì„ ë¶„ì„í•˜ëŠ” ë°ë„ ì €ë¹„ìš©ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ 2D ì‹œìŠ¤í…œì´ ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
      ëª¨ë°”ì¼ ì¥ì¹˜ ë° IoT ì‹œìŠ¤í…œ: ë¦¬ì†ŒìŠ¤ê°€ ì œí•œëœ ì¥ì¹˜ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸ì‹í•  ë•ŒëŠ” ê°€ë²¼ìš´ 2D ëª¨ë¸ì´ ë” ìœ ë¦¬í•©ë‹ˆë‹¤.

  
  
Monodeapth ë¡œ ì¸¡ì •
  Depth anything ; https://depth-anything.github.io/
    ë¬¼ì²´ ì‚¬ì´ì— ì ˆëŒ€ì ì¸ ê±°ë¦¬ë¥¼ ì•Œê³  ìˆë‹¤ëŠ” ê°€ì •í•˜ì—¬ ì–´ëŠì •ë„ ì ˆëŒ€ê±°ë¦¬ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ëŠ” ìˆë‹¤ê³  í•œë‹¤?
https://github.com/kccistc/openvino/tree/main/Tutorials/depth_anything

Despite the considerable improvements, the settings of
different GCN approaches do not align well.










===
Global Motion Compensation (GMC) is a technique used to compensate for the motion of the camera or the entire scene in tracking algorithms. It helps in isolating the motion of tracked objects from global motion, such as camera panning, tilting, or zooming, which could otherwise distort the motion patterns of the objects in the scene.

Dynamic device management
âš“ udev ; https://man7.org/linux/man-pages/man7/udev.7.html
  #ğŸ“ DESCRIPTION ğŸ“… 2024-10-11 15:09:24
    The kernel usually just assigns unpredictable device names based on the order of discovery.
    Meaningful symlinks or network device names provide a way to reliably identify devices based on their properties or current configuration.

    ğŸª± The udev daemon, systemd-udevd.service(8), ...  When udev receives a device event, it matches its configured set of rules against various device attributes to identify the device.
    ğŸª± udev database

  # Keys
    # ATTRS{filename}

    The ENV, GROUP, MODE, NAME, OWNER, PROGRAM, RUN, SECLABEL, and SYMLINK fields support simple string substitutions. 
âš“ udevadm ; https://man7.org/linux/man-pages/man8/udevadm.8.html
  #ğŸš£ Table 1. udevadm info output prefixes

ì•„ë˜êº¼ curl -fsSL ~ ë¶€ë¶„ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± íŒ”ìš” ===
âœ… (how); settings for Embedded development ğŸ“… 2024-10-11 14:17:51
  - install PlatformIO Extension in VSCode
  - install udev ; https://docs.platformio.org/en/latest/core/installation/udev-rules.html
    | https://en.wikipedia.org/wiki/Udev
    ğŸš£ Linux users have to install udev rules for PlatformIO supported boards/devices.
    %shell>
      # udb: user device or userspace/dev
      # https://raw.githubusercontent.com/platformio/platformio-core/develop/platformio/assets/system/99-platformio-udev.rules
      curl -fsSL https://raw.githubusercontent.com/platformio/platformio-core/develop/platformio/assets/system/99-platformio-udev.rules | sudo tee /etc/udev/rules.d/99-platformio-udev.rules
      # udevadm: udev administator
      sudo udevadm control --reload-rules
      sudo udevadm trigger
  - %vscode> PlatformIO: PlatformIO Home
    Quick Access - New Project
      - Project Wizard
        - Name: signal-master
        - Board: Arduino Uno
        - Framework: Arudino
        - Location: <project_root>
  ##  https://docs.platformio.org/en/latest/tutorials/espressif32/arduino_debugging_unit_testing.html ~
  # Compiling and Uploading the Firmware: Compile, Upload, Minitor
  # ğŸ“° Adding Bluetooth LE features

  - check conneted device
    %shell> udevadm info --query=property --name=/dev/ttyACM0 | grep --extended-regexp 'ID_VENDOR_FROM_DATABASE|ID_MODEL_FROM_DATABASE'



%shell>
  lsusb
  dmesg | grep ttyACM

Debugging the Firmware
Setting Up the Hardware
Writing Unit Tests
Adding Bluetooth LE features
Conclusion

  

ESP32ëŠ” Espressif Systemsì—ì„œ ê°œë°œí•œ ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬ ì¹©
JTAG(Joint Test Action Group)ëŠ” ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬ë‚˜ ì¹©ì˜ ë‚´ë¶€ë¥¼ ë””ë²„ê¹…í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë””ë²„ê¹… ì¸í„°í˜ì´ìŠ¤
Arduino Uno R3ì˜ ê²½ìš°, ë³´í†µ JTAG ê°™ì€ ë””ë²„ê¹… ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ì‹œë¦¬ì–¼ ëª¨ë‹ˆí„°ë¥¼ í†µí•´ ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì˜¤ë¥˜ë¥¼ ë””ë²„ê¹…í•©ë‹ˆë‹¤. ë” ì •ë°€í•œ ë””ë²„ê¹…ì´ í•„ìš”í•˜ë‹¤ë©´, ì•„ë‘ì´ë…¸ì— í˜¸í™˜ë˜ëŠ” ë””ë²„ê¹… íˆ´ì´ë‚˜ ì—…ê·¸ë ˆì´ë“œëœ ë³´ë“œ(ì˜ˆ: Arduino Zero)ë¥¼ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

/dev/ttyACM0ëŠ” Linuxì—ì„œ ACM (Abstract Control Model) ì¥ì¹˜ë¡œ ë“±ë¡ëœ USB ì‹œë¦¬ì–¼ í¬íŠ¸
  ACMì€ USB CDC (Communications Device Class) í‘œì¤€ì˜ ì¼ë¶€ë¡œ, ëª¨ë€ì´ë‚˜ ì‹œë¦¬ì–¼ í†µì‹  ì¥ì¹˜ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë¨.
tty (teletypewriter): ì‹œë¦¬ì–¼ í¬íŠ¸ë‚˜ ê°€ìƒ í„°ë¯¸ë„ ë“±ì„ ì˜ë¯¸.


Bluetooth module HC-06 FC-114




Command Query Responsibility Segregation 
CQRS, EDA íŒ¨í„´

Event-Sourcing íŒ¨í„´
ğŸ“ğŸ“ğŸ“ Design pattern
  https://learn.microsoft.com/en-us/dotnet/architecture/microservices/microservice-ddd-cqrs-patterns/eshoponcontainers-cqrs-ddd-microservice
    ğŸ“ It's important to understand that CQRS and most DDD patterns (like DDD layers or a domain model with aggregates) are not architectural styles, but only architecture patterns. 
    Microservices, SOA, and event-driven architecture (EDA) are examples of architectural styles.
    ... [all]
    Different Bounded Contexts (BCs) will employ different patterns. They have different responsibilities, and that leads to different solutions. 
    ... There is only one application architecture: ...


https://developer-wh.tistory.com/entry/%EA%BC%BC%EA%BC%BC%ED%95%98%EA%B2%8C-%EB%85%BC%EB%AC%B8%EC%9D%BD%EA%B8%B0-PYSKL-Towards-Good-Practices-for-Skeleton-Action-Recognition-2022



â¡ï¸ TODO >>>>>>>>>>>>>> ; https://code.visualstudio.com/remote/advancedcontainers/develop-remote-host



ì„ë² ë”©ì€ ê°ì²´ì˜ ì‹œê°ì  íŠ¹ì§•ì„ ìˆ˜ì¹˜ë¡œ ë³€í™˜í•œ ë²¡í„°ì…ë‹ˆë‹¤. ê³ ì°¨ì›ì˜ ì •ë³´ë¥¼ ì €ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•œë‹¤ëŠ” ì .



https://docs.ultralytics.com/guides/nvidia-jetson/#quick-start-with-docker



$RANDOMì€ bashì—ì„œ ë¬´ì‘ìœ„ ìˆ«ìë¥¼ ìƒì„±í•˜ëŠ” ì˜ˆì•½ëœ ë³€ìˆ˜ì…ë‹ˆë‹¤. ì´ë¥¼ ì´ìš©í•´ 12000ë¶€í„° 31999ê¹Œì§€ì˜ ë¬´ì‘ìœ„ í¬íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
$MASTER_PORTëŠ” PyTorch ë¶„ì‚° í•™ìŠµì—ì„œ ë…¸ë“œ ê°„ í†µì‹ ì— ì‚¬ìš©ë˜ëŠ” í¬íŠ¸ë¥¼ ì§€ì •í•˜ëŠ” í™˜ê²½ ë³€ìˆ˜ì…ë‹ˆë‹¤
set -xëŠ” ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œ ë””ë²„ê¹… ëª¨ë“œë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤.
MKL_SERVICE_FORCE_INTEL=1ëŠ” MKLì´ ë¹„ Intel CPUì—ì„œë„ ì‘ë™í•˜ë„ë¡ ê°•ì œë¡œ ì„¤ì •í•˜ëŠ” í™˜ê²½ ë³€ìˆ˜.


>>> KeyPoints ; 25 for NTURGB+D 3D skeleton, 17 for CoCo, 18 for OpenPose, etc. )




To update the inference pipeline and ensure it aligns with your training configuration, I'll use the configuration you've provided and match the inference process for YOLO Pose with the structure you trained PoseC3D on. The key points are:
  Ensure Consistent Input: PoseC3D was trained with 48-frame clips and expects inputs of shape (N, C, T, H, W), where N is batch size, C is channel (17 keypoints), T is the number of frames (48), H and W are height and width.
  Keypoint Preprocessing: During training, the keypoints were processed as (x, y) coordinates, so the inference needs to pass keypoints in the same format.
  Batch Size Alignment: During training, a batch size of 1 was used, so we will ensure the same during inference.

  

í”„ë¡ íŠ¸ì—ì„œ ê°€ì¥ í•œí•œ ê²ƒì€ ì›¹ ì–´ì…ˆë¸”ëŸ¬.
  ê·¸ë˜ì„œ Rust ê°€ ë” ëœ¬ë‹¤ê³  í•œë‹¤.
  í”„ë¡ íŠ¸ì—”ë“œ ì½”ì–´ì—”ì§€ë‹ˆì–´ë“¤ì˜ í•œí•« ì£¼ì œë¼ê³  í•œë‹¤. ã…
  ìë°”ìŠ¤í¬ë¦½íŠ¸ ì–¸ì–´ ìì²´ì˜ í•œê³„ì¸ ì‹±ê¸€ ìŠ¤ë ˆë“œì˜ í•œê³„ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•¨
  "Web Accember" github í™•ì¸.
  ì›ë˜ëŠ” í•˜ë“œì›¨ì–´ë³„ë¡œ ì–´ì…ˆë¸”ëŸ¬ë¥¼ ì´í•´í•˜ê³  ìˆì–´ì•¼ í–ˆëŠ”ë°, Rustê°€ ì´ë¥¼ í•´ê²°í•´ì¤€ë‹¤ê³  í•œë‹¤. ê·¸ë˜ì„œ ëœ¬ë‹¤ê³  í•¨. ìƒë‹¹ë¶€ë¶„ í•´ê²°ì„ í•´ì¤˜ì„œ.

ë°±ì—”ë“œì—ì„œëŠ”
  ì „ì„¸ê³„ì ìœ¼ë¡œëŠ” node ê°€ ê°€ì¥ ìœ ëª…í•˜ë‹¤ê³  í•œë‹¤. ìš°ë¦¬ë‚˜ë¼ë§Œ ìë°”ì— ëª°ë ¤ìˆë‹¤ê³  í•¨.
  ìë°”ìŠ¤í¬ë¦½íŠ¸/íŒŒì´ì¬/ìë°”..
  ëª¨ë°”ì¼ ì•± í”„ë¡œê·¸ë˜ë°ì´ íŠ¸ë Œë“œê°€ ë˜ì—ˆì„ ë•Œ ìë°” ì‹œì¥ì´ ë˜ê²Œ ì»¤ì ¸ì„œê·¸ë ‡ë‹¤ê³  í•¨.
  ìë°”ìŠ¤í¬ë¦½íŠ¸ ì—”ì§„: V8 ì—”ì§„... ë…¸ë“œJS ê°€ ê°ê´‘ì„ ë°›ì€ ì´ìœ .. ì´ê±°ë„ ì‹±ê¸€ ìŠ¤ë ˆë“œì˜ í•œê³„ê°€ ìˆë‹¤ê³  í•¨. 

ì–¸ì–´ëŠ” í¬ê²Œ Memory-Unmanaged ì™€ Memory-Manged ë¡œ ë‚˜ë‰œë‹¤.

ì¸í„°ëŸ½íŠ¸ íœë”©.
pid ì •ë°€ì œì–´ ì•Œê³ ë¦¬ì¦˜?
ğŸª± Tensor. 
  In mathematics, a tensor is an algebraic object that describes a multilinear relationship between sets of algebraic objects related to a vector space. Tensors may map between different objects such as vectors, scalars, and even other tensors.


ì´ì¬ì„± ê°•ì‚¬ë‹˜. ììœ¨ì£¼í–‰ ì½”ë“œ
  https://gitlab.com/MAZE-dankook/self-driving-patrol-car
  

âš“ torch.permute ; https://pytorch.org/docs/stable/generated/torch.permute.html
  Returns a view of the original tensor input with its dimensions permuted.
âš“ torch.stack ; https://pytorch.org/docs/stable/generated/torch.stack.html#torch-stack

ëª¨ë‹ˆí„° ì ˆì „ ëª¨ë“œì—ì„œ ë°œìƒí•˜ëŠ” Ubuntu ì‹œìŠ¤í…œ ì˜¤ë¥˜ í•´ê²°ë°©ë²•?
  # Disable automatic screen lock when the screen is idle
  # This prevents the screen from locking after a certain period of inactivity.
  gsettings set org.gnome.desktop.screensaver lock-enabled false

  # Disable the monitor power saving mode by setting the idle delay to 0 seconds
  # This stops the monitor from going into power saving mode.
  gsettings set org.gnome.desktop.session idle-delay 0

  # Disable dimming the screen when the system is idle
  # By setting idle-dim to false, the screen will not dim after being inactive.
  gsettings set org.gnome.settings-daemon.plugins.power idle-dim false

  # Disable automatic suspend when the system is plugged into AC power
  # This prevents the system from going into suspend mode when connected to a power source.
  gsettings set org.gnome.settings-daemon.plugins.power sleep-inactive-ac-type 'nothing'

  # Enable automatic suspend when the system is running on battery power
  # This will put the system into suspend mode after a period of inactivity on battery.
  gsettings set org.gnome.settings-daemon.plugins.power sleep-inactive-battery-type 'suspend'

  gsettings set org.gnome.desktop.screensaver lock-enabled true

  gsettings set org.gnome.settings-daemon.plugins.power sleep-inactive-ac-type 'nothing'
  gsettings set org.gnome.settings-daemon.plugins.power sleep-inactive-battery-type 'nothing'
  gsettings set org.gnome.settings-daemon.plugins.power idle-dim false
  gsettings set org.gnome.desktop.session idle-delay 0
  gsettings set org.gnome.desktop.screensaver lock-enabled true


YOLO11n-pose	640	50.0	81.0	52.4 Â± 0.5	1.7 Â± 0.0	2.9	7.6



ì¿ íŒ¡ - ë¡¯ë°ì œê³¼ ì œíœ´.
  https://shop.coupang.com/A00148950?source=brandstore_sdp_atf_topbadge&pid=8204987238&viid=85321286829&platform=p&locale=ko_KR
ì¿ íŒ¡ - ì˜¤ëšœê¸° ì œíœ´..
  https://shop.coupang.com/ottogi?source=brandstore_sdp_atf_topbadge&pid=1083072363&viid=86261967613&platform=p&locale=ko_KR
  https://www.coupang.com/vp/products/1083072363?itemId=2036340586&vendorItemId=86261967613&pickType=COU_PICK&q=%EB%BF%8C%EC%85%94%EB%BF%8C%EC%85%94&itemsCount=36&searchId=9d58e51ff00e41eeaaf4087563489045&rank=0&isAddedCart=




This container can be used to run an application or to separate tools, libraries, or runtimes needed for working with a codebase.
?? ë¼ì´ë¸ŒëŸ¬ë¦¬..?ì–´ë–»ê²Œ?

Workspace files are mounted from the local file system or copied or cloned into the container
??copy clone ì°¨ì´

settings, tools, and configurations  ì°¨ì´

Other glibc based Linux containers ??

ã…¡ã…¡ working with git?

Picking your quick start
???

Human Activity Recognition

>>>>>>>>>>>>> TODO: VSCode crawling




Forwarded Ports view.

ğŸ§® %vscode>Remote-SSH: Connect to Host...ë‘ë°
  ëª…ë ¹ì–´ ì•„ì´ì½˜. :abacus:
  ğŸ“„ ~/.vscode-server/data/Machine
    íŒŒì¼ ì•„ì´ì½˜ :paper
  ğŸ“ íŒŒì¼ í´ë” ì•„ì´ì½˜. :file_folder

ğŸ“ ë©´ì ‘ ìƒë‹´ ğŸ“… 2024-10-16 14:53:59
  ë©´ì ‘ê´€ì´ ê´€ì‹¬ ìˆëŠ” ê²ƒì„ ëˆˆì¹˜ìˆê²Œ.. ê·¸ ê²ƒì„ ì–˜ê¸°í•´ë´ì•¼ í•œë‹¤.
    ê·¸ê²ƒì„ í•´ë³´ì•˜ê¸° ë•Œë¬¸ì—, ~ë¥¼ í•  ì¤„ í•œë‹¤. ~ì— ê¸°ì—¬í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤. ì ìš©í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤.
  ì˜ˆë¥¼ë“¤ì–´ ê³µì • ë¶ˆëŸ‰ë¥ ..
    ê·¸ë˜ì„œ ë”¥ëŸ¬ë‹ ì´ëŸ°ê²ƒì„ í•´ë³´ì•˜ë‹¤.
  

  ì½”ë± ì•Œê³ ë¦¬ì¦˜ ê°œë°œí•˜ëŠ” ê³³ì—ì„œ ROS ..ì´ëŸ° ê±¸ ê°•ì¡°í•´ë´¤ì ì˜ë¯¸ ì—†ë‹¤.
  ìê¸°ì†Œê°œì„œë¥¼ ë˜‘ê°™ì€ê²ƒì„ ì ˆëŒ€ ì“°ë©´ ì•ˆë ë“¯ í•œë‹¤.
  ë§ë¡œ í’€ì§€ ë§ê³  ê·¸ë¦¼ì´ë‚˜ í¬íŠ¸í´ë¦¬ì˜¤ë¡œ .. ì´í•´í•  ìˆ˜ ìˆê²Œ. ì˜ìƒ. ë“±ë“±ìœ¼ë¡œ.

  ì»´í“¨í„°ê°€ ëŠë ¤ì„œ ì§€ì†ì ìœ¼ë¡œ í´ë ˆì„ì„ í–ˆì§€ë§Œ ë°›ì•„ë“¤ì—¬ì§€ì§€ ì•Šì•„ì„œ ë‚˜ì™”ì§€ë§Œ, ë©´ì ‘ê´€ì€ ê´€ì‹¬ì´ ì—†ë‹¤. ê´€ì‹¬ì„ ê°€ì ¸ì•¼ í•  ì´ìœ ë„ ì—†ê³ . ìˆ˜ìŠµê¸°ê°„ì€ ì“°ì§€ë„ ì•Šë„ë¡ í•œë‹¤.
  ê·¸ëƒ¥ ë‹¹ì‹œ AI ê°€ ëœ¨ê³  ìˆì—ˆê³  ì›¹ ì „ë§ì— ëŒ€í•´ .. ì–´ì©Œêµ¬..
  ê·¸ë˜ì„œ ë‚˜ì™€ì„œ í† ì´ í”„ë¡œì íŠ¸ë¥¼ í•˜ë©´ì„œ 
  ..ê±´ì„¤ í˜„ì¥...  ë§Œì•½ ë‹¤ì‹œ ëŒì•„ê°„ë‹¤ë©´ ê·¸ëŸ¬ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤. 
  
  ì´í›„ ê·¸ëŸ¬í•œ ê°œë°œ í™˜ê²½ì— ë”°ë¼, ì›ê²© ê°œë°œ í™˜ê²½ì— ëŒ€í•´ì„œë„ ëª¨ìƒ‰í–ˆê³ , tailscale.. ì–´ì©Œêµ¬.. remote-ssh, x11 idsplay ì„¤ì •.. 

  --- ì¤‘ìš”í•œ ê²ƒ
    í˜„ì—…ì„ í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ì—ˆëŠëƒ
    êµ¬ì¡°í™”
    !!! ì¬í˜„ì„±. reproducible
ğŸ“ ë©´ì ‘..
  LLM training.. ê²½í—˜.. sepc..
  bragging..
ì—¬í–‰ê³„íš ì°¸ê³ : ì¼ë³¸, ì˜¤ì‚¬ì¹´, ìœ í‹°ë²„ì…œ ìŠ¤íŠœë””ì˜¤, êµí† 
  ì•„ë´ì‚¬ë§ˆ ì¤‘ë¦¼? êµí† .. 
  ìœ ë‹ˆë²„ì…œ ìŠ¤íŠœë””ì˜¤ ì¬íŒ¬(USJ)
  í˜„ê¸ˆ ëŒ€ì²´ìˆ˜ë‹¨ êµ¬ë¹„
  ìˆ™ì†ŒëŠ” ì›¬ë§Œí•˜ë©´ í•œêµ°ëŒ€.. ìµœëŒ€ ë‘êµ°ëŒ€ê°€ ë‚˜ìŒ ë‹¨ê¸° ìŠë ì—ì„œëŠ”

  ë„ì¿„ ì‹œì¦ˆì˜¤ì¹´, ë„ì¿„. ì‡¼í•‘ê³¼ ë•ì§ˆ. 

  >>> ğŸ‘ ë°œí‘œí•  ë•Œ ì‹œì„  ì²˜ë¦¬
    ê°€ë§Œíˆ ì„œì„œ ppt ë¥¼ ê°€ë¦¬í‚¤ëŠ”ê±°ë³´ë‹¤ ì›€ì§ì´ë©´ì„œ í•˜ëŠ” ê²ƒì´ ë” ë‚«ë‹¤.
    ëˆˆì¹˜ì»· ë‚˜í•œí…Œ ìš°í˜¸ì ì¸ ì‚¬ëŒì—ê²Œ ì‹œì„ ì²˜ë¦¬.
  ğŸ“ ì§€ì›ë™ê¸°ë³´ë‹¤ëŠ”, ì´ì‚¬ëŒì´ íšŒì‚¬ì— ë¬´ì—‡ì„ ê¸°ì—¬í• ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì¨ì•¼ í•œë‹¤. ì‚¬ìš©í•œ ê¸°ìˆ  ì„¸íŠ¸ ë§ê³ .
    ì“¸ê±°ë©´ ì •í™•íˆ ì–´ëŠ ë ˆë²¨ë¡œ í•˜ëŠ”ì§€ ëª…ì‹œí•´ì¤˜ì•¼ í•œë‹¤.
ğŸ“ presentation skills for persuasive vs informative vs ...
ğŸ“ ì§ ì¼ˆëŸ¬. ìµœê³ ì˜ ë°˜ë„ì²´ ì•„í‚¤í…ì²˜ ì„¤ê³„ì
  risk b
  ì  ìŠ¨ í™©
  ìƒ˜ ì˜¬íŠ¸ë§Œ OpenAI CEO
  ë…¼ë¬¸ ë””íœìŠ¤.
ì‚¼ì„±...
  HBM ë¬¸ì œ..
  íŒŒì´ë‚¸ìŠ¤ê°€ ì‚¼ì„±ì„ ë¨¹ì–´ë²„ë ¤ì„œ.. ... ê°œë°œìë“¤ì´ ì˜ ì•ˆëœë‹¤ê³  í•œë‹¤.
  HBM ì— íˆ¬ìê°€ ë§¤ì¶œì´ DRAM ì—ì„œ ì¼ì–´ë‚˜ëŠ” êµ¬ì¡°ì  ë¬¸ì œ + ì‚¼ì„±ì˜ êµ¬ì¡°ì  ë¬¸í™”
  ê·¸ë˜ì„œ ë‚´ ~ê²ƒì„ ë°”íƒ•ìœ¼ë¡œ HBM í”„ë¡œì íŠ¸ì— ê°€ì†.. 
  ë¬¸ì œê°€ ìƒê¸°ë©´ ëê¹Œì§€ ì¡°ì‚¬í•´ì„œ í•´ê²°í•˜ë ¤ í•˜ê³ , ì œì•ˆí•˜ëŠ” ê·¸ëŸ° ëª¨ìŠµì„ ë³´ì—¬ì£¼ê²Ÿë‹¤.

  ğŸ“„ CVPR : CVì—ì„  ìµœê³ ì˜ ì»¨í¼ëŸ°ìŠ¤. ã…‡
  ğŸ“„ CGRAB
ì—­ê¸°êµ¬í•™ ì „ê¸°êµ¬í•™?
ğŸ‘ Canva ë³´ë‹¤ëŠ” Gamma. 
ê³µê¸‰í”¼ë”

ë©´ì ‘: forward" or "publish" 
  https://code.visualstudio.com/docs/devcontainers/containers#_forwarding-or-publishing-a-port
    - Neither specify EXPOSE nor -p
    - Only specify EXPOSE
    - Specify EXPOSE and -p
    - Only specify -p which implicitly does EXPOSE
ë©´ì ‘: ëª¨ë“ˆ vs íŒ¨í‚¤ì§€
  ?
AllowStreamLocalForwarding ; https://man7.org/linux/man-pages/man5/sshd_config.5.html
  âš–ï¸ The available options are yes (the default)
ğŸ‘ man page
  man(1)
    âš“ groups ; https://man7.org/linux/man-pages/man1/groups.1.html
    âš“ğŸš£ getent ; https://man7.org/linux/man-pages/man1/getent.1.html
      get entries from Name Service Switch libraries
      # group
        

  GNU Coreutils ; https://www.gnu.org/software/coreutils/manual/coreutils.html#groups-invocation
    20 User information
      20.1 id: Print user identity
      20.2 logname: Print current login name
      20.3 whoami: Print effective user name
      20.4 groups: Print group names a user is in

      20.5 users: Print login names of users currently logged in
      20.6 who: Print who is currently logged in
      20.7 pinky: Print information about users

>> "í˜¸ìŠ¤íŠ¸"ëŠ” ë„¤íŠ¸ì›Œí¬ì—ì„œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ì£¼ì²´. ssh host ë©´ ì„œë²„.

ì´ í™”ë©´ì€ ì„ íƒì ìœ¼ë¡œ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” íŒŒì¼ì´ë‚˜ ë””ë ‰í„°ë¦¬ë¥¼ ë¬»ëŠ” ì˜µì…˜ ì°½ì…ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ ë³´ì—¬ì§€ëŠ” íŒŒì¼ì€ .github/dependabot.ymlì…ë‹ˆë‹¤.

dependabot.yml íŒŒì¼ì€ GitHubì˜ Dependabotì„ ì„¤ì •í•˜ëŠ” íŒŒì¼ì…ë‹ˆë‹¤. Dependabotì€ í”„ë¡œì íŠ¸ì˜ ì˜ì¡´ì„±(dependency) ì—…ë°ì´íŠ¸ë¥¼ ìë™ìœ¼ë¡œ í™•ì¸í•˜ê³ , ìƒˆ ë²„ì „ì´ ìˆì„ ë•Œ PR(Pull Request)ì„ ìƒì„±í•´ì£¼ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì£¼ë¡œ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë‚˜ íŒ¨í‚¤ì§€ë“¤ì´ ìµœì‹  ìƒíƒœë¡œ ìœ ì§€ë˜ë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.

Optional Files/Directories - .github/dependabot.yml
poetry3-poetry-pyenv
âš“ opt out ; https://en.wiktionary.org/wiki/opt_out

v4l2-ctl --list-formats-ext
v4l2-ctl -d /dev/video0 --all
v4l2-ctl -d /dev/video1 --all # metadata ê°€ í¬í•¨ë˜ì–´ìˆìŒ.? ì¹´ë©”ë¼ë§ˆë‹¤ ë‹¤ë¥¸ë“¯?
USB Webcam Appears as 2 Devices  ë¬¸ì œ..
  ì›¹ìº ì´ ë‘ ê°œì˜ ìŠ¤íŠ¸ë¦¼(ì˜ˆ: ì¼ë°˜ ì˜ìƒ + ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ë˜ëŠ” ë‘ ê°€ì§€ í•´ìƒë„ ì˜µì…˜)ìœ¼ë¡œ ì¸ì‹ë  ë•Œ ë°œìƒ

xhost +local:docker
â“ https://huggingface.co/



Devcontainer... 
Step 11/33 : RUN echo "done 0"     && curl https://pyenv.run | bash     && echo "done 1"     && pyenv install ${PYTHON_VERSION}     && echo "done 2"     && pyenv global ${PYTHON_VERSION}     && echo "done 3"     && curl -sSL https://install.python-poetry.org | python3 -     && poetry config virtualenvs.in-project true
 ---> Running in fbeaa359e5e4
unable to find user vscode: no matching entries in passwd file
[2024-10-17T04:31:47.237Z] unable to find user vscode: no matching entries in passwd file
Most NVIDIA Jetson containers run with root privileges by default. If you require non-root users (like vscode), youâ€™ll need to create and configure them manually.

echo $XDG_SESSION_TYPE

https://www.canva.com/

lsusb -v -d 0bda:5411

ğŸ’¡ torch.Tensor**ëŠ” PyTorchì˜ ë°ì´í„° êµ¬ì¡°ì´ë©°, NumPy ë°°ì—´ê³¼ëŠ” ë‹¤ë¥¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

https://code.visualstudio.com/docs/python/linting
  Linter.. https://marketplace.visualstudio.com/items?itemName=ms-python.mypy-type-checker
  prototype ì—” ã…“ã…ê¸°?


Canva ê¸°ì´ˆë°°ìš°ê¸°:
  ğŸ–‡ï¸ ê¸°ì´ˆ ë°°ìš°ê¸° ; https://www.canva.com/design/DAGT4a4Zfxo/pUXsYyUcLJQRvpweu6g0Lw/edit ğŸ“… 2024-10-18 13:12:41
  ğŸ–‡ï¸ í”„ë ˆì  í…Œì´ì…˜ ì œì‘ ; https://www.canva.com/design/DAGEJYzMKzk/qv9ABywF5dRLHDJXwO8zjA/remix?title=%ED%94%84%EB%A0%88%EC%A0%A0%ED%85%8C%EC%9D%B4%EC%85%98%20%EC%A0%9C%EC%9E%91 ğŸ“… 2024-10-18 13:12:41
  ì†Œì…œ ë¯¸ë””ì–´ í•™ìŠµ ; https://www.canva.com/design/DAGT5HklhSQ/8QN3wb3AELtc84k40Gq2cw/edit

ì–‘ìì—­í•™ 7 - ì œ 5ì°¨ ì†”ë² ì´ íšŒì˜(ë¬¼ë¦¬í•™ í•™íšŒ)

PPT ê°„ë‹¨ ìš”ì•½
  https://www.canva.com/design/DAGT5Pjd7-s/8_vLHAy9aLdXRKOpcEX3OA/edit


ì¸µê°„ì†ŒìŒ -> ì´ì›ƒì‚¬ì´ì„¼í„°
  https://www.noiseinfo.or.kr/floorinfo/consultrequest.do
  ê³µë™ì£¼íƒ: ì¸µê°„ì†ŒìŒê´€ë¤¼ì›íšŒ êµ¬ì„± ì˜ë¬´í™” (2024.10.25)

  

calibrationì€ ëª¨ë¸ì˜ output predictionì´ ì‹¤ì œ í™•ë¥ ê°’ê³¼ ì¼ì¹˜í•˜ë„ë¡ êµì •í•˜ëŠ” ì‘ì—…ì„
There are two main uses of the term calibration in statistics that denote special types of statistical inference problems. Calibration can mean
âš“ğŸª± Calibration (statistics) ; https://en.wikipedia.org/wiki/Calibration_(statistics)
  a reverse process to regression, where instead of a future dependent variable being predicted from known explanatory variables, a known observation of the dependent variables is used to predict a corresponding explanatory variable;[1


1. prctl(PR_SVE_GET_VL) ì˜¤ë¥˜ ì›ì¸
prctlì€ ë¦¬ëˆ…ìŠ¤ì—ì„œ í”„ë¡œì„¸ìŠ¤ì˜ ì†ì„±ì„ ì œì–´í•˜ëŠ” ì‹œìŠ¤í…œ í˜¸ì¶œì…ë‹ˆë‹¤.
ì´ ì˜¤ë¥˜ëŠ” PyTorchê°€ Jetson Nanoì™€ ê°™ì€ ARM ì‹œìŠ¤í…œì˜ CPUë¥¼ ê°ì§€í•˜ë ¤ê³  í•  ë•Œ ë°œìƒí•©ë‹ˆë‹¤.
**SVE(Scalable Vector Extension)**ëŠ” ARMì˜ íŠ¹ì • í™•ì¥ ê¸°ëŠ¥ì¸ë°, Jetson Nanoì—ì„œëŠ” ì´ ê¸°ëŠ¥ì´ ì§€ì›ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— prctl í˜¸ì¶œì— ì‹¤íŒ¨í•©ë‹ˆë‹¤.



# https://github.com/ultralytics/ultralytics/issues/2964

# PyTorch 2.x ë²„ì „ì€ CUDA 11.x ì´ìƒê³¼ í˜¸í™˜ ...
# PyPIì˜ ì˜¤ë˜ëœ ë²„ì „ ì œê³µ ì¤‘ë‹¨...: PyTorchì˜ ì´ì „ ë²„ì „ë“¤ì€ ë” ì´ìƒ PyPIì—ì„œ ì œê³µë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤...

in Jetson nano
  # already installed
  sudo apt-get install nvidia-container-runtime
  # already configured
  code /etc/docker/daemon.json
  {
      "runtimes": {
          "nvidia": {
              "path": "nvidia-container-runtime",
              "runtimeArgs": []
          }
      }
  }

  https://github.com/nvidia/nvidia-container-runtime#daemon-configuration-file
  https://stackoverflow.com/questions/59008295/add-nvidia-runtime-to-docker-runtimes

  runcì™€ NVIDIA ëŸ°íƒ€ì„ì˜ ì°¨ì´ ë° ê¸°ë³¸ ëŸ°íƒ€ì„ ì„¤ì • í•„ìš”ì„±
  1. runcë€ ë¬´ì—‡ì¸ê°€?
  **runc**ëŠ” Open Container Initiative (OCI) í‘œì¤€ì„ ë”°ë¥´ëŠ” ê°€ë²¼ìš´ ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ì…ë‹ˆë‹¤.
  runcëŠ” Docker ë° ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆ ì—”ì§„ì—ì„œ ì»¨í…Œì´ë„ˆì˜ ì‹¤ì œ ì‹¤í–‰ì„ ë‹´ë‹¹í•˜ëŠ” ëŸ°íƒ€ì„ìœ¼ë¡œ, ë¦¬ëˆ…ìŠ¤ ì»¨í…Œì´ë„ˆ(LXC) ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.
  ê¸°ë³¸ ëŸ°íƒ€ì„ìœ¼ë¡œ ì„¤ì •ëœ ê²½ìš°, GPUì™€ ê°™ì€ íŠ¹ìˆ˜ í•˜ë“œì›¨ì–´ì— ì ‘ê·¼í•  ê¸°ëŠ¥ì´ ì—†ê¸° ë•Œë¬¸ì— NVIDIA GPUì™€ ê´€ë ¨ëœ ê¸°ëŠ¥ì€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤â€‹
  NVIDIA


vscode@97eac1039b5e /w/signal-masters> sudo find /usr -name 'libnvidia-ml.so*' ! -path '*stubs*'
vscode@97eac1039b5e /w/signal-masters> 

https://python-poetry.org/docs/repositories/
  poetry source
  
  poetry source add --priority=explicit pytorch-cu102 https://download.pytorch.org/whl/cu102
  poetry add --source pytorch-cu102 torch==1.7.0+cu102 torchvision==0.8.1+cu102

https://pytorch.org/get-started/previous-versions/#v1121
  ğŸ”‘ version: ~CUDA 10.2
https://download.pytorch.org/whl/torch/
  ğŸ”‘ version: manylinux2014_aarch64
    torch-1.12.1-cp310-cp310-manylinux2014_aarch64.whl

    cu- ì ‘ë‘ì‚¬ê°€ ì—†ëŠ” PyTorch ë¹Œë“œëŠ” ì¼ë°˜ì ìœ¼ë¡œ CUDA ëŸ°íƒ€ì„ì„ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    Jetson Nanoì—ì„œëŠ” JetPack SDKê°€ ì´ë¯¸ ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ CUDA ëŸ°íƒ€ì„ì„ ì œê³µí•˜ë¯€ë¡œ, cu- ì ‘ë‘ì‚¬ê°€ ì—†ëŠ” PyTorch íŒ¨í‚¤ì§€ë„ GPU ê°€ì†ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ABI(ì´ì§„ ì¸í„°í˜ì´ìŠ¤)


ğŸ‘ https://forums.developer.nvidia.com/t/gpu-usage-info-nvidia-smi-is-not-there/76155
  Hi Markus, nvidia-smi isnâ€™t supported on Tegra-based platforms. Instead please try the tegrastats utility, you can launch it by running â€œsudo tegrastatsâ€ from the terminal.
  See here for the documentation on tegrastats tool: [url]Welcome â€” Jetson Linux<br/>Developer Guide 34.1 documentation 487
  jetson nano: >> %shell> tegratstats





libnvidia-ml.so.1ëŠ” NVIDIA Management Library (NVML)ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. NVMLì€ NVIDIA GPUì˜ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ì œì–´í•  ìˆ˜ ìˆëŠ” APIë¥¼ ì œê³µí•©ë‹ˆë‹¤. PyTorchì™€ ê°™ì€ GPU ê¸°ë°˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ GPU í”„ë¡œì„¸ìŠ¤ ì •ë³´ë¥¼ ì–»ê³ , ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê´€ë¦¬í•˜ëŠ” ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë³´ë©´, Docker ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ë°œìƒí•œ ë¬¸ì œì…ë‹ˆë‹¤.



ğŸš¨ https://forums.developer.nvidia.com/t/how-to-enable-cuda-with-pytorch-running-on-a-jetson-nano-2gb-device/282762
head -n 1 /etc/nv_tegra_release

###### https://qengineering.eu/install-pytorch-on-jetson-nano.html?ref=xaviergeerinck.com

https://developer.nvidia.com/embedded/learn/tutorials/jetson-container

Jetson Nanoì— ë§ëŠ” PyTorch ë²„ì „ê³¼ íœ  íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ Jetson Nanoì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” PyTorchì˜ ê°€ì¥ ìµœì‹  ë²„ì „ì€ 1.10.xì…ë‹ˆë‹¤.

pip list --not-required


docker run --runtime nvidia -it --rm --network=host jayfalls/l4t-20.04:full-cp311
python3 -c 'import torch; print(f"PyTorch version: {torch.__version__}"); print(f"CUDA available:  {torch.cuda.is_available()}"); print(f"cuDNN version:   {torch.backends.cudnn.version()}"); print(torch.__config__.show());'
Package             Version
------------------- --------------------
certifi             2019.11.28
chardet             3.0.4
cmake               3.29.6
dbus-python         1.2.16
idna                2.8
numpy               1.23.1
pillow              10.3.0
pip                 24.1
psutil              6.0.0
PyGObject           3.36.0
python-apt          2.0.1+ubuntu0.20.4.1
requests            2.22.0
requests-unixsocket 0.2.0
setuptools          45.2.0
six                 1.14.0
tensorrt            8.2.1.8
torch               1.13.0
torchvision         0.14.0a0+5ce4506
typing_extensions   4.12.2
urllib3             1.25.8
wheel               0.34.2


TODO ë‚¨ê¸°ê¸°.
  #ï¸âƒ£ğŸ“° Personalizing with dotfile repositories ; https://code.visualstudio.com/docs/devcontainers/containers#_personalizing-with-dotfile-repositories
  #ï¸âƒ£ğŸ“° Known limitations ; https://code.visualstudio.com/docs/devcontainers/containers#_known-limitations
ì¼ë‹¨ ì»¨í…Œì´ë„ˆ ì•ˆì˜ íŒŒì¼ ë³µì‚¬ ì•ˆë¨.
TODO: for prototype.. VSCode dev containers..  â¡ï¸ #ğŸ“ "Always installed" extensions
  TODO: vscode, ultralytics tos í¬ë¡¤ë§


>>> Container DISPLAY...  ; https://stackoverflow.com/a/75663407

ğŸš¨ During the Docker build process, some steps may default to the root user. This means certain parts of the installation try to access directories like / (root directory) or attempt to write logs there.


ğŸš¨ ì™œ xhost +local:ì´ SSH í„°ë¯¸ë„ì—ì„œ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•Šë‚˜?
  xhost ì„¤ì •ì€ X ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ ì‹œìŠ¤í…œì—ì„œ ì§ì ‘ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤. SSHë¥¼ í†µí•´ ì ‘ì†í•œ ì‹œìŠ¤í…œì€ X ì„œë²„ë¥¼ ì§ì ‘ ìš´ì˜í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ê¶Œí•œì„ ë³€ê²½í•˜ë ¤ê³  í•  ë•Œ ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.

âš“ pytorch ì •ì  ì–‘ìí™” ; https://pytorch.org/docs/stable/quantization.html#quantization-api-summary






https://github.com/dusty-nv/jetson-containers

https://hub.docker.com/r/dustynv/pytorch/tags
https://github.com/dusty-nv/jetson-containers/blob/master/packages/pytorch/Dockerfile

https://www.elinux.org/Jetson_Zoo
â­• Official ; https://github.com/dusty-nv/jetson-containers/tree/master
  docker run --runtime nvidia -it --rm --network=host dustynv/pytorch:1.10-r32.7.1
  %shell> python3 -c 'import torch; print(f"PyTorch version: {torch.__version__}"); print(f"CUDA available:  {torch.cuda.is_available()}"); print(f"cuDNN version:   {torch.backends.cudnn.version()}"); print(torch.__config__.show());'
    - CuDNN 8.2.1
    - Built with CuDNN 8.0

  docker run --runtime nvidia -it --rm --network=host nvcr.io/nvidia/l4t-pytorch:r32.7.1-pth1.10-py3
  docker run --runtime nvidia -it --rm --network=host jayfalls/l4t-20.04:full-cp311

in python 3.12
  (myenv) root@jsnano:~/test# python3 -c 'import torch; print(f"PyTorch version: {torch.__version__}"); print(f"CUDA available:  {torch.cuda.is_available()}"); print(f"cuDNN version:   {torch.backends.cudnn.version()}"); print(torch.__config__.show());'
  Error in cpuinfo: prctl(PR_SVE_GET_VL) failed
  /root/test/myenv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:295: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)
    cpu = _conversion_method_template(device=torch.device("cpu"))
  PyTorch version: 2.5.0
  CUDA available:  False
  cuDNN version:   None
  PyTorch built with:
    - GCC 10.2
    - C++ Version: 201703
    - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
    - OpenMP 201511 (a.k.a. OpenMP 4.5)
    - LAPACK is enabled (usually provided by MKL)
    - NNPACK is enabled
    - CPU capability usage: NO AVX
    - Build settings: BLAS_INFO=open, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/devtoolset-10/root/usr/bin/c++, CXX_FLAGS=-ffunction-sections -fdata-sections -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=open, TORCH_VERSION=2.5.0, USE_CUDA=OFF, USE_CUDNN=OFF, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 
      



root@jsnano:~/test# pyenv global 3.10
root@jsnano:~/test# python3 -m venv myenv
root@jsnano:~/test# source myenv/bin/activate
(myenv) root@jsnano:~/test# pip install https://download.pytorch.org/whl/torch-1.12.1-cp310-cp310-manylinux2014_aarch64.whl#sha256=4e1b9c14cf13fd2ab8d769529050629a0e68a6fc5cb8e84b4a3cc1dd8c4fe541
Collecting torch==1.12.1
  Downloading https://download.pytorch.org/whl/torch-1.12.1-cp310-cp310-manylinux2014_aarch64.whl (55.7 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 55.7/55.7 MB 736.2 kB/s eta 0:00:00
Collecting typing-extensions
  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Installing collected packages: typing-extensions, torch
Successfully installed torch-1.12.1 typing-extensions-4.12.2
WARNING: There was an error checking the latest version of pip.
(myenv) root@jsnano:~/test# python3 -c 'import torch; print(f"PyTorch version: {torch.__version__}"); print(f"CUDA available:  {torch.cuda.is_available()}"); print(f"cuDNN version:   {torch.backends.cudnn.version()}"); print(torch.__config__.show());'
PyTorch version: 1.12.1
CUDA available:  False
cuDNN version:   None
PyTorch built with:
  - GCC 10.2
  - C++ Version: 201402
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: NO AVX
  - Build settings: BLAS_INFO=open, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/devtoolset-10/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=open, TORCH_VERSION=1.12.1, USE_CUDA=OFF, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 



(myenv) root@jsnano:~/test# deactivate
root@jsnano:~/test# python3 -c 'import torch; print(f"PyTorch version: {torch.__version__}"); print(f"CUDA available:  {torch.cuda.is_available()}"); print(f"cuDNN version:   {torch.backends.cudnn.version()}"); print(torch.__config__.show());'^C
pyroot@jsnano:~/test# pyenv global system
root@jsnano:~/test# python3 --version
Python 3.6.9
root@jsnano:~/test# python3 -c 'import torch; print(f"PyTorch version: {torch.__version__}"); print(f"CUDA available:  {torch.cuda.is_available()}"); print(f"cuDNN version:   {torch.backends.cudnn.version()}"); print(torch.__config__.show());'
PyTorch version: 1.10.0
CUDA available:  True
cuDNN version:   8201
PyTorch built with:
  - GCC 7.5
  - C++ Version: 201402
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: NO AVX
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_53,code=sm_53;-gencode;arch=compute_62,code=sm_62;-gencode;arch=compute_72,code=sm_72
  - CuDNN 8.2.1
    - Built with CuDNN 8.0
  - Build settings: BLAS_INFO=open, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=8.0.0, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -DMISSING_ARM_VST1 -DMISSING_ARM_VLD1 -Wno-stringop-overflow, FORCE_FALLBACK_CUDA_MPI=1, LAPACK_INFO=open, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=ON, USE_NCCL=0, USE_NNPACK=ON, USE_OPENMP=ON, 


curl -s https://download.pytorch.org/whl/torch/ | grep 'torch-1.10' | grep 'aarch64' | grep 'cp37' | awk -F'"' '{print "https://download.pytorch.org" $2}'
curl -s https://download.pytorch.org/whl/torch/ | grep 'aarch64' | grep 'cp36' | awk -F'"' '{print "https://download.pytorch.org" $2}'



torch (1.10.0)
torchaudio (0.10.0+d2634d8)
torchvision (0.11.0a0+fa347eb)

(myenv) root@jsnano:~/test# pip install https://download.pytorch.org/whl/cpu/torch-1.10.2-cp36-cp36m-manylinux2014_aarch64.whl#sha256=935e5ac804c5093c79f23a7e6ca5b912c166071aa9d8b4a0a3d6a85126d6a47b
torch-1.10.2-cp36-cp36m-manylinux2014_aarch64.whl is not a supported wheel on this platform.






https://github.com/jayfalls/jetson_nano_ubuntu20_docker/tree/main



ğŸ–¨ï¸ ì¸ì²œê´€ë¦¬ì‹œì„¤ê´€ë¦¬ê³µë‹¨ / í¬ìŠ¤ì½” ICT ğŸ“… 2024-10-21 09:12:00
  ë‚´ë…„ 2ì›”ì— í•œ ë²ˆ ìˆìŒ.
  >>>>>>>
  êµëŒ€ê·¼ë¬´í•˜ë©´ 4300   ì•ˆí•˜ë©´ 4000

  ê¸°ìˆ ì ?

1ì‹œ ë°œí‘œ.



í•˜ë“œì›¨ì–´ ì•„í‚¤í…ì²˜
ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…ì²˜
  // ëª¨ë¸..
  ì‘ì—… íë¦„ë„
  



ì ¯ìŠ¨ ë‚˜ë…¸ìš© í”„ë¡œì íŠ¸ git í•˜ë‚˜ ë§Œë“¤ì–´ì„œ ì˜¬ë ¤ì•¼ê²ŸìŒ. ë³€ê²½ì‚¬í•­ í™•ì¸ì´ ë„ˆë¬´ ì–´ë ¤ì›Œì„œ.. ppt ì— ë§Œë“¤ README.md ì´ê±°ì— ëŒ€í•´ì„œë„ ë§Œë“¤ì–´ì•¼ í•˜ê³ .

ì§€ê¸ˆ í˜„ì¬ ê°€ìƒí™˜ê²½ ì‚¬ìš© ì•ˆí•˜ëŠ”ì¤‘ì¸ë° (ì–´ì°¨í”¼ ë²„ì „ë‚®ì•„ì„œ ê°€ìƒí™˜ê²½ ë§Œë“¤ë©´ torch +yolo ì„¤ì¹˜ ì–´ë ¤ì›€.. pip install ì— ëª©ë¡ ì—†ì–´ì„œ), ì´ ê²½ìš° ë‚´ íŒ¨í‚¤ì§€ ëª¨ë“ˆí™”í•˜ê³  ìˆëŠ”ë° ì´ê²Œ ìê¾¸ module not found ë– ì„œ ì´ê±°ë„ í•´ê²°í•´ì•¼í•¨.


Jetson nano yolo ì–‘ìí™” (ê¸ˆë°©í• ë“¯?) í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ê³  pyserial ë¡œ ì—°ë™í•˜ê¸°



docker run --runtime nvidia -it --rm --network=host ultralytics/ultralytics:latest-jetson-jetpack4
python3 -c 'import torch; print(f"PyTorch version: {torch.__version__}"); print(f"CUDA available:  {torch.cuda.is_available()}"); print(f"cuDNN version:   {torch.backends.cudnn.version()}"); print(torch.__config__.show());'

cuDNN version:   None

sudo apt update
sudo apt install libcudnn8 libcudnn8-dev


docker run --runtime nvidia \
  --gpus all \
  -e LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/lib/aarch64-linux-gnu \
  -it ultralytics/ultralytics:latest-jetson-jetpack4 /bin/bash


ì´ë¯¸ ì„¤ì¹˜ ì˜ ë˜ì–´ìˆì–´vscode@jsnano:/workspaces/signal-masters$ pip freeze --all | grep torch
torch @ https://github.com/ultralytics/assets/releases/download/v0.0.0/torch-1.11.0a0+gitbc2c6ed-cp38-cp38-linux_aarch64.whl#sha256=87c3b1fade566123ddb4e1aa3e7a4ad49a5f05c8324556b0d8b40896731bf4ae
torchvision @ https://github.com/ultralytics/assets/releases/download/v0.0.0/torchvision-0.12.0a0+9b5a3fe-cp38-cp38-linux_aarch64.whl#sha256=71fb38cc7c39e825119f23cd896877b883c5e9fb4a77ca3fabfb35912dd41c60

ChatGPTì˜ ë§:
ChatGPT
í˜„ì¬ PyTorchì™€ torchvisionì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ë§Œ, í•´ë‹¹ ë²„ì „ì—ì„œëŠ” cuDNNì„ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ì„¤ì •ëœ ìƒíƒœì…ë‹ˆë‹¤. ë¬¸ì œì˜ ì›ì¸ì€ PyTorchê°€ cuDNNì´ ë¹„í™œì„±í™”ëœ ìƒíƒœë¡œ ë¹Œë“œëœ ë²„ì „ì„ ì‚¬ìš©í•˜ê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ì•„ë˜ í•´ê²°ì±…ìœ¼ë¡œ ë¬¸ì œë¥¼ í™•ì¸í•˜ê³  í•´ê²°í•´ ë³´ì„¸ìš”.

1. PyTorch ë¹Œë“œ ë¬¸ì œ í™•ì¸
PyTorchê°€ cuDNNì„ ì¸ì‹í•˜ì§€ ëª»í•˜ëŠ” ì´ìœ ëŠ” í•´ë‹¹ ë²„ì „ì´ cuDNN ì§€ì› ì—†ì´ ë¹Œë“œëœ ë²„ì „ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. í˜„ì¬ ì„¤ì¹˜ëœ ë²„ì „ì´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

PyTorch: 1.11.0a0+gitbc2c6ed
Torchvision: 0.12.0a0+9b5a3fe
ì´ ë²„ì „ë“¤ì€ ultralyticsì—ì„œ ì œê³µëœ ì»¤ìŠ¤í…€ ë¹Œë“œì´ë©°, ì´ ë¹Œë“œì—ì„œ USE_CUDNN=OFFë¡œ ì„¤ì •ëœ ìƒíƒœì…ë‹ˆë‹¤. ë”°ë¼ì„œ cuDNNì´ í™œì„±í™”ë˜ì§€ ì•ŠëŠ” ê²ƒì…ë‹ˆë‹¤.



FROM nvcr.io/nvidia/l4t-base:r32.7.1 ì´ë¯¸ì§€ì—, python3.12 ê°€ìƒí™˜ê²½ì„ ì„¤ì¹˜í•´ì„œ import torch í›„ is_available() í•˜ëŠ” ê²½ìš°
  Error in cpuinfo: prctl(PR_SVE_GET_VL) failed
jetson




docker run --runtime nvidia -it --rm --network=host jayfalls/l4t-20.04:full-cp311

âœ…  model -> onnx ë³€í™˜ê¹Œì§€ëŠ” ì–´ëŠ í˜¸ìŠ¤íŠ¸ì—ì„œ í•´ë„ ìƒê´€ì—†ëŠ”ë°,tensorrt ë¡œ ë³€í™˜ë§Œ ì ¯ìŠ¨ ë‚˜ë…¸ì—ì„œ í•˜ë©´ë˜ëŠ”ê±°?
  sudo apt install python3-pip -y

git clone https://github.com/jayfalls/jetson_nano_ubuntu20_docker
cd jetson_nano_ubuntu20_docker/yolo
wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu102 --force-reinstall
pip3 install ultralytics
yolo export model=yolo11n-pose.pt format=onnx opset=13 simplifyxz

python3 -c 'import torch; print(f"PyTorch version: {torch.__version__}"); print(f"CUDA available:  {torch.cuda.is_available()}"); print(f"cuDNN version:   {torch.backends.cudnn.version()}"); print(torch.__config__.show());'
python3 -c 'import cv2; print(f"CUDA available: {cv2.cuda.getCudaEnabledDeviceCount() > 0}")'
>>>>>>>> ğŸ‘ True True for  sudo docker run --runtime nvidia -it --rm --network=host dustynv/l4t-ml:r32.7.1
  https://github.com/dusty-nv/jetson-containers/tree/master/packages/l4t/l4t-ml

from ultralytics import YOLO
from ultralytics.engine.results import Results
model = YOLO("yolo11n-pose.pt")  # Load pre-trained YOLO model
print(model.predict("https://ultralytics.com/images/bus.jpg"))
print(model.predict("https://ultralytics.com/images/bus.jpg"))
print(model.predict("https://ultralytics.com/images/bus.jpg"))
print(model.predict("https://ultralytics.com/images/bus.jpg"))
print(model.predict("https://ultralytics.com/images/bus.jpg"))
print(model.predict("https://ultralytics.com/images/bus.jpg"))
print(model.predict("https://ultralytics.com/images/bus.jpg"))
print(model.predict("https://ultralytics.com/images/bus.jpg"))
print(model.predict("https://ultralytics.com/images/bus.jpg"))
print(model.predict("https://ultralytics.com/images/bus.jpg"))
...

>>>>>>>> ğŸ‘  for
xhost +local:docker && sudo docker run \
--runtime nvidia \
-it --rm
--network host --ipc host 
--gpus all \
-e DISPLAY=$DISPLAY \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-v ~/.Xauthority:/root/.Xauthority \
ultralytics/ultralytics:latest-jetson-jetpack4



>>>> NVIDIA Machine Learning Containers for Jetson and JetPack ; https://github.com/dusty-nv/jetson-containers
docker pull dustynv/l4t-ml:r36.2.0

docker run --runtime nvidia -it --rm --network=host dustynv/pytorch:1.10-r32.7.1
https://hub.docker.com/r/dustynv/l4t-ml/tags
sudo docker run --runtime nvidia -it --rm --network=host dustynv/l4t-ml:r32.7.1


ğŸš¨ https://forums.developer.nvidia.com/t/unable-to-install-ultralytics-in-python3-6-in-jetpack4-6/275989/3
  https://github.com/ultralytics/yolov5/issues/11341
  python < 3.7 ...
https://pypi.org/project/pip-tools/


ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê³¼ì •
[10/21/2024-12:34:34] [TRT] [W] Skipping tactic 3 due to insuficient memory on requested size of 796 detected for tactic 4.
Try decreasing the workspace size with IBuilderConfig::setMaxWorkspaceSize().
[10/21/2024-12:34:35] [TRT] [W] Tactic Device request: 947MB Available: 472MB. Device memory is insufficient to use tactic.
[10/21/2024-12:34:35] [TRT] [W] Skipping tactic 3 due to insuficient memory on requested size of 947 detected for tactic 4.
Try decreasing the workspace size with IBuilderConfig::setMaxWorkspaceSize().
[10/21/2024-12:34:42] [TRT] [W] Tactic Device request: 531MB Available: 515MB. Device memory is insufficient to use tactic.
[10/21/2024-12:34:42] [TRT] [W] Skipping tactic 3 due to insuficient memory on requested size of 531 detected for tactic 4.
Try decreasing the workspace size with IBuilderConfig::setMaxWorkspaceSize().

jsnano@jsnano:~$ tegrastats 
RAM 1332/3956MB (lfb 24x4MB) SWAP 234/6074MB (cached 31MB) CPU [5%@710,5%@921,4%@921,2%@921] EMC_FREQ 0% GR3D_FREQ 0% PLL@27C CPU@28.5C PMIC@50C GPU@29.5C AO@33.5C thermal@29C
RAM 1332/3956MB (lfb 24x4MB) SWAP 234/6074MB (cached 31MB) CPU [4%@102,4%@102,5%@102,2%@102] EMC_FREQ 0% GR3D_FREQ 0% PLL@27C CPU@29C PMIC@50C GPU@29.5C AO@33.5C thermal@29C
RAM 1332/3956MB (lfb 24x4MB) SWAP 234/6074MB (cached 31MB) CPU [9%@204,4%@204,8%@204,4%@204] EMC_FREQ 0% GR3D_FREQ 0% PLL@27C CPU@28.5C PMIC@50C GPU@29.5C AO@33.5C thermal@29C
RAM 1333/3956MB (lfb 24x4MB) SWAP 234/6074MB (cached 31MB) CPU [13%@102,6%@102,15%@102,16%@102] EMC_FREQ 0% GR3D_FREQ 0% PLL@27C CPU@28.5C PMIC@50C GPU@29.5C AO@33.5C thermal@29C
^C
ğŸ…¾ï¸ jsnano@jsnano:~$ sudo docker run --runtime nvidia -it --rm --network=host --ipc=host --gpus all ultralytics/ultralytics:latest-jetson-jetpack4
[sudo] password for jsnano: 
root@jsnano:/ultralytics# 


Try 1
  >>>>>>> sudo docker run --runtime nvidia -it --rm --network=host --ipc=host --gpus all ultralytics/ultralytics:latest-jetson-jetpack4
  from ultralytics import YOLO
  model = YOLO("yolo11n-pose.pt")
  model.export(format="engine", int8=True)
  trt_model = YOLO("yolov11n-pose.engine")
  results = trt_model("https://ultralytics.com/images/bus.jpg")

  >> output 
  [10/21/2024-15:02:11] [TRT] [E] ModelImporter.cpp:779: ERROR: builtin_op_importers.cpp:3352 In function importRange:
  [8] Assertion failed: inputs.at(0).isInt32() && "For range operator with dynamic inputs, this version of TensorRT only supports INT32!"


ğŸ‘ Try 2
  >>>>>>> sudo docker run --runtime nvidia -it --rm --network=host --ipc=host --gpus all ultralytics/ultralytics:latest-jetson-jetpack4
from ultralytics import YOLO
model = YOLO("yolo11n-pose.pt")
model.export(format="engine", half=True)
trt_model = YOLO("yolov11n-pose.engine")
results = trt_model("https://ultralytics.com/images/bus.jpg")





ğŸ‘ Try 3
  >>>>>>> sudo docker run --runtime nvidia -it --rm --network=host --ipc=host --gpus all -v ~/repo/signal-masters:/workspace ultralytics/ultralytics:latest-jetson-jetpack4
  Run python3, and ctrl + c and ctrl + v

  from ultralytics import YOLO

  # Load a YOLOv8n PyTorch model
  model = YOLO("/workspace/best.pt")

  # Export the model
  model.export(format="engine", half=True)  # creates 'yolov8n.engine'

  # Load the exported TensorRT model
  trt_model = YOLO("/workspace/best.engine")

  # Run inference
  results = trt_model("https://ultralytics.com/images/bus.jpg")


Yolo NAS

class_labels = {
    0: "GO",
    1: "LEFT",
    2: "RIGHT",
    3: "STOP",
    4: "SLOW"
}

ğŸ‘ Try 4 with Fine Tuning
  >>>>>>> docker run --runtime nvidia -it --rm --network=host --ipc=host --gpus all \
-v ~/repo/signal-masters:/workspace ultralytics/ultralytics:latest-jetson-jetpack4 \
python3 -c "

from ultralytics import YOLO
model = YOLO('/workspace/best.pt')
model.names = {0: 'GO', 1: 'LEFT', 2: 'RIGHT', 3: 'STOP', 4: 'SLOW'}
model.export(format='engine', half=True)

trt_model = YOLO('/workspace/best.engine', task='pose')
trt_model.names = {0: 'GO', 1: 'LEFT', 2: 'RIGHT', 3: 'STOP', 4: 'SLOW'}
results = trt_model('https://ultralytics.com/images/bus.jpg')
results_origin = model('https://ultralytics.com/images/bus.jpg')
print(results)
print(results_origin)
"




ğŸ§® Snippet: container_host_file_transfer.sh
  #!/bin/bash

  # Define variables for container names, paths, and filenames
  CONTAINER_NAME="cranky_elgamal"  # Docker container name
  DOCKER_CONTAINER_PATH="/ultralytics"  # Path inside the Docker container
  LOCAL_REPO_PATH="$HOME/repo/signal-masters/ml/models/from_ultralytics_container"  # Local path for storing copied files
  ENGINE_FILENAME="yolo11n-pose.engine"  # Name of the engine model file
  ONNX_FILENAME="yolo11n-pose.onnx"  # Name of the ONNX model file

  # Define variables for remote server connection
  DESTINATION_USER="wbfw109v2"  # Username for the remote server
  DESTINATION_HOST="10.10.16.154"  # Remote server's IP address
  DESTINATION_PATH="/home/$DESTINATION_USER/repo/intel-edge-academy-6/prototypes/_initialization/devcontainers/jetson_nano-mount/signal-masters/ml/models/from_ultralytics_container"  # Remote destination path

  # Copy ONNX model from Docker container to the local directory with '_half' suffix
  docker cp "$CONTAINER_NAME:$DOCKER_CONTAINER_PATH/$ONNX_FILENAME" "$LOCAL_REPO_PATH/${ONNX_FILENAME%.*}_half.onnx"

  # Copy engine model from Docker container to the local directory with '_half' suffix
  docker cp "$CONTAINER_NAME:$DOCKER_CONTAINER_PATH/$ENGINE_FILENAME" "$LOCAL_REPO_PATH/${ENGINE_FILENAME%.*}_half.engine"

  # Transfer the local model files to the remote server using SCP
  scp -r $LOCAL_REPO_PATH/* "$DESTINATION_USER@$DESTINATION_HOST:$DESTINATION_PATH/"

scp -r ~/repo/signal-masters wbfw109v2@10.10.16.154:/home/wbfw109v2/repo/intel-edge-academy-6/prototypes/_initialization/devcontainers/jetson_nano-mount

ğŸ¥‡ scp -r ~/repo/signal-masters/* wbfw109v2@10.10.16.154:/home/wbfw109v2/repo/Signal-Project/jetson-nano-mount/
rsync --archive --verbose --update --delete --dirs --progress \
  --exclude='.git' \
  $(git -C ~/repo/signal-masters ls-files --others --ignored --exclude-standard | sed 's/^/--exclude=/') \
  ~/repo/signal-masters/ \
  wbfw109v2@10.10.14.19:/home/wbfw109v2/repo/Signal-Project/jetson-nano-mount/


ì ¯ìŠ¨ ë‚˜ë…¸ì— ì „ì›ì´ ë“¤ì–´ì˜¤ë©´, ì ¯ìŠ¨ ë‚˜ë…¸ì»¨í…Œì´ë„ˆì—ì„œ yolo ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¨ í›„ /dev/ttyACM0 serial ë¡œ í†µì‹ í•˜ë„ë¡ í–ˆëŠ”ë°, ì´ë¥¼ python3 run.py ë¥¼ ì‹¤í–‰í•˜ë„ë¡ í•˜ëŠ” ì„œë¹„ìŠ¤ë¡œ ë§Œë“¤ì–´ì„œ ì‚¬ìš©ì¤‘.
sen 
ê·¼ë° ACM0 ì™€ í†µì‹ ì´ ì•ˆë˜ëŠ”ê²ƒ? Python Serial 



docker exec -d -w /workspaces/signal-masters f4ce64f0a3af python3 run.py


rsync -av --exclude='.venv' ../cuda_test/ ./


ì‚¬ìš©í•œ ë³¼íŠ¸.
3.4v*3
3.7V, 4.44Wh
18650-2200mAh
YU10801-18001
Shenzhen Huayu New Energy Techonlogy Co.,LTD

# Copy ONNX model from Docker container to the local directory with '_half' suffix
docker cp "$CONTAINER_NAME:$DOCKER_CONTAINER_PATH/$ONNX_FILENAME" "$LOCAL_REPO_PATH/${ONNX_FILENAME%.*}_half.onnx"

# Copy engine model from Docker container to the local directory with '_half' suffix
docker cp "$CONTAINER_NAME:$DOCKER_CONTAINER_PATH/$ENGINE_FILENAME" "$LOCAL_REPO_PATH/${ENGINE_FILENAME%.*}_half.engine"

# Transfer the local model files to the remote server using SCP
scp -r $LOCAL_REPO_PATH/* "$DESTINATION_USER@$DESTINATION_HOST:$DESTINATION_PATH/"


**docker exec -d**ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ ê²½ìš° systemdëŠ” ì„œë¹„ìŠ¤ê°€ ì¦‰ì‹œ ì™„ë£Œë˜ì—ˆë‹¤ê³  ì¸ì‹í•©ë‹ˆë‹¤.

journalctl -u signal-masters.service -f



ì—¬ëŸ¬ ì‚¬ëŒì´ ê³µìš©ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ssh ë¡œ ì ‘ì†í•˜ëŠ” í™˜ê²½ì—ì„œ í”„ë¡œì íŠ¸ì— git ì„ ì¨ì•¼í•˜ëŠ”ë° ê³µìš©ìœ¼ë¡œ ê³„ì •ì„ ì“°ê¸°ëŠ” ì–´ë µì”ì•„?
ì¼íšŒì„±ìœ¼ë¡œ í˜„ì¬ í„°ë¯¸ë„ì— ëŒ€í•´ì„œë§Œ, í˜„ì¬ í”„ë¡œì íŠ¸ì— ëŒ€í•´ì„œë§Œ ê¶Œí•œì„ ì£¼ê±°ë‚˜ oauth ê°™ì€ ê²ƒì´ ìˆë‚˜? 


ìµœê·¼ Linux í™˜ê²½ì—ì„œ ê°€ì¥ ì£¼ëª©ë°›ëŠ” í´ë¦½ë³´ë“œ ë„êµ¬ ì¤‘ í•˜ë‚˜ëŠ” **wl-clipboard**ì…ë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” Wayland ê¸°ë°˜ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©ë˜ë©°, ëª…ë ¹ì¤„ì—ì„œ í´ë¦½ë³´ë“œ ë³µì‚¬ ë° ë¶™ì—¬ë„£ê¸°ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê°„ë‹¨í•œ ìœ í‹¸ë¦¬í‹°ì…ë‹ˆë‹¤. X11 í™˜ê²½ì—ì„œ ì£¼ë¡œ ì‚¬ìš©ëœ xclipê³¼ xselì´ Waylandì—ì„œ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•ŠëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ë©° ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤.
  wl-clipboard ì£¼ìš” ê¸°ëŠ¥:
  wl-copy: í…ìŠ¤íŠ¸ë‚˜ íŒŒì¼ì„ í´ë¦½ë³´ë“œì— ë³µì‚¬í•©ë‹ˆë‹¤.
  ì˜ˆ: echo "Hello World" | wl-copyëŠ” í…ìŠ¤íŠ¸ë¥¼ í´ë¦½ë³´ë“œì— ë³µì‚¬í•©ë‹ˆë‹¤.
  wl-paste: í´ë¦½ë³´ë“œì— ì €ì¥ëœ ë‚´ìš©ì„ í„°ë¯¸ë„ì— ì¶œë ¥í•˜ê±°ë‚˜ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
  ì˜ˆ: wl-paste > clipboard.txtëŠ” í´ë¦½ë³´ë“œ ë‚´ìš©ì„ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.
  ì´ ë„êµ¬ëŠ” Unix íŒŒì´í”„ì™€ íŒŒì¼ ê°„ì˜ ë°ì´í„° ì „ì†¡ì„ ìš©ì´í•˜ê²Œ í•˜ë©°, Wayland ì‹œìŠ¤í…œì˜ íŠ¹ì„±ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
  WaylandëŠ” X11ì„ ëŒ€ì²´í•˜ëŠ” ìµœì‹  ë””ìŠ¤í”Œë ˆì´ ì„œë²„ë¡œ ìë¦¬ ì¡ê³  ìˆìœ¼ë©°, wl-clipboardëŠ” ê·¸ í™˜ê²½ì— ë§ì¶˜ ê°€ë³ê³  ì§ê´€ì ì¸ ë„êµ¬ë¡œ í‰ê°€ë°›ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë³´ì•ˆê³¼ ì„±ëŠ¥ì„ ê°•í™”í•œ Waylandì—ì„œ wl-clipboardëŠ” í´ë¦½ë³´ë“œ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

  ë˜í•œ, wl-clipboardë¥¼ ë” í™•ì¥í•œ **wl-clipboard-manager**ë„ ì£¼ëª©ë°›ê³  ìˆëŠ”ë°, ì´ëŠ” ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°ì™€ SQLite ê¸°ë°˜ ë°ì´í„° ì €ì¥ì†Œë¥¼ í™œìš©í•´ ê³ ê¸‰ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ì™€ ê°™ì€ ë„êµ¬ë“¤ì€ í˜„ëŒ€ì ì¸ Linux ë°°í¬íŒì—ì„œ í¸ë¦¬í•œ ì‚¬ìš©ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.

  ì´ ë„êµ¬ë“¤ì€ Arch Linux ë“± ì£¼ìš” ë°°í¬íŒì—ì„œ ì‰½ê²Œ ì„¤ì¹˜í•  ìˆ˜ ìˆìœ¼ë©°, Waylandë¥¼ ê¸°ë³¸ ì§€ì›í•˜ëŠ” ì‹œìŠ¤í…œì—ì„œ ë§¤ìš° ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Waylandë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì´ì™€ ê°™ì€ ë„êµ¬ë¥¼ í†µí•´ X11ì—ì„œ ê²ªë˜ í˜¸í™˜ì„± ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


âœ… 
sudo apt update
sudo apt install wl-clipboard


set -x USER_EMAIL wbfw109v2@gmail.com
ssh-keygen -t rsa -b 4096 -C $USER_EMAIL

>>
Generating public/private rsa key pair.
Enter file in which to save the key (/home/wbfw109v2/.ssh/id_rsa): 
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /home/wbfw109v2/.ssh/id_rsa
Your public key has been saved in /home/wbfw109v2/.ssh/id_rsa.pub
The key fingerprint is:
SHA256:kAZVp9FN7399ZIoV87ew2Nwofaa5QM8et7T9wuwOn+A wbfw109v2@gmail.com
The key's randomart image is:
+---[RSA 4096]----+
|    ....o..o.    |
|     . . +. ..   |
|      + .     +  |
|     . .     . + |
|        S  . .o =|
|          . Bo==+|
|           ++%.B=|
|           .++%.*|
|            EB*++|
+----[SHA256]-----+


cat ~/.ssh/id_rsa.pub
# and copy and paste https://github.com/settings/keys
# >> ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQCpnZq5CnCdclRxcJUtkite3Av1Inpp1ibyiOK0P6ERonW2nTknD/lesW2nzSDFypxK3YDUg6YZaplgQvH/K0+DOFoh7rf8aoPJGXGqOjbp3o+bbXPqxg/MkZ1F29OA3t5Iu0vLE6l59r7OxBSnqyjnXW43oqNgau9HH0LhlM6gSCDjLLAZMPBdVXrriAzlLnwCrccy/sCAn/npeBBMHdGXOFWdVxZUhXl+rUoTwM91VyxrOx67giOMgq55nVksutUXgEdeQ2duO8EkuZAiSU0vSQT0US0NUsT6XN5D+lHJx/0EF9GCjIaHDIMehMh9tHxhlwMvJen4LB+JUEcY1Nob11h9/loHIFJvl1F9ja9I+UStQuCbfO3grHIJmDp29eW/Vd6gSW2IiC1MSCL2oU8dIUOmMjqHWdBcziYHUnKG9o5nTUvObPy7pFZOn8HXQLIdEF05RFZI3rVFgSohVKsh16BwwrmTOVWkHS9glOItDifkhx5rfb8Hkr0JVXyV4EQnhAVBfgwaaKukLYOQX9sfPLkZKA2voyHK6ve2eTTabtynkzLNcNefKaMKCbUGTc4Y8CZSUQSh8ECs7EBS6eIKvNcQCh1DO1DvcKtm+kVqLpngDYn1vzCeZkHV8B/7mbrAS3/QuJbgP5GwkuLDUi6W7bGFv0MhFDxYOzEXQpYkKQ== wbfw109v2@gmail.com


eval (ssh-agent -c)
# e.g. >> Agent pid 34890


ssh-add ~/.ssh/id_rsa
# e.g. >> Identity added: /home/wbfw109v2/.ssh/id_rsa (wbfw109v2@gmail.com)

echo "ë³µì‚¬í•œ ê³µê°œ í‚¤ ë‚´ìš©" >> ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys

ì„œë²„ì— ì„¤ì •





git config user.name "wbfw109v2"
git config user.email "wbfw109v2@gmail.com"

>>>>>>>>>>>ğŸ“°â“ ê° A, B, C (ê°ì ë‹¤ë¥¸ ë°ìŠ¤í¬íƒ‘ PCë¥¼ ê°€ì§€ê³  ìˆìŒ. ssh í´ë¼ì´ì–¸íŠ¸ì´ë‹¤.) ì—ì„œ D (SSH ì„œë²„) ë¡œ ì ‘ì†í•œë‹¤ê³  ê°€ì •. ğŸ“… 2024-10-23 06:19:56
  - A, B, C ëŠ” ssh í´ë¼ì´ì–¸íŠ¸ë¡œì„œ D ì— "ë™ì¼í•œ" jsnano ê³„ì •ìœ¼ë¡œ ì ‘ì†í•œë‹¤.
  - A, B, C ëŠ” Dì— ì ‘ì† í›„, D-C ì— "ë™ì¼í•œ" nano ê³„ì •ìœ¼ë¡œ ì ‘ì†í•œë‹¤.
  - A, B, C ëŠ” D-C ì— "ë™ì¼í•œ" ì‘ì—… ë””ë ‰í„°ë¦¬ì— ëŒ€í•´ ê° ë‹¤ë¥¸ git email, name ìœ¼ë¡œ ê´€ë¦¬ë¥¼ í•´ì•¼ í•œë‹¤.
  1ë²ˆ, 4ë²ˆì— ëŒ€í•´ ì“°ë ¤ê³  í•˜ëŠ”ë°,
  - A, B, C ëŠ” D-C ì— ì ‘ì†í•  ë•Œ docker exec ëª…ë ¹ì–´ê°€ ì•„ë‹ˆë¼ VSCode ì˜ dev container ê¸°ëŠ¥ì¸ Reopen in dev container ê¸°ëŠ¥ì„ ê°€ì§€ê³  ì»¨í…Œì´ë„ˆ ì•ˆì—ì„œ ì‘ì—…ì„ í•œë‹¤.
    devcontainer.json ì„¤ì •ì„ ì‚¬ìš©.
 ì–´ë–»ê²Œ í•´ì•¼í•´?

    >> ssh -t jsnano@D "export GIT_AUTHOR_NAME='User A'; export GIT_AUTHOR_EMAIL='userA@example.com'; docker exec -it D-c /bin/bash"

      #!/bin/bash ì— ì„¤ì •í•„ìš”..

      # SSH ì ‘ì† ì‹œ í™˜ê²½ë³€ìˆ˜ë¡œ ì „ë‹¬ëœ ì‚¬ìš©ì ì •ë³´ í™œìš©
      GIT_USER_NAME=${GIT_AUTHOR_NAME:-"Default User"}
      GIT_USER_EMAIL=${GIT_AUTHOR_EMAIL:-"default@example.com"}

      # Git ì„¤ì • ì„ì‹œ ì ìš©
      git config user.name "$GIT_USER_NAME"
      git config user.email "$GIT_USER_EMAIL"

      1-1. entrypoint.sh ì‘ì„±
        ì»¨í…Œì´ë„ˆ ë‚´ë¶€ /workspace/entrypoint.shì— ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•©ë‹ˆë‹¤:

        bash
        Copy code
        #!/bin/bash

        # ì‚¬ìš©ìì˜ Git ì •ë³´ ì„¤ì •
        git config --global user.name "${GIT_USER_NAME:-'Default User'}"
        git config --global user.email "${GIT_USER_EMAIL:-'default@example.com'}"

        # ì›ë˜ì˜ ì‰˜ì„ ì‹œì‘í•©ë‹ˆë‹¤ (VSCodeê°€ í•„ìš”ë¡œ í•˜ëŠ” bash ì„¸ì…˜ ìœ ì§€)
        exec "$@"


      2-1. devcontainer.json ìˆ˜ì •
        json
        Copy code
        {
          "name": "My Dev Container",
          "image": "ubuntu:latest",
          "remoteEnv": {
            "GIT_USER_NAME": "User A",
            "GIT_USER_EMAIL": "userA@example.com"
          },
          "overrideCommand": false,
          "initializeCommand": "/workspace/entrypoint.sh"
        }

        initializeCommand: ì»¨í…Œì´ë„ˆê°€ ì‹œì‘ë  ë•Œë§ˆë‹¤ entrypoint.shê°€ ì‹¤í–‰ë©ë‹ˆë‹¤.
        overrideCommand: ê¸°ë³¸ ëª…ë ¹ì„ ë®ì–´ì“°ì§€ ì•Šê³  ìœ ì§€í•©ë‹ˆë‹¤.

  ... ì¸ì¦ì€ ì–´ë–»ê²Œí•¨? config ëŠ” ë‹¬ë¦¬í•´ì„œ ë¡œê·¸ì¸í–ˆëŠ”ë°
    ê·¸ëƒ¥ push í•  ë–„ë§ˆë‹¤ ë§¤ë²ˆ oauth ìš”êµ¬í•˜ê²ŒëŠ” ëª»í•˜ë‚˜?

    git config --global --unset credential.helper
  GitHub OAuth ì¸ì¦ì„ ê°•ì œí•˜ê±°ë‚˜ ë§¤ë²ˆ ë¡œê·¸ì¸ì„ ìœ ë„í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì€ ìš°íšŒ ë°©ë²•ì„..?


  ì•„ë‹ˆë©´ commit ë§Œ í•˜ê³  í™•ì¥ í”„ë¡œê·¸ë¨ ì‚¬ìš©í•´ì„œ ê´€ë¦¬í•˜ê±°ë‚˜, 

Mediapipe -> 

ğŸ‘ ìì´ì–¸íŠ¸ ìŠ¤í…. ì¢‹ì€ ì¤‘ê²¬ê¸°ì—… ?

í•œêµ­ì—”ì§€ë‹ˆì–´ë§í˜‘íšŒ .. ë­í•˜ëŠ”ê³³?
  gksrnrwjdqhxhdtls

Joint, Velocity, Boneì˜ ì˜ë¯¸:
  Joint (ê´€ì ˆ ì •ë³´):

  ì¸ì²´ì˜ ì£¼ìš” ê´€ì ˆ(ì˜ˆ: ì–´ê¹¨, íŒ”ê¿ˆì¹˜, ë¬´ë¦ ë“±)ì˜ ì ˆëŒ€ì ì¸ ìœ„ì¹˜ ì¢Œí‘œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŠ” íŠ¹ì • ìˆœê°„ì˜ ì‹ ì²´ ìƒíƒœë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
  Velocity (ì†ë„ ì •ë³´):

  ê´€ì ˆì˜ ì‹œê°„ì— ë”°ë¥¸ ë³€í™”ëŸ‰ì„ ì¸¡ì •í•˜ë©°, ì›€ì§ì„ì˜ ì†ë„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
  ì´ëŠ” ë™ì‘ì˜ ë¹ ë¥´ê¸°ë‚˜ ê°€ì†ë„ë¥¼ í¬ì°©í•´ íŠ¹ì • í™œë™ì˜ ë‹¤ì´ë‚´ë¯¹ì„ êµ¬ë³„í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.
  Bone (ë¼ˆ ì •ë³´):

  ì¸ì ‘í•œ ë‘ ê´€ì ˆ ì‚¬ì´ì˜ ë²¡í„°ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì‹ ì²´ì˜ í¬ì¦ˆë‚˜ ê´€ì ˆ ê°„ ê´€ê³„ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
  ì´ëŠ” ì›€ì§ì„ì˜ êµ¬ì¡°ì  íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤

PoseC3DëŠ” 3D-CNN ê¸°ë°˜ìœ¼ë¡œ, ê¸°ì¡´ GCN ê¸°ë°˜ ì ‘ê·¼ê³¼ ë‹¬ë¦¬ ê·¸ë˜í”„ êµ¬ì¡° ëŒ€ì‹  3D íˆíŠ¸ë§µ ë³¼ë¥¨ì„ ì‚¬ìš©í•´ ìŠ¤ì¼ˆë ˆí†¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤â€‹
  - GCNê³¼ ì°¨ë³„í™”ëœ ì :
    - ë…¸ì´ì¦ˆ ê°•ì¸ì„±: í¬ì¦ˆ ì¶”ì • ì‹œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ì— ëœ ë¯¼ê°í•˜ë©°, ë‹¤ì¤‘ ì¸ë¬¼ ì¶”ì ì—ì„œë„ ì¶”ê°€ ë¹„ìš© ì—†ì´ ë™ì‘í•©ë‹ˆë‹¤.
    - í™•ì¥ì„±: RGB ë°ì´í„°ì™€ ì‰½ê²Œ í†µí•©í•  ìˆ˜ ìˆì–´ ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹° ê²°í•©ì— ìœ ë¦¬í•©ë‹ˆë‹¤.
    - ìŠ¤ì¼ˆë ˆí†¤ í–‰ë™ ì¸ì‹ì˜ íš¨ìœ¨ì„± ê°œì„ : ì‹œê°„ì , ê³µê°„ì  íŒ¨í„´ í•™ìŠµì— ìœ ë¦¬í•œ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤â€‹
  - í•œ ì¤„ ìš”ì•½:
    - PoseC3DëŠ” 3D-CNNì„ í™œìš©í•˜ì—¬ GCNì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ë” ë†’ì€ ì •í™•ë„ì™€ ìœ ì—°ì„±ì„ ì œê³µí•˜ëŠ” ìµœì‹  ìŠ¤ì¼ˆë ˆí†¤ í–‰ë™ ì¸ì‹ ëª¨ë¸ì…ë‹ˆë‹¤.


- X3DëŠ” ê²½ëŸ‰í™”ëœ 3D-CNN ì•„í‚¤í…ì²˜ë¡œ, ë™ì‘ ì¸ì‹ì—ì„œ ë†’ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ì œê³µí•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
  - ì±„ë„ ìˆ˜ì™€ ë„¤íŠ¸ì›Œí¬ ê¹Šì´ë¥¼ ìµœì†Œí™”í•˜ì—¬, FLOPs(ì—°ì‚°ëŸ‰)ê³¼ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ í¬ê²Œ ì¤„ì´ëŠ” ê²ƒì´ íŠ¹ì§•ì…ë‹ˆë‹¤.
  - ì´ëŸ¬í•œ íŠ¹ì„± ë•ë¶„ì—, ì„ë² ë””ë“œ ì‹œìŠ¤í…œê³¼ ê°™ì€ ì œí•œëœ ìì› í™˜ê²½ì—ì„œë„ ì‹¤ì‹œê°„ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
  - PoseC3Dì™€ ê°™ì€ ìŠ¤ì¼ˆë ˆí†¤ ê¸°ë°˜ ëª¨ë¸ì˜ ë°±ë³¸ìœ¼ë¡œ í™œìš©ë˜ì–´, ë™ì‘ ì¸ì‹ì˜ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤

3D-CNN(3D Convolutional Neural Network)ì€ ì‹œê°„ê³¼ ê³µê°„ ì¶•ì„ í•¨ê»˜ ì²˜ë¦¬í•˜ëŠ” í•©ì„±ê³± ê³„ì¸µì„ í†µí•´, ë™ì˜ìƒì´ë‚˜ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì‹œê°„ì  ë° ê³µê°„ì  íŒ¨í„´ì„ ë™ì‹œì— í•™ìŠµí•˜ëŠ” ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤.


>> ì „ì²´ íŒŒì´í”„ë¼ì¸ í•„ìš”í• ë“¯

ê³¨ê²© ê¸°ë°˜(Skeleton-based) ëª¨ë¸: ê´€ì ˆ í¬ì¸íŠ¸(keypoints) ë°ì´í„°ë¥¼ í™œìš©í•œ ì•¡ì…˜ ì¸ì‹ì— ìµœì í™”ë¨.
ê²½ëŸ‰í™”ëœ ì•„í‚¤í…ì²˜: X3D-s ë°±ë³¸ì€ ì´ 241K íŒŒë¼ë¯¸í„°ì™€ 0.6GFLOPsë§Œ ì‚¬ìš©í•˜ì—¬ ë†’ì€ íš¨ìœ¨ì„± ì œê³µ.
ë…¸ì´ì¦ˆ ê°•ì¸ì„±(Noise Robustness): ë‹¤ì–‘í•œ ìì„¸ ë³€í˜•ê³¼ ì™¸ë¶€ í™˜ê²½ ë…¸ì´ì¦ˆì—ë„ ì•ˆì •ì ì¸ ì„±ëŠ¥ ì œê³µ.
ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ì„±: FLOPsê°€ ë‚®ì•„ ì„ë² ë””ë“œ ì‹œìŠ¤í…œì´ë‚˜ ì œí•œëœ ìì›ì—ì„œì˜ ì‹¤ì‹œê°„ ì²˜ë¦¬ì— ìœ ë¦¬.
ì •í™•ë„: NTU60-XSub ë°ì´í„°ì…‹ì—ì„œ 92.3% ì •í™•ë„ë¥¼ ë‹¬ì„±, ìµœì ì˜ ê²½ëŸ‰ ëª¨ë¸ë¡œ ì¸ì •.
í™•ì¥ì„±: ë‹¤ë¥¸ X3D ë³€í˜•ë“¤ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ë” ê¹Šê³  ë„“ì€ ë„¤íŠ¸ì›Œí¬ë¡œ í™•ì¥ ê°€ëŠ¥í•˜ì§€ë§Œ, ì´ ê²½ìš° ì„±ëŠ¥ê³¼ ìì› ê°„ì˜ ê· í˜• ê³ ë ¤ í•„ìš”.


# PoseC3Dì™€ GCNì˜ ë¬¸ì œì  ë° í•´ê²° ë°©ì•ˆ ì •ë¦¬

## 1. GCN(Graph Convolutional Network)ì˜ ë¬¸ì œì 
GCN ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ìŠ¤ì¼ˆë ˆí†¤ ë°ì´í„°ë¥¼ ê·¸ë˜í”„ë¡œ ì²˜ë¦¬í•˜ë©° ì•¡ì…˜ ì¸ì‹ì„ ìˆ˜í–‰í•˜ì§€ë§Œ ì—¬ëŸ¬ ë‹¨ì ì´ ì¡´ì¬í•©ë‹ˆë‹¤:

- **í¬ì¦ˆ ì¶”ì • ëª¨ë¸ ì˜ì¡´ì„±**:  
  GCNì€ ê´€ì ˆ ë°ì´í„°ë¥¼ ê·¸ë˜í”„ ë…¸ë“œë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ, ì •í™•í•œ í¬ì¦ˆ ì¶”ì •ì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í¬ì¦ˆ ì¶”ì • ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ì‘ì€ ì˜¤ë¥˜ë‚˜ ë…¸ì´ì¦ˆì— ë§¤ìš° ë¯¼ê°í•´ ì¸ì‹ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **ì‹œê³µê°„ì  ì •ë³´ ì²˜ë¦¬ì˜ í•œê³„**:  
  GCNì€ ê·¸ë˜í”„ì˜ ê³µê°„ì  êµ¬ì¡°ì—ëŠ” ê°•í•˜ì§€ë§Œ ì‹œê°„ì  ë³€í™”(temporal dynamics)ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ë° ì œí•œì´ ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ë³µì¡í•œ ì›€ì§ì„ ì¸ì‹ì— ì–´ë ¤ì›€ì´ ìˆìŠµë‹ˆë‹¤.

- **ì—°ì‚° ë³µì¡ë„ì˜ ì„ í˜• ì¦ê°€**:  
  GCNì—ì„œëŠ” ìŠ¤ì¼ˆë ˆí†¤ì˜ ê° ê´€ì ˆì´ ë…¸ë“œë¡œ í‘œí˜„ë˜ë©°, ê´€ì ˆì˜ ìˆ˜ì™€ í”„ë ˆì„ì´ ì¦ê°€í•¨ì— ë”°ë¼ ì—°ì‚° ë³µì¡ë„ê°€ ì„ í˜•ì ìœ¼ë¡œ ëŠ˜ì–´ë‚©ë‹ˆë‹¤. ì´ëŠ” íŠ¹íˆ ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œìŠ¤í…œì—ì„œ ì„±ëŠ¥ ì €í•˜ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **í™•ì¥ì„± ë¬¸ì œ**:  
  GCN ê¸°ë°˜ ëª¨ë¸ì€ ì£¼ë¡œ ìŠ¤ì¼ˆë ˆí†¤ ë°ì´í„°ì— ìµœì í™”ë˜ì–´ ìˆì–´, RGBì™€ ê°™ì€ ë‹¤ì¤‘ ëª¨ë‹¬ë¦¬í‹° ë°ì´í„°ë¥¼ í•¨ê»˜ ì²˜ë¦¬í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.

## 2. PoseC3Dì™€ X3D ë°±ë³¸ì˜ í•´ê²° ë°©ì•ˆ
PoseC3DëŠ” ìœ„ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **3D-CNN** ê¸°ë°˜ì˜ ì ‘ê·¼ì„ ë„ì…í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ **3D ì—´ ì§€ë„(heatmap volume)**ë¡œ ìŠ¤ì¼ˆë ˆí†¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•´ ë³´ë‹¤ ê°•ì¸í•œ ì‹œê³µê°„ ì •ë³´ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤:

- **ë…¸ì´ì¦ˆ ê°•ì¸ì„±(Noise Robustness)**:  
  3D-CNNì€ í¬ì¦ˆ ì¶”ì • ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ì‘ì€ ì˜¤ë¥˜ì— ë” ê°•í•˜ë©°, ìŠ¤ì¼ˆë ˆí†¤ ì‹œí€€ìŠ¤ì˜ ì‹œê³µê°„ì  ë³€í™”ë¥¼ ì˜ í¬ì°©í•©ë‹ˆë‹¤.

- **íš¨ìœ¨ì ì¸ ì—°ì‚° ë° ê²½ëŸ‰í™”**:  
  X3Dì™€ ê°™ì€ ë°±ë³¸ì„ ì‚¬ìš©í•´ ê²½ëŸ‰í™”ëœ ë„¤íŠ¸ì›Œí¬ë¡œ ì„¤ê³„ë˜ì–´, 241K íŒŒë¼ë¯¸í„°ì™€ 0.6GFLOPsë¡œ ì‹¤ì‹œê°„ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ëŠ” Jetson Nanoì™€ ê°™ì€ ì„ë² ë””ë“œ ì‹œìŠ¤í…œì—ì„œë„ ë†’ì€ íš¨ìœ¨ì„ ì œê³µí•©ë‹ˆë‹¤.

- **ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ì™€ì˜ í˜¸í™˜ì„±**:  
  PoseC3DëŠ” ìŠ¤ì¼ˆë ˆí†¤ë¿ ì•„ë‹ˆë¼ RGB ë°ì´í„°ì™€ì˜ ê²°í•©ë„ ê°€ëŠ¥í•˜ì—¬ í™•ì¥ì„±ê³¼ ìœ ì—°ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.

## 3. ê²°ë¡ 
PoseC3DëŠ” GCNì˜ ë‹¨ì ì„ í•´ê²°í•˜ë©´ì„œë„ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•œ ëª¨ë¸ë¡œ, **ì„ë² ë””ë“œ ì‹œìŠ¤í…œ ë° ì‹¤ì‹œê°„ ì•¡ì…˜ ì¸ì‹**ì— ì í•©í•œ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. X3D ë°±ë³¸ì„ í™œìš©í•œ ê°€ë²¼ìš´ ì„¤ê³„ëŠ” ì—°ì‚° ìì›ì„ ì¤„ì´ë©´ì„œë„ ë†’ì€ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ íŠ¹íˆ **êµí†µ ì‹ í˜¸ ì¸ì‹**ê³¼ ê°™ì€ ì •í™•í•œ ë™ì‘ ì¸ì‹ì´ í•„ìš”í•œ ì‘ìš©ì— ìœ ë¦¬í•©ë‹ˆë‹¤.

ë” ê¹Šì´ ìˆëŠ” ë‚´ìš©ì€ ë…¼ë¬¸ì˜ [ì›ë¬¸](https://arxiv.org/pdf/2104.13586)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

5ê°œ í¬ì¦ˆ
17


>> preprocess ì–´ë–»ê²Œ ê°œì„ í• ê²ƒì´ëƒ.
  threading - 
  FlowChart ê°œì„ 



ì–‘ìí™” INT8


10ì›” 23 09:39:14 jsnano docker[6285]: Traceback (most recent call last):
10ì›” 23 09:39:14 jsnano docker[6285]:   File "run.py", line 58, in <module>
10ì›” 23 09:39:14 jsnano docker[6285]:     results = model(source=frame, save=False)
10ì›” 23 09:39:14 jsnano docker[6285]:   File "/ultralytics/ultralytics/engine/model.py", line 176, in __call__
10ì›” 23 09:39:14 jsnano docker[6285]:     return self.predict(source, stream, **kwargs)
10ì›” 23 09:39:14 jsnano docker[6285]:   File "/ultralytics/ultralytics/engine/model.py", line 554, in predict
10ì›” 23 09:39:14 jsnano docker[6285]:     return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)
10ì›” 23 09:39:14 jsnano docker[6285]:   File "/ultralytics/ultralytics/engine/predictor.py", line 168, in __call__
10ì›” 23 09:39:14 jsnano docker[6285]:     return list(self.stream_inference(source, model, *args, **kwargs))  # merge list of Result into one
10ì›” 23 09:39:14 jsnano docker[6285]:   File "/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py", line 43, in generator_context
10ì›” 23 09:39:14 jsnano docker[6285]:     response = gen.send(None)
10ì›” 23 09:39:14 jsnano docker[6285]:   File "/ultralytics/ultralytics/engine/predictor.py", line 274, in stream_inference
10ì›” 23 09:39:14 jsnano docker[6285]:     s[i] += self.write_results(i, Path(paths[i]), im, s)
10ì›” 23 09:39:14 jsnano docker[6285]:   File "/ultralytics/ultralytics/engine/predictor.py", line 334, in write_results
10ì›” 23 09:39:14 jsnano docker[6285]:     string += f"{result.verbose()}{result.speed['inference']:.1f}ms"
10ì›” 23 09:39:14 jsnano docker[6285]:   File "/ultralytics/ultralytics/engine/results.py", line 663, in verbose
10ì›” 23 09:39:14 jsnano docker[6285]:     log_string += f"{n} {self.names[int(c)]}{'s' * (n > 1)}, "
10ì›” 23 09:39:14 jsnano docker[6285]: KeyError: 8


ê°€ìƒí™˜ê²½ 
  [10/21/2024-15:02:11] [TRT] [E] ModelImporter.cpp:779: ERROR: builtin_op_importers.cpp:3352 In function importRange:
  [8] Assertion failed: inputs.at(0).isInt32() && "For range operator with dynamic inputs, this version of TensorRT only supports INT32!"
  


WIKFI MODULE: NodeMCU
  price is ow
ê³µìœ ê¸° enba

AP(Application Processor)
íœ´ëŒ€í° ìŠ¤í…Œì´ì…˜ ëª¨ë“œ?
VNC ?



sudo apt -y install flatpak 
sudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo




https://www.ros.org/reps/rep-2000.html#jazzy-jalisco-may-2024-may-2029
 d

ğŸ†š 
  Flatpak	Snap	APT/RPM
  ë°°í¬íŒ í˜¸í™˜ì„±	ëª¨ë“  ë¦¬ëˆ…ìŠ¤ ë°°í¬íŒ ì§€ì›	Ubuntu ì¤‘ì‹¬, ë‹¤ë¥¸ ë°°í¬íŒë„ ì§€ì›

  sudo apt -y install flatpak 

  flatpak install flathub com.usebottles.bottles
  flatpak run com.usebottles.bottles

find ~/.var/app/com.usebottles.bottles/ -type f -iname "*kakaotalk*"


VMWare network bridge settings? 

CMOS ì„¸íŒ…?
sudo apt -y install icoutils
wrestool -x -t3 -n1 --raw KakaoTalk_Setup.exe --output=/path/to/KakaoTalk.png

ë‚´ê°€ ê°€ìƒ í™˜ê²½ window IP:
  10.10.14.179/19ë²ˆ
  linux ~ 21 ë²ˆ~ 39ë²ˆ

netwmark, gateway ëŠ” ë™ì¼í•˜ê²Œ í•˜ê¸°.
nameserver ëŠ” ìœˆë„ìš°ì™€ ë™ì¼í•˜ê²Œ
10.10.10.254 gateway


sudo halt -p ??

>>>
  flatpak install flathub com.usebottles.bottles
  flatpak run com.usebottles.bottles

  - Create a new Bottle
    Bottle type: Application



# https://ubuntu.com/server/docs/openssh-server
sudo apt install openssh-server -y

# lscpu | grep Virtualization
qemu-system-x86_64 -boot d -cdrom ubuntu-20.04.6-desktop-amd64.iso -m 2048 -enable-kvm -cpu host -machine pc



TODO:
  windows (share server) to ubuntu
  ubuntu (share server) to ubuntu
  ìë™ê°±ì‹ ë˜ê²Œ í•˜ëŠ” ë°©ë²•.
#  https://docs.usebottles.com/advanced/cli


>>>  NFS (Network Attached Storage) ì“°ì.


ì˜¤ëŠ˜ì€ ì¥ì¹˜ê³µìœ ê¹Œì§€ í•´ë³´ì. ì ¯ìŠ¨ ë‚˜ë…¸ì—


>>>>>>>> Helix install prototype ìë™í™” ìŠ¤í¬ë¦½íŠ¸ì— ì¶”ê°€. (ì¼ë‹¨ ì—¬ê¸°ì„œ í•´ë³´ê³ )




lsb_release -a ğŸ†š  uname -a



===== Run level
  # df
  #   /boot/efi : ë¶€íŠ¸ ë¡œë”
  #   /dev/sda<n>: në²ˆì¨° íŒŒí‹°ì…˜ì— ì„¤ì¹˜ë˜ì–´ìˆìŒ.

  # text mode
  sudo init 3
  runlevel 
  # runlevel ì€ ìœ ì§€ë³´ìˆ˜, ë³µêµ¬ëª¨ë“œì—ì„œ ì‚¬ìš©ëœë‹¤. root ë¡œ ì´ìš©ë¨.
  ps -F
  # system call functions: folk ..

  cat /etc/init.d/smbd

  #
  sudo apt install samba
  sudo service smbd status
  # make menuconfig
  sudo apt instsal lbuild-essential libncursed-5-dev libssh-dev bision flex libelf-dev dwarves

  ### "time"
  time make bzImage -j4

  man read
  su - root ğŸ†š su root
  ğŸ“° lost+found ë³µêµ¬.. sync ëª…ë ¹ì–´?
  ğŸ“° which cd í•˜ë©´ ì•ˆë‚˜ì˜¤ëŠ” ì´ìœ ê°€ ë‚´ì¥ ëª…ë ¹ì–´ë¼ì„œ. which cp ëŠ” ë‚˜ì˜´. ì™¸ì¥ ëª…ë ¹ì–´ë¼ì„œ. (ì¼ë°˜ ë°”ì´ë„ˆë¦¬ íŒŒì¼ë“¤)
  ğŸ“° lsmod. ëª¨ë¸ì— ì ì¬ë˜ì–´ìˆëŠ” ë””ë°”ì´ìŠ¤ ë“œë¼ì´ë¸Œ í™•ì¸. .ko ëŠ” ì»¤ë„ ì˜¤ë¸Œì íŠ¸ íŒŒì¼
  ì»¤ë„ ë‹¤ìš´ë¡œë“œ í›„ ì»¤ë„ì´ë¯¸ì§€.. ls -l arch/x86/boot/bzImage
  sudo make modules_install --> ë¨ë””ìŠ¤í¬.. í•„ìš”..?
  /boot/..? ë¶€íŠ¸ ë¡œë” ìœ„ì¹˜?
  /llib/modules/
  find . -name *.ko | wc -l  # ê°œìˆ˜ í™•ì¸.
  # debug mode, release mod ê°€ ìˆìŒ. strip ì˜µì…˜ì€ ë¦´ë¦¬ì¦ˆ ëª¨ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒ.
  # sudo find . -name *.ko -exec strip --strip-unnedded {} \; 
  ğŸ“° du -
  gedit ~/linux_c/copy.d/copy.c
  sudo apt install universal-ctags vim
  sudo ctags -R
  vi .. ~/.vimrc
    set number
    set ts=4
    set cindent
    set autoindent
    set smartindent
    set tags=/usr/include/tags
  # ps -ef | grep c.txt
https://docs.ros.org/en/jazzy/Releases.html

TPMì´ë‚˜ Secure Boot í™˜ê²½ì´ ì•„ë‹Œ ê²½ìš°: TPMì´ë‚˜ Secure Bootê°€ ì§€ì›ë˜ì§€ ì•Šê±°ë‚˜ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” QEMU ê°™ì€ ê°€ìƒí™” í™˜ê²½ì—ì„œëŠ” X.509 ì„œëª… ê²€ì¦ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
  $ make menuconfig			   
  -*- Cryptographic API  --->          // ì´ë™ í›„ ì œì¼ ì•„ë˜(ì¸ì¦ ë¬¸ìì—´ ì œê±°)
  # ì»¤ë„ì˜ ë³´ì•ˆê³¼ ë¬´ê²°ì„± ê²€ì¦ì— ì‚¬ìš©ë˜ëŠ” X.509 ì¸ì¦ì„œì™€ ê°„ë ¨ëœ ê²ƒ.
  Certificates for signature checking  --->   //ì„ íƒ, ì•„ë˜ ë¬¸ìì—´ ì œê±°
  (debian/canonical-certs.pem) Additional X.509 keys for default system key ïƒ¨ 
  ()  Additional X.509 keys for default system keyring

  (debian/canonical-revoked-certs.pem) X.509 certificates to be preloaded into the system blacklist key ïƒ¨
  ()    X.509 certificates to be preloaded into the system blacklist key
    ìˆ˜ì • í›„ Exit ì„ íƒ í›„ ì €ì¥/ì¢…ë£Œ

ğŸ“ Interview: Sticky bit ; https://en.wikipedia.org/wiki/Sticky_bit
  for /tmp dirctory 


"workbench.externalBrowser": "firefox" ì„¤ì • ë¬¸ì œì—¿ìŒ.. ìê¾¸ íŒŒì´ì–´í­ìŠ¤ë¡œ ì—´ë¦¬ëŠ”ê±°..
ğŸ“° TODO: Although QEMU has a command line interface and a monitor to interact with running guests, they are typically only used for development purposes. libvirt provides an abstraction from specific versions and hypervisors and encapsulates some workarounds and best practices.
ğŸ“° TODO: Running QEMU/KVM. Warning: This example is just for illustration purposes - it is not generally recommended without verifying the checksums; Multipass and UVTool are much better ways to get actual guests easily.
/


sudo hx /etc/netplan/00-installer-config.yaml

ğŸ“ íš¨ë¦¼ì—‘ìŠ¤ì´: https://m.saramin.co.kr/job-search/company-info-view?csn=aEpLbHFBQjhucHdVQ1FuWkl5QmZFQT09&t_ref_content=generic
  KS ? ì— ë“¤ì–´ê°€ëŠ” ë„¤ë¹„ê²Œì´ì…˜ì„ ë§Œë“œëŠ” íšŒì‚¬? 
  
  
  DMS
    ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •.: ì¡¸ìŒ ê°ì§€,  ë“±ë“±
    !! ëª¨ë¸ í‰ê°€ ë° ê²€ì¦ì—!!
      ì •ë°€ë„, ì¬í˜„ìœ¨ ë“± ë‹¤ì–‘í•œ ì§€í‘œë¥¼ í†µí•´ ëª¨ë¸ì˜ ì •í™•ì„œ ã…‡í‰ê°€.
      ë°, ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦. í•„ë“œì—ì„œ ì •í™•ì„±ê³¼ ì‹ ë¢°ì„± í‰ê°€.
      - ë²¤ì¹˜ í‰ê°€ & ğŸ‘ ì‹¤ì°¨ í‰ê°€. CANalyzerì™€ CANoeê°€
    ê²€ì¦ íˆ´? ğŸ‘ ìº”ë²¡í„° Vector.. ê°• êµìˆ˜ë‹˜ê»˜ì„œ ê°€ì§€ê³  ê³„ì‹ ë‹¤ê³  í•œë‹¤.
      Candb?
    


  ìë™ì°¨ ê²€ì¦ ì—”ì§€ë‹ˆì•„
  DMS ì‹œë‚˜ë¦¬ì˜¤. ìë™ì°¨ ì „ì¥ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ..  ììœ¨ì£¼í–‰ 3ë‹¨ê³„ ì •ë„ì— ë“¤ì–´ê°€ëŠ” ì‹œë‚˜ë¦¬ì˜¤.
  ì´ë¡ &ë²•ê·œ ì„¸ë¯¸ë‚˜
  Driving Montioring system (DMS). ìš´ì „ìì˜ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ ê°ì§€/ë¶„ì„ ìš´ì „ ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìœ„í—˜ ìš”ì†Œë¥´ ã„¹ìµœì†Œí™”.
    ì¡¸ìŒ ìš´ì „, ì£¼ì˜ ì‚°ë§Œ ë“±..
    Types
      ADDW (Advanced Driver Distraction Warning); ê³ ê¸‰ ìš´ì „ì ì£¼ì˜ì‚°ë§Œ ê²½ê³ ì‹œìŠ¤í…œ
      DDAW (Driver Drowsiness and Attention Warning); ìš´ì „ì ì¡¸ìŒ ë° ì£¼ì˜ ê²½ê³ ì‹œìŠ¤í…œ
    https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A02019R2144-20240707
    ğŸ‘ ìë™ì°¨ë¥¼ íŒë§¤í•˜ê¸° ìœ„í•´ì„œ ë¬´ì¡°ê±´ ë„£ì–´ì•¼ í•œë‹¤.
      2024ë…„ë¶€í„° ì¶œì‹œí•˜ëŠ” ëª¨ë“  ì°¨ëŸ‰ì— DMS íƒ‘ì¬ ì˜ë¬´í™”.. (EU ë²•ê·œ). >>>>  ã…œã……ìš”ê°€í™•ì‹¤.
      General Safety Regulation(GSR)* ê·œì •
      https://single-market-economy.ec.europa.eu/publications/new-rules-vehicle-safety-and-automated-mobility_en
      2024ë…„ 7ì›” 7ì¼ë¶€í„° ìœ ëŸ½ ì—°í•©(EU)ì—ì„œëŠ” ëª¨ë“  ì‹ ê·œ ì°¨ëŸ‰ì— Driver Monitoring System(DMS) íƒ‘ì¬ë¥¼ ì˜ë¬´í™”í–ˆìŠµë‹ˆë‹¤
      EU ì—ì„œ ì •í•œ ë²•ê·œê°€ ì‡ë‹¤.
        ğŸ‘ ìš”êµ¬ì‚¬í•­, í™œì„±/ë¹„í™œì„±í™” ê¸°ì¤€, ê²½ê³  ë°©ì‹, ê²½ê³  ì„±ê²©, í•­ëª©.
  ë™ì  ê³„ì‚° ê·¸ë˜í”„ vs ì •ì  ê³„ì‚° ê·¸ë˜í”„
    tensorflow ëŠ” ì •ì  ê³„ì‚° ê·¸ë˜í”„ ê¸°ë°˜.
    pytorch sm ë™ì  ê³„ì‚° ê·¸ë˜í”„ ê¸°ë°˜.

Driving Montioring system (DMS) - Driver Drowsiness and Attention Warning
https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=PI_COM:Ares(2021)1075107&rid=11
ğŸ’¯ https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=PI_COM%3AAres%282021%291075107


Regulation (EU) 2019/2144



address bus, data bus... 
  ë°ì´í„° access í•  ë•Œ address bus ì— ì£¼ì†Œë¥¼ ì§€ì •í•˜ê³  ê·¸ ì£¼ì†Œì— 8bitë‚˜ ê·¸ëŸ° ë°ì´í„°ë¥¼ ë°ì´í„° ë²„ìŠ¤ì— ì‹¤ì–´ì„œ ë‚´ê°€ 
  32ë¹„íŠ¸ ì•„í‚¤í…ì²˜ì—ì„œ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ë©”ëª¨ë¦¬ ë²”ìœ„
b0 ~ 32 
ğŸª± Segmentaton Fault ì˜¤ë¥˜ ; ë©”ëª¨ë¦¬ ì˜ëª» ì ‘ê·¼.
ì „ì—­ ë³€ìˆ˜ëŠ” global ë³€ìˆ˜ì™€ ê°™ì€ ê³µê°„ì—..
32 ë¹„íŠ¸ ìš´ì˜ì²´ì œì—ì„œëŠ” 4 ë°”ì´íŠ¸ ì£¼ì†Œ ì²´ê³„ë¥¼ ê°€ì§. í¬ì¸í„°ì˜ í¬ê¸°. 
  ì–´ë“œë ˆìŠ¤ëŠ” ë‹¨ìˆœíˆ ì£¼ì†Œ. í¬ì¸í„°ëŠ”?.. í¬ê¸°ì •ë³´ê°€ ìˆëŠ” í¬ì¸í„°. ì—†ëŠ”ê²ƒë„ ì‡ê¸´ í•¨. void pointer.
data bus ê°€ 32 bit ì´ê¸° ë•Œë¬¸ì— ì»´í“¨í„°ê°€ ë¹ ë¥´ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” í¬ê¸°ê°€ 4ë°”ì´íŠ¸. ğŸš£ í•œ í´ëŸ­ì—.
>>> ğŸ’¹ chaggpt explain detail of program mermoy layout at most

ìŠ¤íƒì—ë‹¤ê°€ êµ¬ì¡°ì²´ë¥¼ í• ë‹¹í•˜ë©´ â“ **ìŠ¤íƒì— í• ë‹¹í•˜ëŠ” êµ¬ì´ˆì œ ë¹„ìœ¨ì´ ì»¤ì§€ë‹ˆê¹Œ ë¹„íš¨ìœ¨ì ì´ë‹ˆê¹Œ** í™ ì˜ì—­ì— í• ë‹¹ ê¶Œì¥. new delete
    copy. evalulation strategy

  list.append(..) ê·¸ë˜ì„œ ë¹„íš¨ìœ¨ì ì´ë‹¤. ????

  - stack ì€ í™ë³´ë‹¤ í•œì •ì ì¸ 
  -- X í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•  ë•Œ ìŠ¤íƒ stack size ë¥¼ ì •í•  ìˆ˜ê°€ ìˆë‚˜?
    
ğŸ‘ https://byeo.tistory.com/entry/QEMU-VM%EC%9D%98-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%EB%A5%BC-%EC%9D%B8%ED%84%B0%EB%84%B7%EA%B3%BC-%EC%97%B0%EA%B2%B0%ED%95%98%EA%B8%B0?category=1362285



>> Linux commands todo sort out
  background -> foreground ë¡œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‚˜? (ctrl+z) fg%a ?
  ps -ef, ps -f.  port.. 1 ~ 1024 known ports, unknown ports: ~ 65535
  sudo killall <process_name>; e.g. firefox
  sudoers
  umask
  top
  print
    Linux ì»¤ë„ì—ì„œ ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜
  dmesg
    dmesg eth0  # display meesage. driver message
    sudo dmesg | grep eth0
    sudo dmesg | wc -l    # line numbers
    sudo dmesg | wc -c    # character numbers
    sudo dmesg | wc -w    # word numbers

  samba
    sudo apt update
    sudo apt install smbclient cifs-utils

    sudo mount -t cifs -o username=<Windows_Username>,password=<Windows_Password> //Windows_IP_Address/Shared_Folder /mnt/windows_share
    sudo mount -t cifs -o username=intel-teacher/user,password=,uid=$(id -u),gid=$(id -g) //10.10.16.180/shared /mnt/windows-share
    sudo mount -t cifs -o username=ubuntu,password=ubuntu,uid=$(id -u),gid=$(id -g) //10.10.14.40/samba /mnt/windows_share
  ğŸš£ pstree
  ps -f .. ì„œë²„ ì‰˜? ë¡œê·¸ì¸ ì‰˜? ì— ë”¸ëŠ ì°¨ì´?

  /etc/shadow .. md5 ì•”í˜¸í™”?






CIFSëŠ” íŒŒì¼ ê³µìœ  í”„ë¡œí† ì½œì´ê³ , SambaëŠ” í•´ë‹¹ í”„ë¡œí† ì½œì„ êµ¬í˜„í•œ ì†Œí”„íŠ¸ì›¨ì–´ íŒ¨í‚¤ì§€
  CIFS: ì§€ì› SMB ë²„ì „: SMB 1.0 (êµ¬ë²„ì „, ë³´ì•ˆ ë¬¸ì œ ì¡´ì¬)
  Smaba: ì§€ì› SMB ë²„ì „: ìµœì‹  SMB(2.x, 3.x) í”„ë¡œí† ì½œ ì§€ì›
!gcc >> gcc ì— ëŒ€í•œ history.





jobs
fg %1   // ..íŒŒì¼ ë³µêµ¬??? ì´ê²Œ ë¬´ìŠ¨ã…… ã…—ë¦¬..
ps -f ì—ì„œ í•˜ì´í”ˆì´ ì—†ëŠ” ê²ƒì€ ë¡œê·¸ì¸ ì‰˜?
. bash -> í˜„ì¬ ì‰˜ë¡œ ì‹¤í–‰.

./ ë¥¼ ì•ˆí•˜ë©´ path ì— ì‡ëŠ”ê²ƒë“¤ì¤‘ì— ìš°ì„ ì ìœ¼ë¡œ ê²€ìƒ‰í•œë‹¤ëŠ”ë“¯.

ë‚´ì¥/ì™¸ì¥ ëª…ë ¹ì–´ í™•ì¸ ë°©ë²•..
file /bin/pwd ??

ELF: excutable link format.

ê³„íš:
  í™˜ê²½
    host
      OS: Ubuntu 24.04
      network IPv4:
        Address: 10.10.14.19
        Network: 255.255.255.0
        Gateway: 10.10.14.254
        DNS: 203.248.252.2
    qemu vm is crated by
    
bash
  qemu-img create -f qcow2 ~/qemu/ubuntu-vm.qcow2 150G
  qemu-system-x86_64 \
    -enable-kvm \
    -smp 1 \
    -m 2048 \
    -machine q35 \
    -cpu host \
    -global ICH9-LPC.disable_s3=1 \
    -net nic,model=virtio \
    -net user,hostfwd=tcp::8022-:22,hostfwd=tcp::8090-:80 \
    -drive file=$HOME/qemu/OVMF_CODE_4M.secboot.fd,if=pflash,format=raw,unit=0,readonly=on \
    -drive file=$HOME/qemu/OVMF_VARS_4M.ms.fd,if=pflash,format=raw,unit=1 \
    -drive file=$HOME/qemu/ubuntu-vm.qcow2,if=none,id=disk0,format=qcow2,cache=writeback \
    -device virtio-blk-pci,drive=disk0,bootindex=0 \
    -drive file=$HOME/qemu/ubuntu-22.04.5-desktop-amd64.iso,if=none,id=cdrom,media=cdrom \
    -device ide-cd,bus=ide.1,drive=cdrom \
    -serial mon:stdio

  qemu virtual machine ubuntu 22
  ëª…ë ¹ì–´ë¡œ ì„¤ì •í•´ì•¼ í•˜ëŠ” ë‚´ìš© 
    network IPv4:
      Address: 10.10.14.39
      Network: 255.255.255.0
      Gateway: 10.10.14.254
      DNS: 203.248.252.2
    host OS ì—ì„œ ë³µì‚¬í–ˆë˜ í…ìŠ¤íŠ¸ë¥¼ ì´ ê°€ìƒ ë¨¸ì‹  ì•ˆì—ì„œ ê·¸ëŒ€ë¡œ ì´ìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°©ë²•
  
ì˜¤ì§ ëª…ë ¹ì–´ ë˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë§Œ ì‚¬ìš©í•´ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•˜ê³ ì‹¶ã…‡


íƒ­
th0
br0
ì•„ë¬´ê±°ë„ ì„¤ì •ì•ˆí•˜ë©´ virtual bridge, virtual ehternet swtich ë„ ì—†ëŠ” ê²ƒ.
  Host (Physical) NIC ; ë¼ìš°í„° 

  Gateway, ì„œë¸Œë„·ë§ˆìŠ¤í¬, DNS 

  ê°™ì€ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­ì´ë¼ê³  í•˜ë©´. 24 bit subnetmask 
  ì›ê¸°ë‘¥ì´ ë¼ìš°í„° ëª¨ì–‘.
  ê°™ì€ ë„¤íŠ¸ì›Œí¬ ë‚´ì—­
    ëŒ€ì—­1: 10.1.1.1 ~ 10.1.1.20
    ëŒ€ì—­2:  192.168.0.1 24bit ë©´ (C í´ë˜ìŠ¤) ~ 192.168.0.255
    ëŒ€ì—­3: 172.1.1.

    ê°•íŠ¼ ë„¤íŠ¸ì›Œí¬ê°€ ì•„ë‹ˆë©´ ìŠ¤ìœ„ì¹˜ì—ê²Œ ë³´ë‚´ë©´ -> L2 ë¸Œë¡œë“œìºìŠ¤íŠ¸
    172 PC ê°€ ìì‹ ì˜ ìŠ¤ìœ„ì¹˜ì—ê²Œ íŒ¨í‚·ì„ ë³´ë‚´ì„œ ë‹¤ë¥¸ 192ë¥¼ ì°¾ì„ ë•Œ, ìê¸° ìŠ¤ìœ„ì¹˜ ì•ˆì— ì—†ìœ¼ë©´ ë‹¤ë¥¸ ë¼ìš°í„° ëª¨ë‘ì—ê²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ / ARb Request..
      í•´ì„œ ë¿Œë ·ìŒ. 
    ìŠ¤ìœ„ì¹˜ ë„˜ì–´ì„œ ë¼ìš°í„° ì•ì— ê²Œì´íŠ¸ì›¨ì´. 
      ë¼ìš°í„°ì˜ eth0 ì´ëŸ°ê²ƒì„ íŠ¹ë³„í•´ì„œ ê²Œì´íŠ¸ì›¨ì´ë¼ê³  ë¶€ë¦„.
    ë¼ìš°í„°ì—ëŠ” "ë¼ìš°íŒ… í…Œì´ë¸”"ì´ ìˆìŒ -- ëª¨ë“ (?) IP ì— ëŒ€í•œ ê²½ë¡œë¥¼ ì§€ì •í•˜ê³ ìˆì–´ì„œ .. ë¼ìš°íŒ… í…Œì´ë¸” ê³„ì‚°ì‹ì— ì˜í•´ì„œ ì°¾ì•„ê°.
      ë‹¤ë¥¸ ëŒ€ì—­ëŒ€ ê°ˆê±°ë©´.. "ê°€ì¥ ê°€ê¹Œìš´" ë¼ìš°í„°ì˜ eth0 ê°€ ê²Œì´íŠ¸ì›¨ì´ë¥¼ ì§€ë‚œë‹¤.
      
    ê²Œì´íŠ¸ì›¨ì´ë¥¼ ì •ìƒì ìœ¼ë¡œ ì„¤ì •í•´ì•¼ 
      ê²Œì´íŠ¸ì›¨ì´ IP ì˜ ë§¨ ë ê°’ì€ ëˆ„ê°€ ì •í•˜ëƒ? 10.10.14.254
        ì¼ë°˜ì ìœ¼ë¡œ 254ê°€ ê²Œì´íŠ¸ì›¨ì´. ë„¤íŠ¸ì›Œí¬ ë§ì„ ê´€ë¦¬í•˜ê³  ìˆëŠ” ë„¤íŠ¸ì›Œí¬ íšŒì‚¬ KT, íšŒì‚¬ë“¤ì´ ì´ ê°’ì„ ì •í•˜ëŠ” ê²ƒ.
        ë¼ìš°í„° (í†µì‹ /ë¼ìš°í„° ì‚¬ì—…ì. ISP. KT, LG) ---> ë°©í™”ë²½ (ì›¹ ë°©í™”ë²½ê³¼ ë‹¤ë¦„) --> ìŠ¤ìœ„ì¹˜ --> ì„œë²„
          - ë¼ìš°íŒ…ì—ì„œ ê°œì¸ì—ê²Œ í• ë‹¹ì„ í•´ì¤€ë‹¤.
          - ê²Œì´íŠ¸ì›¨ì´ IP
          ======== ê³µì¸ ì•„ì´í”¼ê°€ ê²°êµ­ ê²Œì´íŠ¸ì›¨ì´ IP
          ê²Œì´íŠ¸ì›¨ì´ IP ì•„ë˜ ë°©í™”ë²½: L3 ìŠ¤ìœ„ì¹˜, ë°©í™”ë²½ë„ L3 ê³„ì¸µ. ê³µìœ ê¸°ë„ L3 ê³„ì¸µ
          * picture: Test Network êµ¬ì„±ë„. ì†Œê·œëª¨ ìŠ¤ìœ„ì¹­ êµ¬ì„±. IP NAT ---> 192, 172
            ê³µì¸ IP ë¥¼ ì‚¬ì„¤ IP ë¡œ ë³€ê²½í•´ì£¼ëŠ” ê²ƒ. 172 ëŒ€ì—­, 192ëŒ€ì—­.
            -- ë°©í™”ë²½ ì…ì¥ì—ì„œ ê²Œì´íŠ¸ì›¨ì´ëŠ” External Router IP
            -- ë©”ì¸ ë°±ë³¸ (L2 or L3) . LC ë©´ ë°©í™”ë²½ ë°”ë¡œ ì•ì˜ Gateway.
            -- L2 ëŠ” ê°™ì€ ë„¤íŠ¸ì›Œí¬ë¼ë¦¬ì˜ í†µì‹ ì„ ì´ì–´ì£¼ëŠ” ì¥ë¹„ì˜ ì—­í• ì´ë¼ì„œ ê²Œì´íŠ¸ì›¨ì´ IP ë¼ëŠ” ê²ƒì´ í•„ìš” ì—†ìŒ. ì‹¤ì œë¡œ í• ë‹¹ë„ ë¶ˆê°€ëŠ¥í•¨.
            -- L3 ëŠ” í•„ìš”í•˜ë‹¤.
            -- ê³µìœ ê¸° í—ˆë¸Œ ì—­í• ì´ ë¼ìš°íŒ… í…Œì´ë¸” ì—­í• ë„ í•˜ê³ , .. ê³µìœ ê¸°ì˜ íšŒìƒ‰ì„ ì´ í†µì‹  ì‚¬ì—…ìë‘ ì—°ê²°ë˜ì–´ìˆëŠ” ì„ 
              ê³µì¸ IP ë¥¼ ì‚¬ì„¤ IP ë¡œ ë³€ê²½í•´ì£¼ëŠ” ì‘ì—…; NAT
            -- ê°œì¸ PC ì…ì¥ì—ì„œëŠ” ë³´í†µ ë°©í™”ë²½ ì•ì˜ 
        // ê²Œì´íŠ¸ ì›¨ì´ IP ëŠ”     
  Virtual Bridge ë¼ëŠ” ì„¤ì •ì´ L2 ìŠ¤ìœ„ì¹˜ (Virtual Ethernet Switch) ì™€ L3 ìŠ¤ìœ„ì¹˜ì™€ ì—°ê²°í•´ì£¼ëŠ” ì„ .
  -- ë¸Œë¦¿ì§€ê°€ ì—†ìœ¼ë©´ NAT ë¥¼ ì‚¬ìš© ëª»í•´ì„œ IP ë¥¼ í•œê°œë°–ì— ì—†ìŒ.. ? ã…‡ã…‡?

  1. L2, L3 ê°€ ë­”ê°€?
    ê³„ì¸µ ì´ë¦„.
    L3 ë¶€í„° NAT ë¥¼ í•  ìˆ˜ ìˆë‹¤.
    ê³µì¸ IP = ISP ê°€ í• ë‹¹í•´ì¤€ ì˜ì—­.
  2. 172. 192, 10. ..
    192, 172, 10.. ì€ ì‚¬ì„¤ IP ëŒ€ì—­ìœ¼ë¡œ í†µìƒì ìœ¼ë¡œ ì§€ì •í•´ì¢‹ì€ ëŒ€ì—­. ì•½ì†. ã…‡ã…‡
      LAN (192.168.0.1) ê²Œì´íŠ¸ì›¨ì´ IP ë¥¼ ë ê°’ì„ 1, 2, 3 ìœ¼ë¡œ í•  ìˆ˜ë„ ìˆëŠ”ë° ì´ê²ƒë„ ì•½ì†ì´ ìˆë‹¤. ê´€ìŠµ

  192.168.0.1 ì´ ê²Œì´íŠ¸ì›¨ì´ IPì´ë‹¤. 
    x port
    ğŸª± Port full NAT?
    í¬íŠ¸ì˜ ëŒ€ì—­ëŒ€ëŠ” 1 ~ 65535 ê¹Œì§€ ìˆìŒ
      0 ~ 1024ë²ˆê¹Œì§€ëŠ” ì§€ì •ë˜ì–´ìˆìŒ
      Known port, unknoown port. 1024 ~ 65535.
  ë‚´ ì»´í“¨í„°ì—ì„œ ìŠ¹í™˜ ê³µìœ ê¸°ë¡œ ë³´ë‚¼ ë•Œ ê³µì¸ IP:<random port> (ë‚´ë¶€ IP êµ¬ë¶„í•˜ê¸° ìœ„í•¨)
    ** TCP session ë§ˆë‹¤ ë°”ê¿ˆ.


  -- ëª¨ë“  L3 ìŠ¤ìœ„ì¹˜ê°€ ê²Œì´íŠ¸ì›¨ì´ê°€ ì—¬ëŸ¬ ê°œ ìˆì„ ìˆ˜ ìˆë”°. ë¼ìš°íŒ… í…Œì´ë¸”ì´ë€ ê²ƒì´ ìˆì–´ì„œ.       
    ISP ì—…ì²´ì˜ í…Œì´ë¸” ë¿ ì•„ë‹ˆë¼ê³µìœ ê¸°ë„ ê°€ëŠ¥í•˜ê¸´ í•˜ë‹¤.


  LAN ----bridge------- Host machine
    bridge ì•ˆì—ëŠ” ì—¬ëŸ¬ ê°œì˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤?
    ì–´ëŒ‘í„°ì— ë¸Œë¦¿ì§€?? 
    bridge ê°€ ì„  ìì²´ê°€ ì•„ë‹ˆê³  eth0, tap0, tap1 ì¸í„°í˜ì´ìŠ¤.
    "eth0" ì€ ì‹¤ì œ ë¬¼ë¦¬ì ì¸ ì¸í„°í˜ì´ìŠ¤.
      ë¸Œë¦¬ì§€ ì„¤ì •ì„ í•˜ê¸° ìœ„í•´ì„œ eth0 ì„ í¬ê¸°í•˜ê³ , 
      br0 

  í´ë¼ìš°ë“œë“œí• ë–„
    eth0 ì´ ìˆìœ¼ë©´ ì›ë˜ eth0ì´ ì´ë”ë„·êº¼ì¸ë° eth0 ëŒ€ì‹ ì— br0 ì— í• ë‹¹í•˜ê³  
      


  byeotap0, wlo0 (ì´ë”ë„·), 
    wlo0, eth0 ì´ëŸ°ê±°ë„ ì´ë¦„ ì§€ì •í•  ìˆ˜ ìˆìŒ. ã…‡ã…‡.. í†µìƒì ìœ¼ë¡œ.
      wlo0 ë‚´ê°€ ì§€ì •í•´ì¤€ ì´ë¦„.

  enps0 os ì— ëŒ€í•œ ì¸í„°í˜ì´ìŠ¤ ëª…. 

  .........https://byeo.tistory.com/entry/QEMU-VM%EC%9D%98-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%EB%A5%BC-%EC%9D%B8%ED%84%B0%EB%84%B7%EA%B3%BC-%EC%97%B0%EA%B2%B0%ED%95%98%EA%B8%B0?category=1362285
    ì´ê±° ì´ëŸ¬ë©´ ì™¸ë¶€ì—ì„œ .. í¬íŠ¸ ë°©ì‹ìœ¼ë¡œ.. 201ì—ì„œ í¬íŠ¸ë¡œ êµ¬ë¶„í•˜ëŠ” ê²ƒ..
    >> NAT ã…‚




  >>>>>>>> Helix install prototype ìë™í™” ìŠ¤í¬ë¦½íŠ¸ì— ì¶”ê°€. (ì¼ë‹¨ ì—¬ê¸°ì„œ í•´ë³´ê³ )
  ê·¸ë¦¬ê³  ip -a c ì´ê±° gnu ì—ì„œ ì°¾ê³  ê¶Œì¥ì´ë‹ˆê¹Œ O í‘œì‹œí•˜ê³ , ê´€ë ¨ í•´ì„ ë³´ê¸°.
  QEMU ìš°ë¶„íˆ¬ 22ë¡œ í•˜ê¸° ROS LTS ë²„ì „ê³¼ í˜¸í•œ + Yocto ë²„ì „ê³¼ tier1 í˜¸í™˜.
  samba ? linux to linux ëŠ” ì–´ë–»ê²Œ?

  ë‚´ host OS ê°€ ë¼ìš°í„°ê°€ ë˜ëŠ”ê²ƒ
  https://richong.tistory.com/351ã…‡\

  ë¸Œë§‚ ã…£ìƒì„±í•˜ê³ , tab0 tab1 ìƒì„±í•´ì„œ 

  >??? ì¸í„°í˜ì´ìŠ¤ í•˜ë‚˜ì— IP ì—¬ëŸ¬ ê°œ í• ë‹¹ ê°€ëŠ¥í•˜ë‹¤ê³  í•œë‹¤?


  AWS -- ì„ íƒí•´ì„œ êµ¬ë§¤í•˜ë©´ ì›¹ë°©í™”ë²½ì´ ì˜¬ë¼ê°.
    ì›¹ë°©í™”ë²½ OS 
  ì˜¤ë¼í´ í´ë¼ìš°ë“œëŠ”, Ubuntu OS ë¥¼ ì„¤ì¹˜ë¥¼ í•˜ê³ , ì›¹ë°©í™”ë²½ì„ ì˜¬ë¦¬ê¸° ìœ„í•œ íŒ¨í‚¤ì§€ë“¤ì„ 
    íœíƒ€OS

  tap: tab ì¥ë¹„. ê·¸ëƒ¥ í˜ë ¤ì£¼ëŠ” ì—­í• .
  eth0 ì™€ ã„±ë¹„ìŠ·í•¨.
  ê°™ì€ L2 ë‹¨ì—ì„œëŠ” MAC ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤?
    Virtual MAC (VMAC
    L2 ì¥ë¹„ (ê°™ì€ ì‚¬ì„¤ ë„¤íŠ¸ì›Œí¬ë‹¨ì„ ì—°ê²°í•´ì£¼ëŠ” ì¥ë¹„) ëŠ” MAC table
      IP2
      ??? ì°¾ì•„ë³´ê¸° MAC table ì„ ëˆ„ê°€ ê°€ì§€ê³  ìˆì§€?
    
      MAc Tableì„ ê²½ë¡œë¥¼ ì§€ì •í•˜ê¸° ìœ„í•œ L2ë‹¨ì˜ í”„ë¡œí† ì½œ
    GARP: ë‚˜ ì—¬ê¸° ì‡ë‹¤.. ë¼ê³  í•˜ëŠ” ë‹¤ë¥¸ ê²ƒ.

    1. L2 S/W ìŠ¤ìœ„ì¹˜ì— ì—°ê²°ë˜ë©´, PC ê°€ GARP ë¥¼ ë¿Œë ¤ì„œ Mac Table ì„ ì—…ë°ì´íŠ¸í•œë‹¤.
    2. ë˜ëŠ” ì–´ë–¤ PCê°€ ìš”ì²­ì„ í–ˆì„ ë•Œ, L2 S/W ëŠ” ëª¨ë“  PC ì—ê²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•´ì„œ, ì‘ë‹µì„ ë°˜í™˜í•œë‹¤.
      ARP Request, Reponse ë°©ì‹; 
    

    
    G ARP íŒ¨í‚·?

    
    L2 S/W tap1 

  ì™¸ë¶€ì—ì„œë„ LAn gateway ë¥´ ã„¹í†µí•´ì„œ ì‘ë‹µì„ ì£¼ëŠ” ê²ƒ ë¿?

  L3ë‹¨ì€ í¬íŠ¸ë§ˆë‹¤ IPê°€ ìˆê³  L2 ë‹¨ì€.. ì•„ë‹˜?..ì•„ë‹Œê°€?

  Gateway ê°€ IP ë¡œ ì´ë£¨ì–´ì§„ ê²ƒì´ê³ , Gateway ê°€ ê·¸ íŠ¹ì§•ì„ ë‚˜íƒ€ë‚¸ ê²ƒ ë¿.

  A-1 ---(Routing Table)---- L3 ----(Routing Table)---- L3 -------

  Vm0 -> Vm1 ë¡œ ã„±


  ê°™ì€ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­ì€ 
    MAC ìœ¼ë¡œ í†µì‹ í•œë‹¤ê³  ë³´ì..
    ping ìœ¼ë¡œ ip ë¥¼ ë³´ë‚´ë„ <Mac> <inetrface name>
    "Bridge / Tap ë„¤íŠ¸ì›Œí¬ êµ¬ì„±"


    penta os
    nmcli 

    // ì¥ë¹„ ëª…ë ¹ì–´
    

  ë‘ê°œ ì´ìƒì˜ VMì´ ì‚¬ì„¤ë§ ê³µìœ í•˜ë„ë¡ ë§Œë“¤ê¸° >> NAT

  EOL, EOF, EOD


  â­• âš“ Bridge / Tap ë„¤íŠ¸ì›Œí¬ êµ¬ì„± ; https://gee6809.github.io/posts/qemu-network/



  DLSS 

  https://www.nvidia.com/ko-kr/geforce/graphics-cards/40-series/rtx-4060-4060ti/
  


sudo qemu-system-x86_64 -enable-kvm -cdrom http://archive.ubuntu.com/ubuntu/dists/bionic-updates/main/installer-amd64/current/images/netboot/mini.iso
  ê·¸ë¦¬ê³  ip -a c ì´ê±° gnu ì—ì„œ ì°¾ê³  ê¶Œì¥ì´ë‹ˆê¹Œ O í‘œì‹œí•˜ê³ , ê´€ë ¨ í•´ì„ ë³´ê¸°.
  QEMU ìš°ë¶„íˆ¬ 22ë¡œ í•˜ê¸° ROS LTS ë²„ì „ê³¼ í˜¸í•œ + Yocto ë²„ì „ê³¼ tier1 í˜¸í™˜.
  samba ? linux to linux ëŠ” ì–´ë–»ê²Œ?


  ğŸ“° mv ~/.wine/drive_c/users/wbfw109v2/Documents/ì¹´ì¹´ì˜¤í†¡\ ë°›ì€\ íŒŒì¼/2024ë…„_ì œ6íšŒ_Kë””ì§€í„¸_íŠ¸ë ˆì´ë‹_í•´ì»¤í†¤_ì°¸ê°€ì‹ ì²­ì„œ_ì‘ì„±ì¤‘.docx ~/Downloads/
    sudo mount -t cifs -o username=Guest,password=,uid=$(id -u),gid=$(id -g) //10.10.14.40/class_401 /mnt/windows-share
    
    ### gnome íŒŒì¼ ì‹œìŠ¤í…œ ë°”ë¡œê°€ê¸° ë“±ë¡í•˜ëŠ” ëª…ë ¹ì–´ í•„ìš”.
    ~/.wine/drive_c/users/wbfw109v2/Documents/KakaoTalk Downloads
  âš“ syscalls ; https://man7.org/linux/man-pages/man2/syscalls.2.html
    The list of system calls that are available as at Linux 5.14 (or in a few cases only on older kernels) is as follows: ...
    passwd

    -netdev tap,id=net0,ifname=tap0,script=no,downscript=no -device e1000,netdev=net0


  sudo systemctl status qemu-kvm --no-pager && sudo systemctl status libvirtd --no-pager
  sudo usermod -aG kvm $USER && sudo usermod -aG libvirt $USER
  
  # VM managemnet tool virsh in libvirt-daemon-system package
  virsh net-list 
  virsh net-info default
  qemu-kvm

  ë¦¬ëˆ…ìŠ¤ ê°€ìƒí™” ì†Œí”„íŠ¸ì›¨ì–´ ë„êµ¬ 

  (Kernel Spaceìª½ì€ KVM, User Space ìª½ì€ QEMU)

  libvirt-daemon-system

  ë¦¬ëˆ…ìŠ¤ì—ì„œ Hypervisorê¸°ë°˜ ê°€ìƒí™” ê´€ë¦¬ ë° ì œì–´ë„êµ¬

  bridge-utils

  VMê°„ ê°€ìƒ ë„¤íŠ¸ì›Œí¬ êµ¬ì„± ìœ„í•œ  ë¸Œë¦¿ì§€ êµ¬ì„± ë° ê´€ë¦¬ ë„êµ¬ 
  virtinst

  ë¦¬ëˆ…ìŠ¤ ê°€ìƒí™” í™˜ê²½ì—ì„œ VM ìƒì„± ë° ê´€ë¦¬ ë„êµ¬



  sudo mkdir -p /etc/qemu
  echo "allow br0" | sudo tee /etc/qemu/bridge.conf
  sudo setcap cap_net_admin+ep /usr/lib/qemu/qemu-bridge-helper

  # 1. í˜¸ìŠ¤íŠ¸ì˜ ìœ íš¨í•œ ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ ê°ì§€ (ì˜ˆ: eno1)
  set INTERFACE (ip -o link show | awk -F': ' '/state UP/ && $2 !~ /lo|tailscale0/ {print $2; exit}')

  # 2. ê°ì§€ëœ ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ ì¶œë ¥
  echo "Detected network interface: $INTERFACE"

  # 3. ë¸Œë¦¬ì§€ ë„¤íŠ¸ì›Œí¬ ì„¤ì •
  sudo ip link add name br0 type bridge
  sudo ip link set br0 up
  sudo ip link set "$INTERFACE" master br0

  # 4. ë¸Œë¦¬ì§€ ìƒíƒœ í™•ì¸
  echo "Bridge br0 created and linked to $INTERFACE."
  ip addr show br0



  virtual box -> ctrl+alt+f2 tty ê°œìˆ˜. QEMU? ì—ì„œëŠ”?

  ğŸ“° DHCP


  sudo apt install -y spice-v

  nmcli c add type bridge ifname bridge0 con-name bridge0 ip4 192.168.0.3/24 gw4 192.168.0.1 ipv4.dns 164.124.101.2
  nmcli c add type ethernet slave-type bridge con-name eth-bridge0 ifname enp1s0 master bridge0
  nmcli c up eth-bridge0
  ì˜¤ì§ ëª…ë ¹ì–´ ë˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë§Œ ì‚¬ìš©í•´ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•˜ê³ ì‹¶ã…‡

  Netplan ì„¤ì • íŒŒì¼ ì´ë¦„ê³¼ ìš°ì„ ìˆœìœ„
    Netplanì€ /etc/netplan/ ë””ë ‰í„°ë¦¬ì˜ ëª¨ë“  YAML íŒŒì¼ì„ ì½ì–´ì„œ ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ ì ìš©í•©ë‹ˆë‹¤.
      íŒŒì¼ì´ ì—¬ëŸ¬ ê°œì¼ ê²½ìš°, ìˆ«ìê°€ ì‘ì€ íŒŒì¼ì´ ë¨¼ì € ì ìš©ë©ë‹ˆë‹¤.
        ì˜ˆ: 00-, 01-, 50- ë“±ê³¼ ê°™ì€ ì´ë¦„ì˜ íŒŒì¼ì´ ìˆìœ¼ë©´ 00-ì´ ë¨¼ì € ì ìš©ë©ë‹ˆë‹¤.
    íŒŒì¼ ì´ë¦„ì€ ì„ì˜ë¡œ ì§€ì •í•´ë„ ë˜ì§€ë§Œ, ìš°ì„ ìˆœìœ„ëŠ” ìˆ«ì ì ‘ë‘ì‚¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•©ë‹ˆë‹¤.
    >> nmcli ë¥¼ ì“°ë©´ ìë™ìœ¼ë¡œ ì´ ê³³ì— íŒŒì¼ ìƒì„±ë¨.
  ê¶Œì¥ íŒŒì¼ ì´ë¦„
    ì„œë²„ì™€ ë°ìŠ¤í¬íƒ‘ì—ì„œ ê³µí†µì ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´ 00-network-config.yaml ë˜ëŠ” **01-netcfg.yaml**ì²˜ëŸ¼ ì´ë¦„ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
      ì´ìœ : 00- ë˜ëŠ” 01- ì ‘ë‘ì‚¬ë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¤ë¥¸ ì„¤ì •ë³´ë‹¤ ìš°ì„  ì ìš©ë©ë‹ˆë‹¤.
      ì˜ˆ: /etc/netplan/00-network-config.yaml

  NAT ë€: https://aws-hyoh.tistory.com/145
  .... https://m.blog.naver.com/love_tolty/222650880951


  ==========
  echo "
  <network>
    <name>br0</name>
    <forward mode='bridge'/>
    <bridge name='br0'/>
  </network>
  " | virsh net-define /dev/stdin

  virsh net-start br0
  virsh net-autostart br0

  qemu info qc2img


âš“ TAP (Traffic Access Point) ; https://en.wikipedia.org/wiki/Network_tap
  A network tap is a system that monitors events on a local network. 
  
  >> í˜„ì¬
    qemu-img create -f qcow2 ~/qemu/ubuntu-vm.qcow2 150G
    qemu-system-x86_64 \
      -enable-kvm \
      -smp 1 \
      -m 2048 \
      -machine q35 \
      -cpu host \
      -global ICH9-LPC.disable_s3=1 \
      -net nic,model=virtio \
      -net user,hostfwd=tcp::8022-:22,hostfwd=tcp::8090-:80 \
      -drive file=$HOME/qemu/OVMF_CODE_4M.secboot.fd,if=pflash,format=raw,unit=0,readonly=on \
      -drive file=$HOME/qemu/OVMF_VARS_4M.ms.fd,if=pflash,format=raw,unit=1 \
      -drive file=$HOME/qemu/ubuntu-vm.qcow2,if=none,id=disk0,format=qcow2,cache=writeback \
      -device virtio-blk-pci,drive=disk0,bootindex=0 \
      -serial mon:stdio


sudo nmcli c add type bridge ifname br0 con-name br0 #Bridge ìƒì„±í•˜ê¸°
sudo nmcli c add type ethernet slave-type bridge con-name eth-br0 ifname eth0 master br0 #eth0ë¥¼ bridgeì— ì—°ê²°í•˜ê¸°
sudo nmcli c up eth-br0 #bridge ì—°ê²° í™œì„±í™”í•˜ê¸°


cat /etc/udev/rules.d/99-bridge-filter.rules


ğŸ‘ required: sudo apt install cloud-init cloud-image-utils
# write ... and
cloud-localds cloud-init.iso user-data.yaml meta-data.yaml
  Infrasturcture as a Code ..
ğŸ‘ Run
sudo qemu-system-x86_64 \
  -enable-kvm \
  -smp 1 \
  -m 2048 \
  -machine q35 \
  -cpu host \
  -netdev tap,id=net0,ifname=tap0,script=no,downscript=no -device e1000,netdev=net0 \
  -global ICH9-LPC.disable_s3=1 \
  -drive file=$HOME/qemu/OVMF_CODE_4M.secboot.fd,if=pflash,format=raw,unit=0,readonly=on \
  -drive file=$HOME/qemu/OVMF_VARS_4M.ms.fd,if=pflash,format=raw,unit=1 \
  -drive file=$HOME/qemu/ubuntu-vm.qcow2,if=none,id=disk0,format=qcow2,cache=writeback \
  -device virtio-blk-pci,drive=disk0,bootindex=0 \
  -serial mon:stdio

  # -cdrom cloud-init.iso \
  -netdev tap,id=net0,ifname=tap0,script=no,downscript=no \
  -device e1000,netdev=net0,mac=52:54:00:12:34:56 \
  # -net user,hostfwd=tcp::8022-:22,hostfwd=tcp::8090-:80 \

sudo qemu-system-x86_64 \
  -enable-kvm \
  -smp 1 \
  -m 2048 \
  -machine q35 \
  -cpu host \
  -netdev tap,id=net0,ifname=tap0,script=no,downscript=no \
  -device virtio-net-pci,netdev=net0,mac=52:54:00:12:34:56 \
  -global ICH9-LPC.disable_s3=1 \
  -drive file=$HOME/qemu/OVMF_CODE_4M.secboot.fd,if=pflash,format=raw,unit=0,readonly=on \
  -drive file=$HOME/qemu/OVMF_VARS_4M.ms.fd,if=pflash,format=raw,unit=1 \
  -cdrom cloud-init.iso \
  -boot d \
  -drive file=$HOME/qemu/ubuntu-vm.qcow2,if=none,id=disk0,format=qcow2,cache=writeback \
  -device virtio-blk-pci,drive=disk0,bootindex=1 \
  -serial mon:stdio
  
>> ğŸ‘ cloud-localds cloud-init.iso user-data.yaml meta-data.yaml --network-config=network-config.yaml
>> sudo cat /var/log/cloud-init-output.log
>> ğŸ‘ Cloud-initëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì²« ë¶€íŒ… ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤. ë§Œì•½ ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìˆ˜ì •í•˜ê³  ì‹¶ë‹¤ë©´ cloud-init clean ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸°í™” ìƒíƒœë¡œ ë³µêµ¬í•œ í›„, ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë‹¤ì‹œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ cloud-initê°€ ë‹¤ì‹œ ì‹¤í–‰ë©ë‹ˆë‹¤.
  


ğŸš¨ cloud-initì€ ì¼ë°˜ì ìœ¼ë¡œ ìš°ë¶„íˆ¬ ì„œë²„ ì´ë¯¸ì§€ì™€ ê³µì‹ í´ë¼ìš°ë“œ ì´ë¯¸ì§€ì— ê¸°ë³¸ì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì–´ ì œê³µë©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëª¨ë“  ìš°ë¶„íˆ¬ ì´ë¯¸ì§€ì— í¬í•¨ëœ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. íŠ¹íˆ, ë°ìŠ¤í¬íƒ‘ ë²„ì „ì´ë‚˜ ì¼ë¶€ ì»¤ìŠ¤í…€ ISOì—ì„œëŠ” ê¸°ë³¸ ì„¤ì¹˜ê°€ ëˆ„ë½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  sudo apt update && sudo apt install cloud-init


- virtioë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ VM ë‚´ë¶€ì˜ OS(ì˜ˆ: Ubuntu)ì— virtio-net ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ìµœì‹  ë¦¬ëˆ…ìŠ¤ ë°°í¬íŒì—ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

cloud-init or use dnsmasq
  https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/8/html/configuring_and_managing_cloud-init_for_rhel_8/introduction-to-cloud-init_cloud-content
    by https://stackoverflow.com/questions/19721938/setting-ip-address-of-the-guest-operating-system-while-launching-qemu

sudo cloud-init clean
sudo cloud-init init
sudo cloud-init status --wait

tap0ë¥¼ ì´ìš©í•´ì„œ QEMU VMì„ êµ¬ë™í•©ë‹ˆë‹¤. tap0ëŠ” br0ë¡œ eth0ì™€ ë¬¶ì—¬ìˆê¸° ë•Œë¬¸ì—, í˜¸ìŠ¤íŠ¸ì™€ ê°™ì€ ëŒ€ì—­ì˜ IPë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. LANì— ë¬¼ë ¤ìˆëŠ” ê³µìœ ê¸°ê°€ DHCPì„œë²„ë¡œì¨ ê°€ìƒë¨¸ì‹ ë“¤ì—ë„ ipë¥¼ í• ë‹¹í•´ì£¼ê²Œ ë©ë‹ˆë‹¤.

ë§Œì•½ ìœ„ì˜ ì‘ì—…ì„ í•˜ê³ ë„ tap ë„¤íŠ¸ì›Œí¬ê°€ í™œì„±í™”ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…ì„ ì¶”ê°€ë¡œ í•´ì¤ë‹ˆë‹¤. 1) /etc/sysctl.d/bridge-filter.confì— ë‹¤ìŒ ë‚´ìš© ì¶”ê°€

net.bridge.bridge-nf-call-ip6tables=0
net.bridge.bridge-nf-call-iptables=0
net.bridge.bridge-nf-call-arptables=0
2) /etc/udev/rules.d/99-bridge-filter.rules ì— ë‹¤ìŒ ë‚´ìš© ì¶”ê°€

ACTION=="add", SUBSYSTEM=="module", KERNEL=="br_netfilter", RUN+="/sbin/sysctl -p /etc/> sysctl.d/bridge-filter.conf"
3) ì¬ë¶€íŒ…


My network IPv4:
  Address: 10.10.14.19
  Network: 255.255.255.0
  Gateway: 10.10.14.254
  DNS: 203.248.252.2
My VM1 network IPv4:
  Address: 10.10.14.39
  Network: 255.255.255.0
  Gateway: 10.10.14.254
  DNS: 203.248.252.2


2. tuntapì˜ ì•½ìì™€ ì˜ë¯¸
  tuntapì€ TUN/TAPì˜ í•©ì„±ì–´ì…ë‹ˆë‹¤.

  TUN (Network TUNnel):
    3ê³„ì¸µ ë„¤íŠ¸ì›Œí¬ ì¥ì¹˜ë¡œì„œ, IP íŒ¨í‚·ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    ì¼ë°˜ì ìœ¼ë¡œ VPNê³¼ ê°™ì€ í„°ë„ë§ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
  TAP (Network TAP):
    2ê³„ì¸µ ë„¤íŠ¸ì›Œí¬ ì¥ì¹˜ë¡œì„œ, Ethernet í”„ë ˆì„ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    ê°€ìƒ ë„¤íŠ¸ì›Œí¬ í™˜ê²½ì—ì„œ ë¸Œë¦¬ì§€ ì—°ê²° ë“±ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
    ì¦‰, tuntapì€ TUN ë° TAP ê°€ìƒ ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ì»¤ë„ ë“œë¼ì´ë²„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.




>> ë¬¸ì œ
  - ë„¤íŠ¸ì›Œí¬ êµ¬ì„±í•œ ê²ƒ ì˜êµ¬ ì„¤ì •í•´ì•¼ í•¨
  - ë„¤íŠ¸ì›Œí¬ êµ¬ì„±í•œ ê²ƒ ë‹¤ì‹œ ë˜ëŒë¦´ ìˆ˜ ìˆì–´ì•¼ í•¨.
  - í´ë¦½ë³´ë“œ ê³µìœ í•´ì•¼ í•¨.
  - QEMU ì—ì„œ í™œì„±í™” ì°½ì—ì„œ ì‚¬ìš©í•œ ë‹¨ì¶•í‚¤ëŠ” QEMU ì—ì„œ ì‘ë™í•´ì•¼ í•¨.
  - samba ìš°ë¶„íˆ¬-ìš°ë¶„íˆ¬ ê°„ í†µeeì‹  í•´ì•¼ í•¨.


í•œêµ­ì •ë³´í†µì‹ ê³µì‚¬í˜‘íšŒ - ì´ˆê¸‰ê¸°ìˆ ì ë°œê¸‰ë°›ê¸° - ê¸°ìˆ ìê°ë¦¬ì›. ê¸°ìˆ ììê²© ì‹ ì²­


https://unix.stackexchange.com/a/677988
# lname = link nmae
  find /sys/class/net -mindepth 1 -maxdepth 1 -lname '*virtual*' -prune -o -printf '%f\n'

í…”ë ˆì¹©ìŠ¤, í•˜ë§Œ, ì¸í…”,ê¸€ë£¨ë¸Œë“œ swm


sudo apt install mariadb-server
https://velog.io/@xangj0ng/Linux-Ubuntu-Mariadb-%EC%84%A4%EC%B9%98



# âš“ Kernel offical urls ; https://www.kernel.org/
mkdir -p ~/qemu
wget -P ~/qemu https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.15.169.tar.xz
xz -d ~/qemu/linux-5.15.169.tar.xz



IP_ADDRESS="10.10.14.19"
NETMASK="255.255.255.0"
GATEWAY="10.10.14.254"
DNS="203.248.252.2"


- NoCloudëŠ” cloud-initì˜ ë°ì´í„° ì†ŒìŠ¤ ì¤‘ í•˜ë‚˜ë¡œ, í´ë¼ìš°ë“œ í™˜ê²½ ì—†ì´ë„ ë¡œì»¬ ë˜ëŠ” ê°€ìƒ ë¨¸ì‹  í™˜ê²½ì—ì„œ cloud-init êµ¬ì„±ì„ ì ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì¦‰, ì¸í„°ë„·ì„ í†µí•´ í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ëŒ€ì‹ , ë¡œì»¬ ISO íŒŒì¼ì´ë‚˜ íŒŒì¼ ì‹œìŠ¤í…œì— ìˆëŠ” ë°ì´í„°ë¡œë¶€í„° ì´ˆê¸°í™” ì„¤ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤â€‹
Nautilus


Atemgea 128 ì— flash memory ê°€ 128KB, SRAM: 4KB (í™ ë©”ëª¨ë¦¬ì˜ì—­..?ì „ì—­ ë³€ìˆ˜, ì§€ì—­ ë³€ìˆ˜ê°€ ì¡íˆëŠ” ì˜ì—­)
ğŸ“° Helix TODO:..
  dw: í˜„ì¬ ì»¤ì„œì—ì„œ ë‹¤ìŒ ë‹¨ì–´ê¹Œì§€ ì‚­ì œí•©ë‹ˆë‹¤.
  dW: ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ ë‹¨ì–´ê¹Œì§€ ì‚­ì œí•©ë‹ˆë‹¤ (êµ¬ë‘ì  í¬í•¨).
  xd: You can use xd, which will select the current line (x) and delete it (d). Tip: pressing x repeatedly will select more lines downwards.
ë²”ìš© ë ˆì§€ìŠ¤í„°? R0 ~ R31 ? 32 ë¹„íŠ¸êµ¬ì¡°.. ARM architecture.. LU.. 
ë©”ëª¨ë¦¬ ê³µê°„ì„ ì¡ê³  ë³€ìˆ˜ì— ì´ë¦„ì„ ë¶™ì¸ ê²ƒ.


ë¡œì»¬ ë¨¸ì‹ ì—ì„œ
  >> ssh-keygen -t rsa -b 4096 -C "wbfw109v2@gamil.com"

~/home/wbfw109v2/.ssh/id_rsa

ì‚¬ìš©ì ì´ë¦„ + ì‹œìŠ¤í…œ ì´ë¦„ + ìš©ë„ë¥¼

ssh-keygen -t rsa -b 4096 -C "wbfw109v2@gmail.com" -f ~/.ssh/id_rsa_vm-management
  The key fingerprint is:
  SHA256:QTPThTRgQ5vdpmHnib1CqQPgWG2jvwSDZg2IF1tf5dQ wbfw109v2@gmail.com
  The key's randomart image is:
  +---[RSA 4096]----+
  |  . .  .@==+.    |
  |.. + o + @ooE    |
  |o + o = + = +    |
  | . B + . o X .   |
  |  = * . S = +    |
  | o   + . o   .   |
  |      o o . .    |
  |     . . . .     |
  |      .          |
  +----[SHA256]-----+

??? ì„ë² ë””ë“œ í”„ë¡œê·¸ë˜ë°ì—ì„œëŠ” system call í•¨ìˆ˜ë¥¼ ì§ì ‘ ì‚¬ìš©í•´ì„œ ì‚¬ìš©í•˜ë‚˜? stdlib ë¥¼ ì•ˆì“°ê³ ?

>> Holy.. ë³µêµ¬í•˜ê¸°
  wbfw109v2@iot4-computer ~/r/intel-edge-academy-6 (main)> nmcli connection delete eth-br0
  Connection 'eth-br0' (9a85aeb1-c9a0-4cc7-971f-f6993b216e04) successfully deleted.
  wbfw109v2@iot4-computer ~/r/intel-edge-academy-6 (main)> nmcli connection connect eno1
  Error: argument 'connect' not understood. Try passing --help instead.
  wbfw109v2@iot4-computer ~/r/intel-edge-academy-6 (main) [2]> nmcli connection connect eno1^C
  wbfw109v2@iot4-computer ~/r/intel-edge-academy-6 (main) [2]> sudo nmcli device connect eno1

>>>>>>>>>>>>> ì‹¤íŒ¨
wbfw109v2@iot4-computer ~/r/intel-edge-academy-6 (main)> sudo nmcli connection add type tap ifname tap0 con-name tap0 mode tap owner (i
d -u)
Error: bad connection type: 'tap' not among [6lowpan, 802-11-olpc-mesh (olpc-mesh), 802-11-wireless (wifi), 802-3-ethernet (ethernet), adsl, bluetooth, bond, bridge, cdma, dummy, generic, gsm, hsr, infiniband, ip-tunnel, loopback, macsec, macvlan, ovs-bridge, ovs-dpdk, ovs-interface, ovs-patch, ovs-port, pppoe, team, tun, veth, vlan, vpn, vrf, vxlan, wifi-p2p, wimax, wireguard, wpan, bond-slave, bridge-slave, team-slave]

ë„¤, nmcli ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•´ TAP ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì„±í•˜ë ¤ê³  í•  ë•Œ ë°œìƒí•œ ë¬¸ì œë¥¼ ì •í™•íˆ ì§šì–´ì£¼ì…¨ìŠµë‹ˆë‹¤. í˜„ì¬ nmcliëŠ” TAP ì¸í„°í˜ì´ìŠ¤ì— ëŒ€í•œ ì§ì ‘ì ì¸ íƒ€ì…(tap)ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹  tun íƒ€ì…ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.

  TUNê³¼ TAPì€ ë‘˜ ë‹¤ ê°€ìƒ ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ì´ì§€ë§Œ, ê°ê°ì˜ ì—­í• ì´ ì•½ê°„ ë‹¤ë¦…ë‹ˆë‹¤.

  1. TUNê³¼ TAPì˜ ì°¨ì´ì 
  TUN (Network Tunnel Device):

  IP ë ˆë²¨ì˜ ê°€ìƒ ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
  OSI ë„¤íŠ¸ì›Œí¬ ê³„ì¸µì—ì„œ 3ê³„ì¸µ(ë„¤íŠ¸ì›Œí¬ ê³„ì¸µ) íŒ¨í‚·(IP íŒ¨í‚·)ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
  VPN ê°™ì€ ë„¤íŠ¸ì›Œí¬ í„°ë„ë§ì—ì„œ ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
  TAP (Network Tap Device):

  ì´ë”ë„· í”„ë ˆì„ì„ ì§ì ‘ ì²˜ë¦¬í•˜ëŠ” 2ê³„ì¸µ(ë°ì´í„° ë§í¬ ê³„ì¸µ) ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
  ê°€ìƒ ë¨¸ì‹ (VM)ì´ë‚˜ ì»¨í…Œì´ë„ˆì—ì„œ ë¸Œë¦¬ì§€ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ LANê³¼ ì—°ê²°í•  ë•Œ ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
  2. nmclië¡œ TAPì„ ì§ì ‘ ìƒì„±í•  ìˆ˜ ì—†ëŠ” ì´ìœ 
  **nmcli**ëŠ” í˜„ì¬ TAP ì¸í„°í˜ì´ìŠ¤ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì§€ì›í•˜ì§€ ì•Šìœ¼ë©°, TUN ì¸í„°í˜ì´ìŠ¤ë§Œì„ ì§€ì›í•©ë‹ˆë‹¤.
  í•˜ì§€ë§Œ, ip ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ TAP ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì„±í•œ í›„ ë¸Œë¦¬ì§€ì— ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  